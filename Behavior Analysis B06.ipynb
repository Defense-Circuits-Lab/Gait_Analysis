{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36ae279",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox, HBox, interactive\n",
    "import math\n",
    "import matplotlib.image as img\n",
    "import cv2\n",
    "from IPython.display import clear_output, display\n",
    "from tkinter import Tk, filedialog\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6effd3ea",
   "metadata": {},
   "source": [
    "This notebook consists of the following classes:\n",
    "  \n",
    "    \n",
    "    class main\n",
    "    class subjects\n",
    "    class session\n",
    "    class side_cam\n",
    "    class bottom_cam\n",
    "    class top_cam\n",
    "    class maze corner\n",
    "    class clean_df\n",
    "    class df_functions\n",
    "    class stats\n",
    "    \n",
    "    class gui\n",
    "        class main_gui\n",
    "        class subject_gui\n",
    "        class bc_gui\n",
    "        class tc_gui\n",
    "        class sc_gui\n",
    "        class clean_df_gui\n",
    "        class select_functions\n",
    "        \n",
    "    class maze_corner_gui       \n",
    "    class stats_gui\n",
    "\n",
    "\n",
    "Name all of your .csv/.mp4/.avi files strictly like this: \n",
    "\n",
    "                        210_F1-83_220518_OTT_bottom\n",
    "                        211_F3-04_211123_OTR_top\n",
    "\n",
    "                        Line_ID_Date_Paradigm_Camera   \n",
    "                    \n",
    "Your framerate should not have decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c74159",
   "metadata": {},
   "outputs": [],
   "source": [
    "class main: \n",
    "    \"\"\"Main object contains overview over all files, subjects and common variable over a folder of files as specified by the path.\"\"\"\n",
    "    l_maze_corners_bc = []\n",
    "    l_maze_corners_tc = []\n",
    "\n",
    "    def __init__(self, path = \"PATH\", dict_cams_used = {\"bottom_cam\": False, \"top_cam\": False, \"side_cam\": False}, gui = False):\n",
    "        #creates common variables\n",
    "        main.path = path\n",
    "        main.dict_cams_used = dict_cams_used\n",
    "        main.gui = gui\n",
    "        if main.path != \"PATH\":\n",
    "            self.all_information_given()\n",
    "        \n",
    "    def all_information_given(self):\n",
    "        #creates objects for all of the files in the chosen folder\n",
    "        main.l_session_IDs = np.unique(np.array([file for file in set ([elem[0:-11] for elem in os.listdir(self.path) if elem.endswith('bottom.csv')]+[elem[0:-8] for elem in os.listdir(self.path) if elem.endswith('top.csv')]+[elem[0:-9] for elem in os.listdir(self.path) if elem.endswith('side.csv')])])).tolist()\n",
    "        main.l_sessions = [session(session_ID) for session_ID in self.l_session_IDs]\n",
    "        main.l_subject_IDs = ([session.subject_ID for session in self.l_sessions])\n",
    "        main.l_subjects = [subject(subject_ID) for subject_ID in self.l_subject_IDs]\n",
    "        if main.gui==False:\n",
    "            #branch that will be used if gui-less usage is chosen\n",
    "            if self.dict_cams_used[\"bottom_cam\"] or self.dict_cams_used[\"top_cam\"]:\n",
    "                self.get_maze_corners()\n",
    "            \n",
    "    def subjects_to_groups(self, subject_group_dict, l_groups):\n",
    "        #provides each subject a subject_ID as in subject_group_dict\n",
    "        for subject in main.l_subjects:\n",
    "            subject.group_ID = subject_group_dict[subject.subject_ID]\n",
    "        main.l_groups = l_groups\n",
    "        \n",
    "    def get_maze_corners(self):\n",
    "        #if top or bottom cam are used, this function creates the maze_corner annotation\n",
    "        if self.dict_cams_used[\"bottom_cam\"] & self.all_files_there:\n",
    "            main.l_maze_corners_bc = [session.bc.mc for session in self.l_sessions]\n",
    "        if self.dict_cams_used[\"top_cam\"] & self.all_files_there:\n",
    "            main.l_maze_corners_tc = [session.tc.mc for session in self.l_sessions]\n",
    "        \n",
    "        if self.dict_cams_used[\"bottom_cam\"] or self.dict_cams_used[\"top_cam\"]:\n",
    "            main.l_maze_corners = self.l_maze_corners_bc + self.l_maze_corners_tc\n",
    "            if gui.displayed == False:\n",
    "                display(gui.main_tab)\n",
    "            maze_corner_gui()\n",
    "        else:\n",
    "            self.get_processed_dfs()\n",
    "                   \n",
    "    def get_processed_dfs(self, DLC_likelihood_threshold = 0.9):\n",
    "        #processes the dataframes\n",
    "        main.dict_bodyparts = {}#wird zuk√ºnftig ersetzt durch class bodypart \n",
    "        if self.dict_cams_used[\"bottom_cam\"]:\n",
    "            for session in self.l_sessions:\n",
    "                session.bc.processed_df = clean_df(session.bc, DLC_likelihood_threshold).df \n",
    "        if self.dict_cams_used[\"top_cam\"]:\n",
    "            for session in self.l_sessions:\n",
    "                session.tc.processed_df = clean_df(session.tc, DLC_likelihood_threshold).df\n",
    "        if self.dict_cams_used[\"side_cam\"]:\n",
    "            #clean_df\n",
    "            pass        \n",
    "        \n",
    "    def execute_functions(self, dict_selected_functions = {\"Anxiety\": False, \"Parkinson\": False}):\n",
    "        #calculates the target variables as chosen in dict_selected_functions\n",
    "        self.get_col_in_master_df_and_main_dataframe(dict_selected_functions)\n",
    "        for subject in self.l_subjects:\n",
    "            for session in subject.l_sessions:\n",
    "                session.master_df = df_functions(subject, session, dict_selected_functions).master_df\n",
    "                self.append_session_to_d_data(subject, session, dict_selected_functions)\n",
    "        stats_gui(dict_selected_functions)\n",
    "        \n",
    "    def get_col_in_master_df_and_main_dataframe(self, dict_selected_functions):\n",
    "        #creates the master and main dataframe\n",
    "        main.d_data = {'subject_ID': [], 'group_ID': [], 'paradigm': [], 'trialnumber': [], }\n",
    "        main.col_in_master_df = [('subject_ID', ('subject_ID', '')),\n",
    "                    ('group_ID', ('group_ID', '')),\n",
    "                    ('paradigm', ('paradigm', '')),\n",
    "                    ('trialnumber', ('trialnumber', '')),\n",
    "                    ('time', ('time', '')),\n",
    "                    ('exclude', ('all', 'exclude')), \n",
    "                    ('CenterOfGravity_x_norm_cm', ('CenterOfGravity', 'x_norm_cm')),\n",
    "                    ('CenterOfGravity_y_norm_cm', ('CenterOfGravity', 'y_norm_cm')),                    \n",
    "                    ('CenterOfGravity_rolling_speed_px_per_s', ('CenterOfGravity', 'rolling_speed_px_per_s'))]\n",
    "        if dict_selected_functions[\"Anxiety\"]:              \n",
    "            d_data_anx = { 'count_freezing_bouts': [],\n",
    "                       'mean_freezing_bout_duration': [],\n",
    "                       'percentage_of_time_spent_freezing': [],\n",
    "                       'mean_freezing_bouts_y_position': [],\n",
    "                       'median_freezing_bouts_y_position': [],\n",
    "                       'wall_endzone_mean_freezing_bouts_y_position': [], \n",
    "                       'wall_endzone_median_freezing_bouts_y_position': [], \n",
    "                       'wall_endzone_stddev_freezing_bouts_y_position': [], \n",
    "                       'wall_endzone_count_freezing_bouts': [],}\n",
    "            main.d_data = self.d_data | d_data_anx\n",
    "            main.col_in_master_df.extend([('freezing', ('Freezing_bout', '')),\n",
    "                    ('freezing_bout_count', ('Freezing_bout', 'count')),\n",
    "                    ('freezing_bout_duration', ('Freezing_bout', 'duration')),\n",
    "                    ('freezing_bout_mean_x_norm_cm', ('Freezing_bout', 'mean_x_norm_cm')),\n",
    "                    ('freezing_bout_mean_y_norm_cm', ('Freezing_bout', 'mean_y_norm_cm')),\n",
    "                    ('Percentage_time_spent_freezing_session', ('whole_session', 'percentage_time_spent_freezing')),\n",
    "                    ('Median_freezing_bout_duration_session', ('whole_session', 'median_freezing_bout_duration')),\n",
    "                    ('Median_x_norm_cm_all_freezing_bouts_session', ('whole_session', 'median_x_norm_cm_all_freezing_bouts')),\n",
    "                    ('Median_y_norm_cm_all_freezing_bouts_session', ('whole_session', 'median_y_norm_cm_all_freezing_bouts'))])\n",
    "                      \n",
    "        if dict_selected_functions[\"Parkinson\"]:\n",
    "            d_data_pd =  {'count_gait_disruption_bouts_all': [],\n",
    "                       #'count_gait_disruption_bouts_in': [],\n",
    "                       #'count_gait_disruption_bouts_out': [],\n",
    "                       'mean_gait_disruption_bout_duration_all': [], \n",
    "                       #'mean_gait_disruption_bout_duration_in': [], \n",
    "                       #'mean_gait_disruption_bout_duration_out': [],\n",
    "                       'percentage_of_time_spent_gait_disrupted_all': [],\n",
    "                       'mean_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'mean_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'mean_gait_disruption_bouts_y_position_out': [], \n",
    "                       'median_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'median_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'median_gait_disruption_bouts_y_position_out': [], \n",
    "                       'wall_endzone_mean_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'wall_endzone_mean_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'wall_endzone_mean_gait_disruption_bouts_y_position_out': [],\n",
    "                       'wall_endzone_median_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'wall_endzone_median_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'wall_endzone_median_gait_disruption_bouts_y_position_out': [],\n",
    "                       'wall_endzone_stddev_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'wall_endzone_stddev_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'wall_endzone_stddev_gait_disruption_bouts_y_position_out': [],\n",
    "                       'wall_endzone_count_gait_disruption_bouts_all': [],\n",
    "                       #'wall_endzone_count_gait_disruption_bouts_in': [],\n",
    "                       #'wall_endzone_count_gait_disruption_bouts_out': [], \n",
    "                         }\n",
    "            main.d_data = self.d_data | d_data_pd\n",
    "            main.col_in_master_df.extend([('gaitdisruption', ('GaitDisruption_bout', '')),\n",
    "                    ('gaitdisruption_bout_count', ('GaitDisruption_bout', 'count')),\n",
    "                    ('gaitdisruption_bout_duration', ('GaitDisruption_bout', 'duration')),\n",
    "                    ('gaitdisruption_bout_mean_x_norm_cm', ('GaitDisruption_bout', 'mean_x_norm_cm')),\n",
    "                    ('gaitdisruption_bout_mean_y_norm_cm', ('GaitDisruption_bout', 'mean_y_norm_cm')),\n",
    "                    ('gaitdisruption_bout_direction_bool', ('GaitDisruption_bout', 'direction_bool')),\n",
    "                    ('gaitdisruption_bout_direction_mean', ('GaitDisruption_bout', 'direction_mean')),\n",
    "                    ('Percentage_time_spent_gaitdisrupted_session', ('whole_session', 'percentage_time_spent_gait_disrupted')),\n",
    "                    ('Median_gaitdisruption_bout_duration_session', ('whole_session', 'median_gait_disruption_bout_duration')),\n",
    "                    ('Median_x_norm_cm_all_gaitdisruption_bouts_session', ('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')),\n",
    "                    ('Median_y_norm_cm_all_gaitdisruption_bouts_session', ('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts'))])\n",
    "            \n",
    "    def append_session_to_d_data(self, subject, session, dict_selected_functions): \n",
    "            #appends data of each session to a dict containing all sessions\n",
    "            wall_end_position = 35 #in cm\n",
    "            \n",
    "            self.d_data['subject_ID'].append(session.subject_ID)\n",
    "            self.d_data['group_ID'].append(subject.group_ID)\n",
    "            self.d_data['paradigm'].append(session.paradigm)\n",
    "            self.d_data['trialnumber'].append(subject.trialnumber)\n",
    "            \n",
    "            if dict_selected_functions[\"Anxiety\"]: \n",
    "                self.d_data['count_freezing_bouts'].append(self.get_total_bount_count(session.master_df['freezing_bout_count'].unique()))\n",
    "                self.d_data['mean_freezing_bout_duration'].append(session.master_df['freezing_bout_duration'].mean())\n",
    "                self.d_data['percentage_of_time_spent_freezing'].append(session.master_df['Percentage_time_spent_freezing_session'].unique()[0])\n",
    "                self.d_data['mean_freezing_bouts_y_position'].append(session.master_df['freezing_bout_mean_y_norm_cm'].mean())\n",
    "                self.d_data['median_freezing_bouts_y_position'].append(session.master_df['freezing_bout_mean_y_norm_cm'].median())\n",
    "                \n",
    "                mean_pos_freezing, median_pos_freezing, std_dev_freezing, bout_count_freezing = self.get_fuzziness(session.master_df, wall_end_position, 10)\n",
    "                \n",
    "                self.d_data['wall_endzone_mean_freezing_bouts_y_position'].append(mean_pos_freezing)\n",
    "                self.d_data['wall_endzone_median_freezing_bouts_y_position'].append(median_pos_freezing)\n",
    "                self.d_data['wall_endzone_stddev_freezing_bouts_y_position'].append(std_dev_freezing)\n",
    "                self.d_data['wall_endzone_count_freezing_bouts'].append(bout_count_freezing)\n",
    "            \n",
    "            if dict_selected_functions[\"Parkinson\"]: \n",
    "                self.d_data['count_gait_disruption_bouts_all'].append(self.get_total_bount_count(session.master_df['gaitdisruption_bout_count'].unique()))\n",
    "                #self.d_data['count_gait_disruption_bouts_in'].append(self.get_total_bount_count(df_temp_in['gaitdisruption_bout_count'].unique()))\n",
    "                #self.d_data['count_gait_disruption_bouts_out'].append(self.get_total_bount_count(df_temp_out['gaitdisruption_bout_count'].unique()))\n",
    "\n",
    "\n",
    "                self.d_data['mean_gait_disruption_bout_duration_all'].append(session.master_df['gaitdisruption_bout_duration'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bout_duration_in'].append(df_temp_in['gaitdisruption_bout_duration'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bout_duration_out'].append(df_temp_out['gaitdisruption_bout_duration'].mean())\n",
    "\n",
    "\n",
    "                self.d_data['percentage_of_time_spent_gait_disrupted_all'].append(session.master_df['Percentage_time_spent_gaitdisrupted_session'].unique()[0])\n",
    "\n",
    "\n",
    "                self.d_data['mean_gait_disruption_bouts_y_position_all'].append(session.master_df['gaitdisruption_bout_mean_y_norm_cm'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bouts_y_position_in'].append(df_temp_in['gaitdisruption_bout_mean_y_norm_cm'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bouts_y_position_out'].append(df_temp_out['gaitdisruption_bout_mean_y_norm_cm'].mean())\n",
    "\n",
    "\n",
    "                self.d_data['median_gait_disruption_bouts_y_position_all'].append(session.master_df['gaitdisruption_bout_mean_y_norm_cm'].median())\n",
    "                #self.d_data['median_gait_disruption_bouts_y_position_in'].append(df_temp_in['gaitdisruption_bout_mean_y_norm_cm'].median())\n",
    "                #self.d_data['median_gait_disruption_bouts_y_position_out'].append(df_temp_out['gaitdisruption_bout_mean_y_norm_cm'].median())\n",
    "\n",
    "\n",
    "                mean_pos_gait_all, median_pos_gait_all, std_dev_gait_all, bout_count_gait_all = self.get_fuzziness(session.master_df, wall_end_position, 10)\n",
    "                #mean_pos_gait_in, median_pos_gait_in, std_dev_gait_in, bout_count_gait_in = self.get_fuzziness(df_temp_in, wall_end_position, 10)\n",
    "                #mean_pos_gait_out, median_pos_gait_out, std_dev_gait_out, bout_count_gait_out = self.get_fuzziness(df_temp_out, wall_end_position, 10)\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_mean_gait_disruption_bouts_y_position_all'].append(mean_pos_gait_all)\n",
    "                #self.d_data['wall_endzone_mean_gait_disruption_bouts_y_position_in'].append(mean_pos_gait_in)\n",
    "                #self.d_data['wall_endzone_mean_gait_disruption_bouts_y_position_out'].append(mean_pos_gait_out)\n",
    "\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_median_gait_disruption_bouts_y_position_all'].append(median_pos_gait_all)\n",
    "                #self.d_data['wall_endzone_median_gait_disruption_bouts_y_position_in'].append(median_pos_gait_in)\n",
    "                #self.d_data['wall_endzone_median_gait_disruption_bouts_y_position_out'].append(median_pos_gait_out)\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_stddev_gait_disruption_bouts_y_position_all'].append(std_dev_gait_all)\n",
    "                #self.d_data['wall_endzone_stddev_gait_disruption_bouts_y_position_in'].append(std_dev_gait_in)\n",
    "                #self.d_data['wall_endzone_stddev_gait_disruption_bouts_y_position_out'].append(std_dev_gait_out)\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_count_gait_disruption_bouts_all'].append(bout_count_gait_all)\n",
    "                #self.d_data['wall_endzone_count_gait_disruption_bouts_in'].append(bout_count_gait_in)\n",
    "                #self.d_data['wall_endzone_count_gait_disruption_bouts_out'].append(bout_count_gait_out)\n",
    "            \n",
    "            main.dataframe = pd.DataFrame(data = self.d_data)   \n",
    "            \n",
    "    def get_total_bount_count(self, uniques):\n",
    "        uniques = uniques[~np.isnan(uniques)]\n",
    "        return uniques.shape[0]\n",
    "\n",
    "    #was ist half_window_size, ist es fix auf 10?\n",
    "    def get_fuzziness(self, df_tmp, wall_end_position, half_window_size):\n",
    "        mean_pos = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                              (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].mean()\n",
    "\n",
    "        median_pos = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                                (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].median()\n",
    "\n",
    "        std_dev = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                             (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].std()\n",
    "\n",
    "        bout_count = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                                (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].shape[0]\n",
    "\n",
    "        if bout_count < 3:\n",
    "            mean_pos = np.NaN\n",
    "            std_dev = np.NaN    \n",
    "    \n",
    "        return mean_pos, median_pos, std_dev, bout_count\n",
    "        \n",
    "    def calculate_stats(self, output_path, l_selected_data_col_dict):\n",
    "        #calls the stats class with inputs as chosen in the stats_gui\n",
    "        for dict_stats in l_selected_data_col_dict:\n",
    "            stats.total_count_stats(self, dict_stats[\"data_col\"], dict_stats[\"independent_variable\"], dict_stats[\"hue\"], output_path)\n",
    "            if \"y_position\" in dict_stats[\"data_col\"]:\n",
    "                stats.position_stats(self, dict_stats[\"data_col\"], dict_stats[\"independent_variable\"], dict_stats[\"hue\"], output_path)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5350d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class subject(main):\n",
    "    \"\"\"creates an object representing an individual subject\"\"\"\n",
    "    def __init__(self, subject_ID):\n",
    "        self.subject_ID = subject_ID\n",
    "        self.l_sessions = [session for session in main.l_sessions if session.subject_ID == self.subject_ID]\n",
    "        #if len(self.l_sessions) > 1:\n",
    "            #self.l_paradigms = [session.paradigm for session in self.l_sessions]\n",
    "        self.dict_date_paradigm = {session.date:session.paradigm for session in self.l_sessions}\n",
    "        self.trialnumber = 1 #muss noch implementiert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c17da831",
   "metadata": {},
   "outputs": [],
   "source": [
    "class session(subject):\n",
    "    \"\"\"creates an object representing an individual session and checks, whether all the files are there\"\"\"\n",
    "    def __init__(self, session_ID):\n",
    "        self.session_ID = session_ID\n",
    "        if 'OTE' in self.session_ID:\n",
    "            self.paradigm = 'exponential'\n",
    "        elif 'OTT'  in self.session_ID:\n",
    "            self.paradigm  = 'triangle'\n",
    "        elif 'OTR'  in self.session_ID:\n",
    "            self.paradigm = 'rectangle'\n",
    "        self.subject_ID_date = self.session_ID[0:-4] \n",
    "        #falls andere Paradigmen eingebaut werden, die nicht drei spaces in der Benennung haben, muss das ge√§ndert werden\n",
    "        #generisch: self.session_ID[self.session_ID.index('')+1:self.session_ID.index('')]\n",
    "        self.date = datetime.strptime(self.subject_ID_date[-6:], '%y%m%d')\n",
    "        self.subject_ID = self.subject_ID_date[0:-7]\n",
    "        bc_csv = self.session_ID in set([elem[0:-11] for elem in os.listdir(main.path) if elem.endswith('_bottom.csv')])\n",
    "        bc_mp4 = self.session_ID in set([elem[0:-11] for elem in os.listdir(main.path) if elem.endswith('_bottom.mp4')]) \n",
    "        tc_csv = self.session_ID in set([elem[0:-8] for elem in os.listdir(main.path) if elem.endswith('_top.csv')])\n",
    "        tc_mp4 = self.session_ID in set([elem[0:-8] for elem in os.listdir(main.path) if elem.endswith('_top.mp4') or elem.endswith('_top.avi')])\n",
    "        sc_csv = self.session_ID in set([elem[0:-9] for elem in os.listdir(main.path) if elem.endswith('_side.csv')])\n",
    "        sc_mp4 = self.session_ID in set([elem[0:-9] for elem in os.listdir(main.path) if elem.endswith('_side.mp4')])\n",
    "        \n",
    "        main.all_files_there = True\n",
    "        missing_files_statement = \"\\nPlease name your files as the following: 210_F1-83_220518_OTT_bottom.mp4 \\nLine_ID_Date_Paradigm_Camera_ending\"\n",
    "        if main.dict_cams_used[\"bottom_cam\"]:\n",
    "            if bc_csv == False:\n",
    "                print(\"Missing _bottom.csv file for session {} in {}!\".format(self.session_ID, main.path), missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            elif bc_mp4 == False:\n",
    "                print(\"Missing _bottom.mp4 file for session {} in {}!\".format(self.session_ID, main.path), missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            else:\n",
    "                bc_video_filename = session_ID + \"_bottom.mp4\"\n",
    "                bc_csv_filename = session_ID + \"_bottom.csv\"\n",
    "                bc_df = pd.read_csv(main.path + bc_csv_filename, skiprows=1, index_col=0, header=[0, 1])\n",
    "                self.bc = bottom_cam(self.session_ID, bc_df)\n",
    "\n",
    "        if main.dict_cams_used[\"top_cam\"]:\n",
    "            if tc_csv ==False:\n",
    "                print(\"Missing _top.csv file for session {} in {}!\".format(self.session_ID, main.path), missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            elif tc_mp4 == False:\n",
    "                print(\"Missing top.mp4 file for session {} in {}!\".format(self.session_ID, main.path), missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            else:  \n",
    "                tc_video_filename = session_ID + \"_top.mp4\"\n",
    "                tc_csv_filename = session_ID + \"_top.csv\"\n",
    "                tc_df = pd.read_csv(main.path + tc_csv_filename, skiprows=1, index_col=0, header=[0, 1])\n",
    "                self.tc = top_cam(self.session_ID, tc_df)\n",
    "            \n",
    "        if main.dict_cams_used[\"side_cam\"]:\n",
    "            if sc_csv == False:\n",
    "                print(\"Missing _side.csv file for session {} in {}!\".format(self.session_ID, main.path), missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            elif sc_mp4 == False:\n",
    "                print(\"Missing side.mp4 file for session {} in {}!\".format(self.session_ID, main.path),missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            else:\n",
    "                sc_video_filename = session_ID + \"_side.mp4\"\n",
    "                sc_csv_filename = session_ID + \"_side.csv\"\n",
    "                sc_df = pd.read_csv(main.path + sc_csv_filename, skiprows=1, index_col=0, header=[0, 1])\n",
    "                #create side_cam object\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "620c7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottom_cam(session):\n",
    "    \"\"\"creates an object containing the data for bottom cam recording modality\"\"\"\n",
    "    def __init__(self, session_ID, df):\n",
    "        self.session_ID = session_ID\n",
    "        self.df = df\n",
    "        path_avi = main.path + session_ID + \"_bottom.AVI\"\n",
    "        path_mp4 = main.path + session_ID + \"_bottom.mp4\"\n",
    "        if os.path.exists(path_avi):\n",
    "            self.video_path = path_avi\n",
    "        elif os.path.exists(path_mp4):\n",
    "            self.video_path = path_mp4\n",
    "        self.mc = maze_corners(self.video_path)\n",
    "        video = imageio.get_reader(self.video_path,  'ffmpeg')\n",
    "        self.framerate = video.get_meta_data()[\"fps\"]\n",
    "        self.cam = \"bottom_cam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13d7d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class top_cam:\n",
    "    \"\"\"creates an object containing the data for top cam recording modality\"\"\"\n",
    "    def __init__(self, session_ID, df):\n",
    "        self.session_ID = session_ID\n",
    "        self.df = df\n",
    "        path_avi = main.path + session_ID + \"_top.AVI\"\n",
    "        path_mp4 = main.path + session_ID + \"_top.mp4\"\n",
    "        if os.path.exists(path_avi):\n",
    "            self.video_path = path_avi\n",
    "        elif os.path.exists(path_mp4):\n",
    "            self.video_path = path_mp4\n",
    "        self.mc = maze_corners(self.video_path)\n",
    "        video = imageio.get_reader(self.video_path,  'ffmpeg')\n",
    "        self.framerate = video.get_meta_data()[\"fps\"]\n",
    "        self.cam = \"top_cam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168e62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class side_cam:\n",
    "    \"\"\"creates an object containing the data for side cam recording modality\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        #stitch()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5456523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class clean_df(session):\n",
    "    \"\"\"creates an object that returns the cleaned dataframe after processing several functions\"\"\"\n",
    "    maze_length_in_cm = 50\n",
    "    \n",
    "    def __init__(self, session_cam_object, threshold):        \n",
    "        self.threshold = threshold\n",
    "        self.framerate = session_cam_object.framerate\n",
    "        self.results = session_cam_object.mc.results #side cams geben keine results weil sie keine mc objects haben\n",
    "        df = session_cam_object.df\n",
    "        self.l_bodyparts = [elem[0] for elem in df.columns[::3]]\n",
    "        main.dict_bodyparts[session_cam_object.cam] = self.l_bodyparts #wird zuk√ºnfitg ersetzt durch class bodypart \n",
    "        df = self.get_time(df)\n",
    "        df = self.identify_duplicates(df)\n",
    "        df[('all', 'exclude')] = False\n",
    "        df = self.exclude_frames(df)\n",
    "        if \"CenterOfGravity\" not in self.l_bodyparts:\n",
    "            df = self.get_center_of_gravity(df)\n",
    "        df = self.normalize_coordinates(df)\n",
    "        self.df = df\n",
    "        \n",
    "    def get_time(self, df):\n",
    "        #appends the dataframe with an column time, calculated by index and framerate\n",
    "        df['time'] = np.NaN\n",
    "        df['time'] = df['EarRight'].index/self.framerate\n",
    "\n",
    "        return df\n",
    "        # in future version: check for NaN\n",
    "        \n",
    "    def identify_duplicates(self, df):\n",
    "        #checks for possible duplicates made by the DLC network and excludes them\n",
    "        l_indices = list(df.index)\n",
    "        l_unique_indices = list(set(l_indices))\n",
    "\n",
    "        if len(l_indices) != len(l_unique_indices):\n",
    "            l_duplicates = []\n",
    "            for index in l_unique_indices:\n",
    "                if l_indices.count(index) > 1:\n",
    "                    l_duplicates.append(index)\n",
    "            df.loc[l_duplicates, ('all', 'exclude')] = True\n",
    "\n",
    "        return df\n",
    "\n",
    "    def exclude_frames(self, df):\n",
    "        #excludes frames, where the likelihood is below a certain threshold\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            df.loc[:, (bodypart, 'exclude')] = False\n",
    "            df.loc[df[bodypart]['likelihood'] < self.threshold, (bodypart, 'exclude')] = True\n",
    "            df.loc[df[('all', 'exclude')] == True, (bodypart, 'exclude')] = True\n",
    "        return df\n",
    "    \n",
    "    def rotate(self, xy, theta):\n",
    "        cos_theta, sin_theta = math.cos(theta), math.sin(theta)\n",
    "\n",
    "        return (\n",
    "            xy[0] * cos_theta - xy[1] * sin_theta,\n",
    "            xy[0] * sin_theta + xy[1] * cos_theta\n",
    "        )\n",
    "\n",
    "    def translate(self, xy, offset):\n",
    "        return xy[0] + offset[0], xy[1] + offset[1]\n",
    "\n",
    "\n",
    "    def normalize_coordinates(self, df):\n",
    "        #uses the functions rotate and translate to normalize the coordinates\n",
    "        length = self.results['length']\n",
    "        width = self.results['width']\n",
    "        offset_to_standard = (-self.results['offset_x'], -self.results['offset_y'])\n",
    "        offset_from_standard = (self.results['offset_x'], self.results['offset_y'])\n",
    "        theta_to_standard = -self.results['theta']\n",
    "\n",
    "\n",
    "        length_in_px = length\n",
    "        cm_per_px = self.maze_length_in_cm/length_in_px\n",
    "\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            df[(bodypart, 'x_norm')] = self.translate(self.rotate((df[(bodypart,'x')], df[(bodypart,'y')]), theta_to_standard), offset_to_standard)[0]\n",
    "            df[(bodypart, 'y_norm')] = self.translate(self.rotate((df[(bodypart,'x')], df[(bodypart,'y')]), theta_to_standard), offset_to_standard)[1]\n",
    "            df[(bodypart, 'x_norm_cm')] = 3 - (df[(bodypart, 'x_norm')] * cm_per_px)\n",
    "            df[(bodypart, 'y_norm_cm')] = 50 - (df[(bodypart, 'y_norm')] * cm_per_px)\n",
    "\n",
    "        return df    \n",
    "\n",
    "    \n",
    "    def get_center_of_gravity(self, df):\n",
    "        #calculates the center of gravity, if it is not labeled in DLC\n",
    "        df.loc[(df[('all', 'exclude')] == False) & (df[('EarRight', 'exclude')] == False) & (df[('EarLeft', 'exclude')] == False) & (df[('TailBase', 'exclude')] == False), \n",
    "           ('CenterOfGravity', 'x')] = (df.loc[df[('all', 'exclude')] == False, ('EarRight', 'x')] + \n",
    "                                          df.loc[df[('all', 'exclude')] == False, ('EarLeft', 'x')] + \n",
    "                                          df.loc[df[('all', 'exclude')] == False, ('TailBase', 'x')]) / 3\n",
    "\n",
    "        df.loc[(df[('all', 'exclude')] == False) & (df[('EarRight', 'exclude')] == False) & (df[('EarLeft', 'exclude')] == False) & (df[('TailBase', 'exclude')] == False), \n",
    "           ('CenterOfGravity', 'y')] = (df.loc[df[('all', 'exclude')] == False, ('EarRight', 'y')] + \n",
    "                                          df.loc[df[('all', 'exclude')] == False, ('EarLeft', 'y')] + \n",
    "                                          df.loc[df[('all', 'exclude')] == False, ('TailBase', 'y')]) / 3\n",
    "\n",
    "        df[('CenterOfGravity', 'exclude')] = False\n",
    "        df.loc[(df[('CenterOfGravity', 'x')].isnull()) | (df[('CenterOfGravity', 'y')].isnull()), ('CenterOfGravity', 'exclude')] = True\n",
    "\n",
    "        self.l_bodyparts.append('CenterOfGravity')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4374cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class df_functions(bottom_cam, top_cam, side_cam):\n",
    "    \"\"\"class that returns the dataframe appended with the chosen target variables after calling several functions and combines different recording modalities\"\"\"\n",
    "    immobility_threshold = 16\n",
    "\n",
    "    min_freezing_duration = 1\n",
    "\n",
    "    TIME_OF_GAIT_BEFORE_DISRUPT = 0.5\n",
    "    TARGET_TIME_GAIT_DISRUPTION = 0.2\n",
    "    \n",
    "    def __init__(self, subject, session, dict_selected_functions):\n",
    "        #loops through the functions for each dataframe\n",
    "        self.session = session\n",
    "        self.subject = subject\n",
    "        self.dict_selected_functions = dict_selected_functions\n",
    "        self.l_dfs = []\n",
    "        if main.dict_cams_used[\"bottom_cam\"]:\n",
    "            df = session.bc.processed_df\n",
    "            self.l_bodyparts = main.dict_bodyparts[\"bottom_cam\"]\n",
    "            self.framerate = session.bc.framerate\n",
    "            \n",
    "            df = self.get_speed_and_rolling_speed(df)\n",
    "            df = self.get_immobility(df)\n",
    "            if dict_selected_functions[\"Anxiety\"]:\n",
    "                df = self.get_freezing_bouts(df)\n",
    "                df = self.get_freezing_avg(df)\n",
    "            if dict_selected_functions[\"Parkinson\"]:\n",
    "                df = self.get_direction_bc(df)\n",
    "                df = self.get_gait_disruption_bouts(df)\n",
    "                df = self.get_gait_disruption_avg(df)\n",
    "            self.l_dfs.append(df)\n",
    "            \n",
    "        if main.dict_cams_used[\"top_cam\"]:\n",
    "            self.l_bodyparts = main.dict_bodyparts[\"top_cam\"]\n",
    "            df = session.tc.processed_df\n",
    "            self.framerate = session.tc.framerate\n",
    "            df = self.get_speed_and_rolling_speed(df)\n",
    "            df = self.get_immobility(df)\n",
    "            if dict_selected_functions[\"Anxiety\"]:\n",
    "                df = self.get_freezing_bouts(df)\n",
    "                df = self.get_freezing_avg(df)\n",
    "            if dict_selected_functions[\"Parkinson\"]:\n",
    "                df = self.get_direction_tc(df)\n",
    "                df = self.get_gait_disruption_bouts(df)\n",
    "                df = self.get_gait_disruption_avg(df)\n",
    "            self.l_dfs.append(df)\n",
    "            \n",
    "            \n",
    "        if main.dict_cams_used[\"side_cam\"]:\n",
    "            self.l_bodyparts = main.dict_bodyparts[\"side_cam\"]\n",
    "            self.framerate = session.sc.framerate\n",
    "            \n",
    "            self.l_dfs.append(df)\n",
    "        \n",
    "        self.combined_df = self.combine_cam_dfs()\n",
    "        self.combined_df = self.add_metadata(self.combined_df)\n",
    "        self.master_df = self.get_master_df()\n",
    "                \n",
    "    \n",
    "    def get_speed_and_rolling_speed(self, df):\n",
    "        #calcualtes speed for the bodyparts\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            df[(bodypart, 'speed_px_per_s')] = np.NaN\n",
    "            df[(bodypart, 'rolling_speed_px_per_s')] = np.NaN\n",
    "\n",
    "            # Limitation: since we have to exclude some frames, these calculations are not made frame by frame (yet for most)\n",
    "            df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'speed_px_per_s')] = (((df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'x')].diff()**2                                                                                                        + df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'y')].diff()**2)**(1/2)) \n",
    "                                                                                                                             / df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), 'time'].diff())\n",
    "            df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'rolling_speed_px_per_s')] = df.loc[df[('all', 'exclude')] == False, (bodypart, 'speed_px_per_s')].rolling(5, min_periods=3, center=True).mean()\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def get_direction_bc(self, df): \n",
    "        #calculates the direction of the animal and appends the dataframe by a direction column\n",
    "        #used Snout instead of EarLeft & EarRight (less secure parameter?, but better suitable for BottomCam?)\n",
    "            #could also synchronize with top Cam data and use direction from there\n",
    "        df[('moving_towards_maze_end', '')] = False\n",
    "        df.loc[(df[('Snout', 'y_norm')] < df[('TailBase', 'y_norm')]), ('moving_towards_maze_end', '')] = True\n",
    "        #df.loc[(df[('Snout', 'y_norm')] < df[('CenterOfGravity', 'y_norm')]), ('moving_towards_maze_end', '')] = True\n",
    "        return df\n",
    "    \n",
    "    def get_dircetion_tc(self, df):\n",
    "        #calculates the direction of the animal and appends the dataframe by a direction column\n",
    "        df[('moving_towards_maze_end', '')] = False\n",
    "        df.loc[(df[('EarRight', 'y_norm')] < df[('CenterOfGravity', 'y_norm')]) \n",
    "               & (df[('EarLeft', 'y_norm')] < df[('CenterOfGravity', 'y_norm')]), ('moving_towards_maze_end', '')] = True\n",
    "        return df\n",
    "    \n",
    "    def get_direction_sc(self, df):\n",
    "        pass\n",
    "    \n",
    "    def get_immobility(self, df):\n",
    "        #checks for immobility\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            # create 'immobility' column and set base value to false\n",
    "            df.loc[ :, (bodypart, 'immobility')] = False\n",
    "            df.loc[df[(bodypart,'rolling_speed_px_per_s')] < self.immobility_threshold, (bodypart, 'immobility')] = True\n",
    "        return df\n",
    "        \n",
    "    def get_gait_disruption_bouts(self, df):\n",
    "        #checks for gait disruption bouts\n",
    "        df[('GaitDisruption_bout', '')] = False\n",
    "        df[('GaitDisruption_bout', 'count')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'duration')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'mean_x_norm_cm')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'mean_y_norm_cm')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'direction_bool')] = ''\n",
    "        df[('GaitDisruption_bout', 'direction_mean')] = np.NaN\n",
    "\n",
    "        if self.dict_selected_functions[\"Anxiety\"] == False:\n",
    "            df['all_freezing_bodyparts_immobile'] = df[[('EarRight', 'immobility'), ('EarLeft', 'immobility'), ('CenterOfGravity', 'immobility')]].all(axis=1)\n",
    "        \n",
    "        l_timesteps = []\n",
    "        if self.framerate%1 != 0:\n",
    "            print(\"gait disruption bout calculations are invalid due to framerate with decimal places\")\n",
    "        for i in range(int(self.framerate)):\n",
    "            l_timesteps.append(i/self.framerate)\n",
    "\n",
    "        time_gait_disruption = self.find_nearest(np.asarray(l_timesteps), self.TARGET_TIME_GAIT_DISRUPTION)\n",
    "        frames_difference = l_timesteps.index(time_gait_disruption)\n",
    "\n",
    "        gait_disruption_threshold_reached = df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].iloc[np.where(np.round(df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].diff(frames_difference).values, 7) == round(time_gait_disruption, 7))[0]].values\n",
    "\n",
    "        # could still throw an error if only a single frame, because of slicing to find first and last index of each interval?    \n",
    "        if gait_disruption_threshold_reached.shape[0] > 0:\n",
    "            indices = np.asarray(df.loc[df['time'].isin(gait_disruption_threshold_reached)].index)\n",
    "            lower_end = (indices+1)[:-1]\n",
    "            upper_end = indices[1:]\n",
    "            mask = lower_end < upper_end\n",
    "            mask_last = np.concatenate([mask, np.array([True])])\n",
    "            mask_first = np.concatenate([np.array([True]), mask])\n",
    "\n",
    "            last_value_of_intervals = indices[mask_last]\n",
    "            first_value_of_intervals = indices[mask_first]\n",
    "            \n",
    "            first_value_of_intervals = first_value_of_intervals-l_timesteps.index(self.find_nearest(np.asarray(l_timesteps), self.TARGET_TIME_GAIT_DISRUPTION))\n",
    "\n",
    "            interval_ranges = np.column_stack([first_value_of_intervals,last_value_of_intervals])\n",
    "\n",
    "            frames_prior_to_interval_start = l_timesteps.index(self.find_nearest(np.asarray(l_timesteps), self.TIME_OF_GAIT_BEFORE_DISRUPT))\n",
    "            bout_count = 0\n",
    "\n",
    "            if interval_ranges.shape[0] > 0:\n",
    "                for first_idx, last_idx in interval_ranges:\n",
    "                    start_idx_gait_check = first_idx - frames_prior_to_interval_start\n",
    "                    if df.loc[start_idx_gait_check:first_idx-1, 'all_freezing_bodyparts_immobile'].any() == False:\n",
    "                        bout_count = bout_count + 1\n",
    "                        bout_duration = (df.loc[last_idx, 'time'] - df.loc[first_idx, 'time'])[0]\n",
    "                        mean_pos_x_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'x_norm_cm')].mean()\n",
    "                        mean_pos_y_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'y_norm_cm')].mean()\n",
    "                        direction_bool = df.loc[first_idx:last_idx, ('moving_towards_maze_end', '')].all()\n",
    "                        direction_mean = df.loc[first_idx:last_idx, ('moving_towards_maze_end', '')].mean()\n",
    "\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', '')] = True\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'count')] = bout_count\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'duration')] = bout_duration\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'mean_x_norm_cm')] = mean_pos_x_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'mean_y_norm_cm')] = mean_pos_y_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'direction_bool')] = direction_bool\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'direction_mean')] = direction_mean\n",
    "\n",
    "        return df\n",
    "        \n",
    "    def find_nearest(self, array, value):\n",
    "        array = np.asarray(array)\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "        return array[idx]\n",
    "\n",
    "    # f√ºr verschiedene Cams anpassen?\n",
    "    def get_freezing_bouts(self, df):\n",
    "        #checks for freezing bouts\n",
    "        df[('Freezing_bout', '')] = False\n",
    "        df[('Freezing_bout', 'count')] = np.NaN\n",
    "        df[('Freezing_bout', 'duration')] = np.NaN\n",
    "        df[('Freezing_bout', 'mean_x_norm_cm')] = np.NaN\n",
    "        df[('Freezing_bout', 'mean_y_norm_cm')] = np.NaN\n",
    "\n",
    "        df['all_freezing_bodyparts_immobile'] = df[[('EarRight', 'immobility'), ('EarLeft', 'immobility'), ('CenterOfGravity', 'immobility')]].all(axis=1)\n",
    "\n",
    "        times_where_freezing_threshold_was_reached = df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].iloc[np.where(df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].diff(self.framerate).values == 1)[0]].values\n",
    "\n",
    "        # could still throw an error if only a single frame, because of slicing to find first and last index of each interval?\n",
    "        if times_where_freezing_threshold_was_reached.shape[0] > 0:\n",
    "            indices = np.asarray(df.loc[df['time'].isin(times_where_freezing_threshold_was_reached)].index)\n",
    "            lower_end = (indices+1)[:-1]\n",
    "            upper_end = indices[1:]\n",
    "            mask = lower_end < upper_end\n",
    "            mask_last = np.concatenate([mask, np.array([True])])\n",
    "            mask_first = np.concatenate([np.array([True]), mask])\n",
    "\n",
    "            last_value_of_intervals = indices[mask_last]\n",
    "            first_value_of_intervals = indices[mask_first]\n",
    "\n",
    "            first_value_of_intervals = first_value_of_intervals-self.framerate\n",
    "\n",
    "            interval_ranges = np.column_stack([first_value_of_intervals,last_value_of_intervals])\n",
    "\n",
    "            bout_count = 0\n",
    "\n",
    "            if interval_ranges.shape[0] > 0:\n",
    "                for first_idx, last_idx in interval_ranges:\n",
    "                        bout_count = bout_count + 1\n",
    "                        bout_duration = (df.loc[last_idx, 'time'] - df.loc[first_idx, 'time'])[0]\n",
    "                        mean_pos_x_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'x_norm_cm')].mean()\n",
    "                        mean_pos_y_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'y_norm_cm')].mean()\n",
    "\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', '')] = True\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'count')] = bout_count\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'duration')] = bout_duration\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'mean_x_norm_cm')] = mean_pos_x_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'mean_y_norm_cm')] = mean_pos_y_norm_cm\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def get_freezing_avg(self, df):\n",
    "        #calculates the session average for freezing\n",
    "        freezing_bout_count = df[('Freezing_bout', 'count')].unique().shape[0] - 1\n",
    "\n",
    "        if freezing_bout_count > 0:\n",
    "            df[('whole_session', 'percentage_time_spent_freezing')] = (df.loc[df[('Freezing_bout', '')] == True].shape[0] / df.shape[0]) * 100\n",
    "            df[('whole_session', 'median_freezing_bout_duration')] = np.nanmedian(df[('Freezing_bout', 'duration')].unique())\n",
    "            df[('whole_session', 'median_x_norm_cm_all_freezing_bouts')] = np.nanmedian(df[('Freezing_bout', 'mean_x_norm_cm')].unique())\n",
    "            df[('whole_session', 'median_y_norm_cm_all_freezing_bouts')] = np.nanmedian(df[('Freezing_bout', 'mean_y_norm_cm')].unique())\n",
    "        else:\n",
    "            df[('whole_session', 'percentage_time_spent_freezing')] = 0\n",
    "            df[('whole_session', 'median_freezing_bout_duration')] = np.NaN\n",
    "            df[('whole_session', 'median_x_norm_cm_all_freezing_bouts')] = np.NaN\n",
    "            df[('whole_session', 'median_y_norm_cm_all_freezing_bouts')] = np.NaN       \n",
    "            \n",
    "        return df\n",
    "            \n",
    "    def get_gait_disruption_avg(self, df):\n",
    "        #calculates the session average for gait disruption\n",
    "        gait_disruption_bout_count = df[('GaitDisruption_bout', 'count')].unique().shape[0] - 1\n",
    "\n",
    "        if gait_disruption_bout_count > 0:\n",
    "            df[('whole_session', 'percentage_time_spent_gait_disrupted')] = (df.loc[df[('GaitDisruption_bout', '')] == True].shape[0] / df.shape[0]) * 100\n",
    "            df[('whole_session', 'median_gait_disruption_bout_duration')] = np.nanmedian(df[('GaitDisruption_bout', 'duration')].unique())\n",
    "            df[('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')] = np.nanmedian(df[('GaitDisruption_bout', 'mean_x_norm_cm')].unique())\n",
    "            df[('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts')] = np.nanmedian(df[('GaitDisruption_bout', 'mean_y_norm_cm')].unique())\n",
    "        else:\n",
    "            df[('whole_session', 'percentage_time_spent_gait_disrupted')] = 0\n",
    "            df[('whole_session', 'median_gait_disruption_bout_duration')] = np.NaN\n",
    "            df[('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')] = np.NaN\n",
    "            df[('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts')] = np.NaN\n",
    "\n",
    "        return df\n",
    "\n",
    "    def combine_cam_dfs(self):\n",
    "        #combines the data from different recording modalities. not yet implemented. requires class bodyparts\n",
    "        if len(self.l_dfs) == 1:\n",
    "            combined_df = self.l_dfs[0]\n",
    "            return combined_df\n",
    "        else:\n",
    "            #crazy function to combine input of all cams using self.l_dfs\n",
    "            #or the bodypart class\n",
    "            #return combined_df \n",
    "            pass\n",
    "        \n",
    "    def add_metadata(self, df):\n",
    "        #adds metadata to the dataframe\n",
    "        df['subject_ID'] = self.subject.subject_ID\n",
    "        df['group_ID'] = self.subject.group_ID\n",
    "        df['trialnumber'] = 1 #muss noch implementiert werden!\n",
    "        df['DateOfRecording'] = self.session.date\n",
    "        df['paradigm'] = self.session.paradigm\n",
    "        return df\n",
    "    \n",
    "    def get_master_df(self):\n",
    "        #combines all the information into a master_df as specified by col_in_precessed_df\n",
    "        d_for_master_df = {}\n",
    "\n",
    "        for key, col_in_processed_df in main.col_in_master_df:\n",
    "            d_for_master_df[key] = self.combined_df[col_in_processed_df].values\n",
    "\n",
    "        master_df = pd.DataFrame(data=d_for_master_df)\n",
    "        return master_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e4ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maze_corners(bottom_cam, top_cam):   \n",
    "    \"\"\"creates an object representing the maze_corners\"\"\"\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.cap = cv2.VideoCapture(self.filepath)\n",
    "        self.ret, self.frame = self.cap.read()\n",
    "        self.results = {}\n",
    "        \n",
    "        \n",
    "    def rotate(self, xy, theta):\n",
    "        cos_theta, sin_theta = math.cos(theta), math.sin(theta)\n",
    "\n",
    "        return (\n",
    "            xy[0] * cos_theta - xy[1] * sin_theta,\n",
    "            xy[0] * sin_theta + xy[1] * cos_theta\n",
    "        )\n",
    "\n",
    "    def translate(self, xy, offset):\n",
    "        return xy[0] + offset[0], xy[1] + offset[1]\n",
    "\n",
    "    def f(self, x, y, length, width, degrees):\n",
    "        offset = (x, y)\n",
    "        corners = [(0, 0), (width, 0), (width, length), (0, length)]\n",
    "        rotated_and_shifted_corners = [self.translate(self.rotate(xy, math.radians(degrees)), offset) for xy in corners]\n",
    "\n",
    "        end_right_corner = list(rotated_and_shifted_corners[0]) + ['red']\n",
    "        end_left_corner = list(rotated_and_shifted_corners[1]) + ['orange']\n",
    "        start_left_corner = list(rotated_and_shifted_corners[2]) + ['cyan']\n",
    "        start_right_corner = list(rotated_and_shifted_corners[3]) + ['green']\n",
    "\n",
    "        fig = plt.figure(figsize=(18, 10))\n",
    "        gs = fig.add_gridspec(2, 4)\n",
    "\n",
    "        fig.add_subplot(gs[0:2, 0:2])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.ylim(0,self.frame.shape[0])\n",
    "        plt.xlim(0,self.frame.shape[1])\n",
    "\n",
    "        if len(self.results.keys()) > 0:\n",
    "            saved_current = 'saved'\n",
    "        else:\n",
    "            saved_current = 'missing'\n",
    "\n",
    "        plt.title('current file: {} (analysis {})'.format(self.filepath, saved_current))\n",
    "\n",
    "        l_corners = [start_right_corner, start_left_corner, end_right_corner, end_left_corner]\n",
    "\n",
    "        for corner in l_corners:\n",
    "            plt.scatter(corner[0], corner[1], c=corner[2], s=100)\n",
    "\n",
    "        fig.add_subplot(gs[0, 2])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[0][0], l_corners[0][1], c=l_corners[0][2], s=100)\n",
    "        plt.xlim(l_corners[0][0]-25, l_corners[0][0]+25)\n",
    "        plt.ylim(l_corners[0][1]-25, l_corners[0][1]+25)\n",
    "        plt.title('start right corner')\n",
    "\n",
    "        fig.add_subplot(gs[0, 3])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[1][0], l_corners[1][1], c=l_corners[1][2], s=100)\n",
    "        plt.xlim(l_corners[1][0]-25, l_corners[1][0]+25)\n",
    "        plt.ylim(l_corners[1][1]-25, l_corners[1][1]+25)\n",
    "        plt.title('start left corner')\n",
    "\n",
    "        fig.add_subplot(gs[1, 2])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[2][0], l_corners[2][1], c=l_corners[2][2], s=100)\n",
    "        plt.xlim(l_corners[2][0]-25, l_corners[2][0]+25)\n",
    "        plt.ylim(l_corners[2][1]-25, l_corners[2][1]+25)\n",
    "        plt.title('end right corner')\n",
    "\n",
    "        fig.add_subplot(gs[1, 3])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[3][0], l_corners[3][1], c=l_corners[3][2], s=100)\n",
    "        plt.xlim(l_corners[3][0]-25, l_corners[3][0]+25)\n",
    "        plt.ylim(l_corners[3][1]-25, l_corners[3][1]+25)\n",
    "        plt.title('end left corner')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b694fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gui():\n",
    "    \"\"\"represents the GUI\"\"\"\n",
    "    main_tab = widgets.Tab()   \n",
    "    tab_index = -1\n",
    "    displayed = False\n",
    "    \n",
    "    class main_gui(main):\n",
    "        \"\"\"creates a main object as specified by the path input and recording modalities\"\"\"\n",
    "        def __init__(self):\n",
    "            self.path = \"\"\n",
    "            folder_select = widgets.Button(description=\"Select folder\", layout=widgets.Layout(width=\"auto\"))\n",
    "            folder_select.on_click(self.select_folder)\n",
    "            \n",
    "            select_recording_modalities = widgets.Label(value=\"Select recording modalities\", layout=widgets.Layout(width=\"auto\"))\n",
    "            self.bottom_cam_check = widgets.Checkbox(value=False, description='Bottom Cam', layout=widgets.Layout(width=\"auto\"))\n",
    "            self.top_cam_check = widgets.Checkbox(value=False, description='Top Cam', layout=widgets.Layout(width=\"auto\"))\n",
    "            self.side_cam_check = widgets.Checkbox(value=False, description='Side Cam', disabled = True, layout=widgets.Layout(width=\"auto\"))\n",
    "            \n",
    "            confirm_button = widgets.Button(description = \"Confirm Settings\", layout=widgets.Layout(width=\"auto\"))\n",
    "            confirm_button.on_click(self.confirm_settings)\n",
    "            \n",
    "            col0 = VBox([folder_select])\n",
    "            col1 = VBox([select_recording_modalities, self.bottom_cam_check, self.top_cam_check, self.side_cam_check])\n",
    "            col2 = VBox([confirm_button])\n",
    "            box = HBox([col0, col1, col2])\n",
    "            gui.main_tab.children = [box]\n",
    "            gui.tab_index += 1\n",
    "            gui.main_tab.set_title(gui.tab_index, \"General Settings\")\n",
    "            display(gui.main_tab)\n",
    "            gui.displayed = True\n",
    "            gui.main_tab.selected_index = gui.tab_index\n",
    "\n",
    "        def select_folder(self, b):\n",
    "            root = Tk()\n",
    "            root.withdraw()\n",
    "            root.call('wm', 'attributes', '.', '-topmost', True)\n",
    "            self.path = filedialog.askdirectory() + \"/\"\n",
    "            display(self.path)        \n",
    "            \n",
    "        def confirm_settings(self, b):\n",
    "            if self.path == \"\":\n",
    "                display(\"Set the path before continuing!\")\n",
    "            else:\n",
    "                gui.a = main(path = self.path, dict_cams_used= {\"bottom_cam\": self.bottom_cam_check.value, \"top_cam\": self.top_cam_check.value, \"side_cam\": self.side_cam_check.value}, gui=True)\n",
    "                gui.a.all_information_given()\n",
    "                if gui.a.all_files_there == True:\n",
    "                    gui.subject_gui()\n",
    "        \n",
    "    class subject_gui(main):\n",
    "        \"\"\"allows to allocate subjects to groups\"\"\"\n",
    "        def __init__(self):\n",
    "            self.num_of_groups_dropdown = widgets.Dropdown(options=[1, 2, 3, 4, 5, 6], value=2, description='Choose, how many groups you have in your dataset', layout=widgets.Layout(width=\"auto\"), style={'description_width': 'auto'})\n",
    "            confirm_groups_button = widgets.Button(description='Confirm number of groups', layout=widgets.Layout(width=\"auto\"))\n",
    "            confirm_groups_button.on_click(self.name_groups)\n",
    "            row0 = HBox([self.num_of_groups_dropdown, confirm_groups_button])\n",
    "            box = VBox([row0])\n",
    "            gui.main_tab.children += (box, ) \n",
    "            gui.tab_index += 1\n",
    "            gui.main_tab.set_title(gui.tab_index, \"Subjects to groups\")\n",
    "            gui.main_tab.selected_index = gui.tab_index\n",
    "            \n",
    "        def name_groups(self, b):\n",
    "            self.num_of_groups = self.num_of_groups_dropdown.value\n",
    "            self.l_group_texts = [widgets.Text(value = 'group {}'.format(n), description='Name of group {}'.format(n), layout=widgets.Layout(width=\"auto\"), style = {'description_width': 'auto'}) for n in range (self.num_of_groups)]\n",
    "            name_subjects_button = widgets.Button(description = \"Confirm name of the groups\", layout=widgets.Layout(width=\"auto\"))\n",
    "            name_subjects_button.on_click(self.subjects_to_groups)\n",
    "            box = HBox([VBox(self.l_group_texts), name_subjects_button])\n",
    "            gui.main_tab.children[gui.tab_index].children += (box,)\n",
    "\n",
    "            \n",
    "        def subjects_to_groups(self, b):\n",
    "            l_subject_label = [widgets.Label(value=subject.subject_ID, layout=widgets.Layout(width=\"auto\")) for subject in gui.a.l_subjects]\n",
    "            self.l_group_toggle_buttons = [widgets.ToggleButtons(options = [text.value for text in self.l_group_texts], layout=widgets.Layout(width=\"auto\")) for subject in range(len(gui.a.l_subjects))]\n",
    "            continue_button = widgets.Button(description = \"All subjects in the right group\", layout=widgets.Layout(width=\"auto\"))\n",
    "            continue_button.on_click(self.next_step)\n",
    "            col0 = VBox(l_subject_label)\n",
    "            col1 = VBox(self.l_group_toggle_buttons)\n",
    "            box = HBox([col0, col1, continue_button])\n",
    "            gui.main_tab.children[gui.tab_index].children += (box,)\n",
    "            \n",
    "        def next_step(self, b):\n",
    "            l_groups = [self.l_group_texts[n].value for n in range(len(self.l_group_texts))]\n",
    "            gui.a.subjects_to_groups({subject.subject_ID:self.l_group_toggle_buttons[n].value for subject, n in zip (gui.a.l_subjects, range(len(gui.a.l_subjects)))}, l_groups)\n",
    "            gui.a.get_maze_corners()\n",
    "        \n",
    "    class bc_gui(main):\n",
    "        def __init__(self):\n",
    "            #defish\n",
    "            pass\n",
    "    class tc_gui(main):\n",
    "        def __init__(self):\n",
    "            #?\n",
    "            pass\n",
    "    class sc_gui(main):\n",
    "        def __init__(self):\n",
    "            # stitch\n",
    "            pass\n",
    "            \n",
    "    class select_functions(main):\n",
    "        \"\"\"allows to select the target variables, that will be analysed\"\"\"\n",
    "        def __init__(self):\n",
    "            select_functions = widgets.Label(value=\"Select functions in which you're interested in\", layout=widgets.Layout(width=\"auto\"), style = {'description_width': 'auto'})\n",
    "            self.anxiety_check = widgets.Checkbox(value=False, description='Anxiety', layout=widgets.Layout(width=\"auto\"))\n",
    "            self.parkinson_check = widgets.Checkbox(value=False, description='Parkinson', layout=widgets.Layout(width=\"auto\"))\n",
    "            \n",
    "            self.l_checkboxes = [self.anxiety_check, self.parkinson_check]\n",
    "\n",
    "            confirm_selection_button = widgets.Button(description = \"Confirm Selection\", layout=widgets.Layout(width=\"auto\"))\n",
    "            confirm_selection_button.on_click(self.confirm_selection)\n",
    "\n",
    "            col0 = VBox([select_functions, self.anxiety_check, self.parkinson_check])\n",
    "            col1 = VBox([confirm_selection_button])\n",
    "            box = HBox([col0, col1])\n",
    "            gui.main_tab.children += (box, ) \n",
    "            gui.tab_index += 1\n",
    "            gui.main_tab.set_title(gui.tab_index, \"Select Functions\")\n",
    "            gui.main_tab.selected_index = gui.tab_index\n",
    "\n",
    "        def confirm_selection(self, b):\n",
    "            l_selected_functions_values = [checkbox.value for checkbox in self.l_checkboxes]\n",
    "            l_selected_functions_keys = [checkbox.description for checkbox in self.l_checkboxes]\n",
    "            dict_selected_functions = {key:value for key,value in zip(l_selected_functions_keys,l_selected_functions_values)}\n",
    "            gui.a.execute_functions(dict_selected_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bc658d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maze_corner_gui(main):\n",
    "    \"\"\"creates the GUI for annotation maze corners, used in GUI as well as GUI-less usage\"\"\"\n",
    "    def __init__(self):\n",
    "        self.maze_corner_idx = 0\n",
    "        self.actualize()\n",
    "        self.clean_df = False\n",
    "        self.create_gui()\n",
    "\n",
    "    def on_load_next_button_click(self, b):\n",
    "        if self.results_saved:\n",
    "            if self.maze_corner_idx >= (len(main.l_maze_corners)-1):\n",
    "                #check, whether all Maze Corners are saved to bc.mc.results\n",
    "                if self.clean_df == False:\n",
    "                    print(\"Maze Corners for all videos set.\")\n",
    "                    main.get_processed_dfs(main)\n",
    "                    self.clean_df = True\n",
    "                    print(\"Dataframes cleaned.\")\n",
    "                    if gui.tab_index > 0:\n",
    "                        gui.select_functions()\n",
    "                else: \n",
    "                    self.maze_corner_idx += 1\n",
    "                    self.actualize()\n",
    "        else:\n",
    "            display(\"Please save the settings before continuing!\")\n",
    "\n",
    "    def on_load_previous_button_click(self, b):\n",
    "        if self.maze_corner_idx <= 0:\n",
    "            display(\"Index out of range! Index has been set to 0.\")\n",
    "            self.maze_corner_idx = 0\n",
    "        else:\n",
    "            if self.results_saved:\n",
    "                self.maze_corner_idx -= 1\n",
    "                self.actualize()\n",
    "            else:\n",
    "                display(\"Please save the settings before continuing!\")\n",
    "\n",
    "    def actualize(self):\n",
    "        self.results_saved = False\n",
    "\n",
    "    def on_save_button_click(self, b):\n",
    "        main.l_maze_corners[self.maze_corner_idx].results[\"offset_x\"] = self.interactive_plot.children[0].value\n",
    "        main.l_maze_corners[self.maze_corner_idx].results[\"offset_y\"] = self.interactive_plot.children[1].value\n",
    "        main.l_maze_corners[self.maze_corner_idx].results[\"length\"] = self.interactive_plot.children[2].value\n",
    "        main.l_maze_corners[self.maze_corner_idx].results[\"width\"] = self.interactive_plot.children[3].value\n",
    "        main.l_maze_corners[self.maze_corner_idx].results[\"theta\"] = math.radians(self.interactive_plot.children[4].value)\n",
    "        self.results_saved = True\n",
    "\n",
    "    def create_gui(self):\n",
    "        width, height = main.l_maze_corners[self.maze_corner_idx].frame.shape[0], main.l_maze_corners[self.maze_corner_idx].frame.shape[1]#replace slider with int, since slider are very slow\n",
    "        slider_x = widgets.IntSlider(value=300, min=0, max=width, step=1, description='x offset', continuous_update=False)\n",
    "        slider_y = widgets.IntSlider(value=5, min=0, max=height, step=1, description='y offset', continuous_update=False)\n",
    "        slider_length = widgets.IntSlider(value=height/2, min=0, max=height*1.5, step=1, continuous_update=False)\n",
    "        slider_width = widgets.IntSlider(value=width/20, min=0, max=width/7, step=1, continuous_update=False)\n",
    "        slider_degrees = widgets.FloatSlider(value=0, min=0, max=90, step=0.1, continuous_update=False)\n",
    "\n",
    "        self.interactive_plot = interactive(main.l_maze_corners[self.maze_corner_idx].f, x=slider_x, y=slider_y, length=slider_length, width=slider_width, degrees=slider_degrees)\n",
    "\n",
    "        self.interactive_plot.children[-1].layout.height = '600px'\n",
    "\n",
    "        load_next_button = widgets.Button(description=\"Load next file\", style = {'description_width': 'auto'})\n",
    "        save_button = widgets.Button(description=\"Save settings\", style = {'description_width': 'auto'})\n",
    "        load_previous_button = widgets.Button(description=\"Load previous file\", style = {'description_width': 'auto'})\n",
    "\n",
    "        load_next_button.on_click(self.on_load_next_button_click)\n",
    "        load_previous_button.on_click(self.on_load_previous_button_click)\n",
    "        save_button.on_click(self.on_save_button_click)\n",
    "\n",
    "        col0 = VBox([load_next_button, save_button])\n",
    "        col1 = VBox([self.interactive_plot.children[0], self.interactive_plot.children[1]])\n",
    "        col2 = VBox([self.interactive_plot.children[2], self.interactive_plot.children[3]])\n",
    "        col3 = VBox([self.interactive_plot.children[4], load_previous_button])\n",
    "        row0 = HBox([col0, col1, col2, col3])\n",
    "        box = VBox([row0, self.interactive_plot.children[-1]])\n",
    "\n",
    "        gui.main_tab.children += (box, ) \n",
    "        gui.tab_index += 1\n",
    "        gui.main_tab.set_title(gui.tab_index, \"Set Maze Corners\")\n",
    "        gui.main_tab.selected_index = gui.tab_index\n",
    "    \n",
    "class stats_gui(main):\n",
    "    \"\"\"allows to choose and individualize the stats\"\"\"\n",
    "    output_path = \"\"\n",
    "\n",
    "    def __init__(self, dict_selected_functions):\n",
    "        self.dict_selected_functions = dict_selected_functions\n",
    "        self.select_stats_dropdown = widgets.RadioButtons(options=[\"basic\", \"all\", \"select\"], value=\"basic\", description = \"Choose, which statistics you want to plot\", layout=widgets.Layout(width=\"auto\"), style = {'description_width': 'auto'})\n",
    "\n",
    "        confirm_button = widgets.Button(description = \"Confirm\", layout=widgets.Layout(width=\"auto\"))\n",
    "        confirm_button.on_click(self.confirm)\n",
    "\n",
    "        enter_path = widgets.Button(description=\"Select output folder\", layout=widgets.Layout(width=\"auto\"))\n",
    "        enter_path.on_click(self.select_output_path)\n",
    "\n",
    "        select_ind_var_label = widgets.Label(value=\"Select independent variable\", layout=widgets.Layout(width=\"auto\"))\n",
    "        self.select_ind_variable = widgets.Dropdown(options = [\"group_ID\", \"trialnumber\", \"paradigm\"], layout=widgets.Layout(width=\"auto\"))\n",
    "        select_hue_label = widgets.Label(value=\"Select hue\", layout=widgets.Layout(width=\"auto\"))\n",
    "        self.select_hue = widgets.Dropdown(options = [\"subject_ID\", \"paradigm\", \"group_ID\"], layout=widgets.Layout(width=\"auto\"))\n",
    "\n",
    "        col0 = VBox([self.select_stats_dropdown, confirm_button])\n",
    "        col1 = VBox([select_ind_var_label, self.select_ind_variable])\n",
    "        col2 = VBox([select_hue_label, self.select_hue])\n",
    "        col3 = VBox ([enter_path])\n",
    "        row0 = HBox([col0, col1, col2, col3])\n",
    "        box = VBox([row0])\n",
    "        gui.main_tab.children += (box, ) \n",
    "        gui.tab_index += 1\n",
    "        gui.main_tab.set_title(gui.tab_index, \"Select Statistics\")\n",
    "        gui.main_tab.selected_index = gui.tab_index\n",
    "\n",
    "    def select_output_path(self, b):\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.call('wm', 'attributes', '.', '-topmost', True)\n",
    "        self.output_path = filedialog.askdirectory() + \"/\"\n",
    "        display(self.output_path)        \n",
    "\n",
    "    def confirm(self, b):\n",
    "        if self.select_stats_dropdown.value == \"select\":\n",
    "            self.select_data_col()\n",
    "        else:\n",
    "            if self.select_stats_dropdown.value == \"basic\":\n",
    "                self.l_selected_data_col = []\n",
    "                if self.dict_selected_functions[\"Anxiety\"]:\n",
    "                    self.l_selected_data_col.extend(['count_freezing_bouts', 'percentage_of_time_spent_freezing', 'mean_freezing_bouts_y_position'])\n",
    "                if self.dict_selected_functions[\"Parkinson\"]:\n",
    "                    self.l_selected_data_col.extend(['mean_gait_disruption_bouts_y_position_all'])\n",
    "            elif self.select_stats_dropdown.value == \"all\":\n",
    "                self.l_selected_data_col = [key for key in main.d_data.keys() if key not in set(['subject_ID', 'group_ID', 'paradigm', 'trialnumber'])]\n",
    "            l_selected_data_col_dict = []\n",
    "            for data_col in self.l_selected_data_col:\n",
    "                dict_stats = {}\n",
    "                dict_stats[\"data_col\"] = data_col\n",
    "                dict_stats[\"independent_variable\"] =  self.select_ind_variable.value\n",
    "                dict_stats[\"hue\"] =  self.select_hue.value\n",
    "                l_selected_data_col_dict.append(dict_stats)\n",
    "            main.calculate_stats(main, self.output_path, l_selected_data_col_dict)\n",
    "\n",
    "    def select_data_col(self):\n",
    "        confirm_button = widgets.Button(description = \"Confirm\", layout=widgets.Layout(width=\"auto\"))\n",
    "        confirm_button.on_click(self.confirm_selected_data_col)\n",
    "        select_data_key_label = widgets.Label(value=\"Select Data Column\", layout=widgets.Layout(width=\"auto\"))\n",
    "        select_ind_var_label = widgets.Label(value=\"Select independent variable\", layout=widgets.Layout(width=\"auto\"))\n",
    "        select_hue_label = widgets.Label(value=\"Select hue\", layout=widgets.Layout(width=\"auto\"))\n",
    "\n",
    "        l_grid_children = [select_data_key_label, select_ind_var_label, select_hue_label]\n",
    "        for key in main.d_data.keys(): \n",
    "            if key not in set(['subject_ID', 'group_ID', 'paradigm', 'trialnumber']):\n",
    "                l_grid_children.append(widgets.Checkbox(value=False, description=key, layout=widgets.Layout(width=\"auto\")))\n",
    "                l_grid_children.append(widgets.Dropdown(options = [\"group_ID\", \"trialnumber\", \"paradigm\"], value='group_ID', layout=widgets.Layout(width=\"auto\")))\n",
    "                l_grid_children.append(widgets.Dropdown(options = [\"subject_ID\", \"paradigm\", \"group_ID\"], value='subject_ID', layout=widgets.Layout(width=\"auto\")))\n",
    "\n",
    "        enter_path = widgets.Button(description=\"Select output folder\", layout=widgets.Layout(width=\"auto\"))\n",
    "        enter_path.on_click(self.select_output_path)\n",
    "\n",
    "        col3 = VBox([enter_path, confirm_button]) \n",
    "\n",
    "        self.grid = widgets.GridBox(l_grid_children, layout=widgets.Layout(grid_template_columns=\"repeat(3, auto)\"))\n",
    "\n",
    "        box = HBox([self.grid, col3])\n",
    "        gui.main_tab.children[gui.tab_index].children += (box,)\n",
    "        gui.main_tab.children[gui.tab_index].children[0].children = (gui.main_tab.children[gui.tab_index].children[0].children[0], )\n",
    "\n",
    "\n",
    "    def confirm_selected_data_col(self, b):\n",
    "        l_selected_data_col_dict = []\n",
    "        for n in range(len(self.grid.children)):\n",
    "            if n>2 & n%3 == 0:\n",
    "                if self.grid.children[n].value == True:\n",
    "                    dict_stats = {}\n",
    "                    dict_stats[\"data_col\"] = self.grid.children[n].description\n",
    "                    dict_stats[\"independent_variable\"] =  self.grid.children[n+1].value\n",
    "                    dict_stats[\"hue\"] =  self.grid.children[n+2].value\n",
    "                    l_selected_data_col_dict.append(dict_stats)\n",
    "        main.calculate_stats(main, self.output_path, l_selected_data_col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3ddf38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stats(main):\n",
    "    \"\"\"creates stats and output plots/.csv files as specified in the stats gui\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def position_stats(self, data_col, independent_variable, hue, output_path):\n",
    "        l_columns = ['group_ID', 'subject_ID', 'paradigm']\n",
    "\n",
    "        dataframe = main.dataframe.loc[:, [data_col] + l_columns]\n",
    "        dataframe.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        plt.figure(figsize=(7,9), facecolor='white')\n",
    "        \n",
    "        sns.violinplot(data=dataframe, y=\"paradigm\", x=data_col, fliersize=0, orient='h', hue=independent_variable)\n",
    "        sns.stripplot(data=dataframe, y=\"paradigm\", x=data_col, orient='h', color='k', hue=independent_variable, dodge=True, alpha=0.3)\n",
    "        plt.vlines(x=35, ymin=0.5, ymax=3.5, color='magenta', linestyle='dashed')\n",
    "\n",
    "        if output_path != \"\":\n",
    "            figname = 'differences between {} for {}.png'.format(data_col, independent_variable)\n",
    "            plt.savefig(output_path + figname, dpi=300)\n",
    "            csv_name = figname.replace('png', 'csv')\n",
    "            dataframe.to_csv(output_path + csv_name)\n",
    "    \n",
    "        plt.xlim(0, 75)\n",
    "        plt.legend(loc='center right')\n",
    "        plt.title(data_col + \" per \" + independent_variable)\n",
    "        plt.show()\n",
    "        #plt.close()\n",
    "        \n",
    "    def total_count_stats(self, data_col, independent_variable, hue, output_path):\n",
    "        l_columns = ['group_ID', 'subject_ID', 'paradigm']\n",
    "        \n",
    "        dataframe = main.dataframe.loc[:, [data_col] + l_columns].copy()\n",
    "        dataframe.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        plt.figure(figsize=(7,4), facecolor='white')\n",
    "        \n",
    "        sns.boxplot(data=dataframe, y=\"paradigm\", x=data_col, hue=independent_variable, fliersize=0)\n",
    "        sns.stripplot(data=dataframe, y=\"paradigm\", x=data_col, hue=independent_variable, dodge=True, color='k')\n",
    "        \n",
    "        if output_path != \"\":\n",
    "            figname = 'differences between {} for {}.png'.format(data_col, independent_variable)\n",
    "            plt.savefig(output_path + figname, dpi=300)\n",
    "            csv_name = figname.replace('png', 'csv')\n",
    "            dataframe.to_csv(output_path + csv_name)\n",
    "\n",
    "        plt.ylim(0)\n",
    "        plt.xlim(-0.5,5.5)\n",
    "        #plt.legend('')\n",
    "        plt.title(data_col + \" per \" + independent_variable)\n",
    "        plt.show()\n",
    "        #plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba47e9",
   "metadata": {},
   "source": [
    "Use GUI for the Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1e25349",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ef940daf0c422f866a2af1484694f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HBox(children=(VBox(children=(Button(description='Select folder', layout=Layout(width='auto'), s‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.gui.main_gui at 0x1ec1f746b20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'C:/Users/kobel/Documents/Medizin/Doktorarbeit/Coding/Dummy Data/'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maze Corners for all videos set.\n",
      "Dataframes cleaned.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gui.main_gui()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079d119a",
   "metadata": {},
   "source": [
    "GUI-less usage (as much as possible) of the Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b62177",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = main(path = \"C:/Users/kobel/Documents/Medizin/Doktorarbeit/Coding/Dummy Data/\", dict_cams_used = {\"bottom_cam\": False, \"top_cam\": True, \"side_cam\": False}, gui=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522191d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(project.l_subjects)):\n",
    "    print(project.l_subjects[i].subject_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2688748",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.subjects_to_groups({\"211_F1-86\": \"control\"}, [\"control\", \"experimental\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590dc383",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.execute_functions(dict_selected_functions = {\"Anxiety\": True, \"Parkinson\": True})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
