[
  {
    "objectID": "inspect.html",
    "href": "inspect.html",
    "title": "inspect",
    "section": "",
    "text": "Before starting with the example usage, let´s quickly define two helper functions that we will need:\n\nsource\n\n\n\n\n get_only_matching_xlsx_files (dir_path:pathlib.Path, paradigm_id:str,\n                               week_id:Optional[int]=None)\n\n\nsource\n\n\n\n\n get_metadata_from_filename (filepath_session_results:pathlib.Path,\n                             group_assignment_filepath:pathlib.Path)\n\n\n\n\nThis obviously assumes that you were using the gait_analysis package to analyze your 2D tracking data created the corresponding result exports. To get some quick insights into your data, feel free to use the following collection of functions.\nFirst, you need to provide the filepath to the exported Excel files as root_dir_path as a Path object (see exmaple below). You can also specify if you´d like to right away filter only for a certain set of weeks or paradigms (you can also just pass a list with a single value for each). Please note that you have to provide the exact name of the respective Excel Tab you are interested in as: sheet_name.\nNote: The group_assignment Excel Sheet is still quite customized & should be replaced by a more generalizable configs file (e.g. .yaml) in future versions.\n\nsource\n\n\n\n\n collect_all_available_data (root_dir_path:pathlib.Path,\n                             group_assignment_filepath:pathlib.Path,\n                             paradigm_ids:List[str], week_ids:List[str],\n                             sheet_name:str)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nroot_dir_path\nPath\nFilepath to the directory that contains the exported results .xlsx files\n\n\ngroup_assignment_filepath\nPath\nFilepath to the group_assignments.xlsx file\n\n\nparadigm_ids\ntyping.List[str]\nList of paradigms of which the results shall be loaded\n\n\nweek_ids\ntyping.List[str]\nList of weeks from which the results shall be loaded\n\n\nsheet_name\nstr\nTab name of the exported results sheet to load, e.g. “session_overview”\n\n\nReturns\nDataFrame\n\n\n\n\nFor instance, if you´d like to inspect the overall session overview, use:\ndf = collect_all_available_data(root_dir_path = Path('/path/to/your/directory/with/the/exported/retults/'),\n                                group_assignment_filepath = Path('/filepath/to/your/group_assignment.xlsx'),\n                                paradigm_ids = ['paradigm_a', 'paradigm_b', 'paradigm_c'],\n                                week_ids = [1, 4, 8, 12, 14],\n                                sheet_name = 'session_overview')\n\n\n\nYou might want to filter your data to only inspect a specific proportion of it. You can do so quite easily by using the filter_dataframe() funtion (see example usage below):\n\nsource\n\n\n\n\n filter_dataframe (df:pandas.core.frame.DataFrame,\n                   filter_criteria:List[Tuple])\n\nYou need to specify your filter criteria in a list of tuples, for which each tuple follows this schema: &gt; (column_name, comparison_method, reference_value)\nSo for instance, if you´d like to filter your dataframe by selecting only the data of all freezing bouts, you would add a tuple that specifies that you want all rows from the column “bout_type” that have the value “all_freezing_bouts”: &gt; ('bout_type', 'equal_to', 'all_freezing_bouts')\nYou can also add more criteria with additional tuples, for instance to filter for specific mouse lines your filter criteria would look like this: &gt; ('line_id', 'is_in_list', ['206', '209'])\nBringing it together, you´d define your filter_criteria in a list of these tuples:\nfilter_criteria = [('line_id', 'is_in_list', ['206', '209']),\n                   ('bout_type', 'equal_to', 'all_freezing_bouts')]\nYou can add as many tuples (= criteria) you´d like. Currently implemented comparison methods include: - “greater”: selects only rows in which the values of the column are greater than the reference value - “smaller”: selects only rows in which the values of the column are smaller than the reference value - “equal_to”: selects only rows in which the values of the column are equal to the reference value - “is_in_list”: selects only rows in which the values of the column are matching to an element in the reference value (which has to be a list, in this case) - “is_nan”: selects only rows in which the values of the column are NaN\nYou can then pass the filter_criteria along your dataframe to the filter_dataframe() function:\ndf_filtered = filter_dataframe(df = df, filter_criteria = filter_criteria)\n\n\n\nEventually, you can also plot your data, filtering it even more, if you´d like to. When you´re using the plot() function, you can specify the following parameters (see function documentation and example usage below):\n\nsource\n\n\n\n\n plot (df:pandas.core.frame.DataFrame, x_column:str, y_column:str,\n       plot_type:str='violinplot', hue_column:Optional[str]=None,\n       hide_legend:bool=True)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nthe DataFrame that contains the data you´d like to plot\n\n\nx_column\nstr\n\nthe column name of the data that should be visualized on the x-axis\n\n\ny_column\nstr\n\nthe column name of the data that should be visualized on the y-axis\n\n\nplot_type\nstr\nviolinplot\ncurrently only “violinplot” and “stripplot” are implemented\n\n\nhue_column\ntyping.Optional[str]\nNone\nif you´d like to use the data of a column to color-code the plotted, you can specify it here (see example below)\n\n\nhide_legend\nbool\nTrue\npass along as False if you´d like the legend of the plot to be displayed\n\n\nReturns\nNone\n\n\n\n\n\nplot(df = df_filtered, x_column = 'group_id', y_column = 'total_duration', hue_column = 'week_id')\nYou can also use the following function to create a DataFrame that gives you an overview of your data availability:\n\nsource\n\n\n\n\n check_data_availability (root_dir_path:pathlib.Path,\n                          all_week_ids:List[int],\n                          all_paradigm_ids:List[str])"
  },
  {
    "objectID": "inspect.html#example-usage",
    "href": "inspect.html#example-usage",
    "title": "inspect",
    "section": "",
    "text": "Before starting with the example usage, let´s quickly define two helper functions that we will need:\n\nsource\n\n\n\n\n get_only_matching_xlsx_files (dir_path:pathlib.Path, paradigm_id:str,\n                               week_id:Optional[int]=None)\n\n\nsource\n\n\n\n\n get_metadata_from_filename (filepath_session_results:pathlib.Path,\n                             group_assignment_filepath:pathlib.Path)\n\n\n\n\nThis obviously assumes that you were using the gait_analysis package to analyze your 2D tracking data created the corresponding result exports. To get some quick insights into your data, feel free to use the following collection of functions.\nFirst, you need to provide the filepath to the exported Excel files as root_dir_path as a Path object (see exmaple below). You can also specify if you´d like to right away filter only for a certain set of weeks or paradigms (you can also just pass a list with a single value for each). Please note that you have to provide the exact name of the respective Excel Tab you are interested in as: sheet_name.\nNote: The group_assignment Excel Sheet is still quite customized & should be replaced by a more generalizable configs file (e.g. .yaml) in future versions.\n\nsource\n\n\n\n\n collect_all_available_data (root_dir_path:pathlib.Path,\n                             group_assignment_filepath:pathlib.Path,\n                             paradigm_ids:List[str], week_ids:List[str],\n                             sheet_name:str)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nroot_dir_path\nPath\nFilepath to the directory that contains the exported results .xlsx files\n\n\ngroup_assignment_filepath\nPath\nFilepath to the group_assignments.xlsx file\n\n\nparadigm_ids\ntyping.List[str]\nList of paradigms of which the results shall be loaded\n\n\nweek_ids\ntyping.List[str]\nList of weeks from which the results shall be loaded\n\n\nsheet_name\nstr\nTab name of the exported results sheet to load, e.g. “session_overview”\n\n\nReturns\nDataFrame\n\n\n\n\nFor instance, if you´d like to inspect the overall session overview, use:\ndf = collect_all_available_data(root_dir_path = Path('/path/to/your/directory/with/the/exported/retults/'),\n                                group_assignment_filepath = Path('/filepath/to/your/group_assignment.xlsx'),\n                                paradigm_ids = ['paradigm_a', 'paradigm_b', 'paradigm_c'],\n                                week_ids = [1, 4, 8, 12, 14],\n                                sheet_name = 'session_overview')\n\n\n\nYou might want to filter your data to only inspect a specific proportion of it. You can do so quite easily by using the filter_dataframe() funtion (see example usage below):\n\nsource\n\n\n\n\n filter_dataframe (df:pandas.core.frame.DataFrame,\n                   filter_criteria:List[Tuple])\n\nYou need to specify your filter criteria in a list of tuples, for which each tuple follows this schema: &gt; (column_name, comparison_method, reference_value)\nSo for instance, if you´d like to filter your dataframe by selecting only the data of all freezing bouts, you would add a tuple that specifies that you want all rows from the column “bout_type” that have the value “all_freezing_bouts”: &gt; ('bout_type', 'equal_to', 'all_freezing_bouts')\nYou can also add more criteria with additional tuples, for instance to filter for specific mouse lines your filter criteria would look like this: &gt; ('line_id', 'is_in_list', ['206', '209'])\nBringing it together, you´d define your filter_criteria in a list of these tuples:\nfilter_criteria = [('line_id', 'is_in_list', ['206', '209']),\n                   ('bout_type', 'equal_to', 'all_freezing_bouts')]\nYou can add as many tuples (= criteria) you´d like. Currently implemented comparison methods include: - “greater”: selects only rows in which the values of the column are greater than the reference value - “smaller”: selects only rows in which the values of the column are smaller than the reference value - “equal_to”: selects only rows in which the values of the column are equal to the reference value - “is_in_list”: selects only rows in which the values of the column are matching to an element in the reference value (which has to be a list, in this case) - “is_nan”: selects only rows in which the values of the column are NaN\nYou can then pass the filter_criteria along your dataframe to the filter_dataframe() function:\ndf_filtered = filter_dataframe(df = df, filter_criteria = filter_criteria)\n\n\n\nEventually, you can also plot your data, filtering it even more, if you´d like to. When you´re using the plot() function, you can specify the following parameters (see function documentation and example usage below):\n\nsource\n\n\n\n\n plot (df:pandas.core.frame.DataFrame, x_column:str, y_column:str,\n       plot_type:str='violinplot', hue_column:Optional[str]=None,\n       hide_legend:bool=True)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nthe DataFrame that contains the data you´d like to plot\n\n\nx_column\nstr\n\nthe column name of the data that should be visualized on the x-axis\n\n\ny_column\nstr\n\nthe column name of the data that should be visualized on the y-axis\n\n\nplot_type\nstr\nviolinplot\ncurrently only “violinplot” and “stripplot” are implemented\n\n\nhue_column\ntyping.Optional[str]\nNone\nif you´d like to use the data of a column to color-code the plotted, you can specify it here (see example below)\n\n\nhide_legend\nbool\nTrue\npass along as False if you´d like the legend of the plot to be displayed\n\n\nReturns\nNone\n\n\n\n\n\nplot(df = df_filtered, x_column = 'group_id', y_column = 'total_duration', hue_column = 'week_id')\nYou can also use the following function to create a DataFrame that gives you an overview of your data availability:\n\nsource\n\n\n\n\n check_data_availability (root_dir_path:pathlib.Path,\n                          all_week_ids:List[int],\n                          all_paradigm_ids:List[str])"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nEventBout\n\n EventBout (event_type:str, event_id:int, start_idx:int, end_idx:int,\n            fps:int)\n\nAnalysis of the gait_analysis package is mainly composed of identifying different types of events and their combined analysis thereafter. This class represents the core interface for these analyses, as it bundles all relevant information of such events.\nAttributes: self.event_type(str): type of event (e.g. “freezing” or “gait”) self.event_id(int): index of the occurance of this event type in a recording in chronological order self.start_idx(int): frame index in which this event bout starts self.end_idx(int): frame index at which this event bout ends self.fps(int): frames-per-second of the recording self.duration(float): duration of the event bout in s\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nevent_type\nstr\ntype of event (e.g. “immobility” or “gait”)\n\n\nevent_id\nint\nevnt index (e.g. 0 for the first occurance of this event type in a recording)\n\n\nstart_idx\nint\nindex of the frame at which this event bout starts\n\n\nend_idx\nint\nindex of the frame at which this event bout ends\n\n\nfps\nint\nframes-per-second value of the corresponding video recording\n\n\nReturns\nNone\n\n\n\n\n\nsource\n\n\nTrackedRecording\n\n TrackedRecording (filepath:pathlib.Path, week_id:int)\n\nWhile the analysis depends mainly on the identification of EventBouts and their integrated analyses, TrackedRecordings are the data objects on which these events are identified. They are implemented here as an abstract base class, as they will require slightly different functionalities depending on whether a 2D or 3D tracking needs to be handled.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nfilepath\nPath\nthe filepath to the output of DLC (.h5 or .csv file)\n\n\nweek_id\nint\nthe experimental week post injection in which the recording was performed. Has to be an element of the self.valid_week_ids list\n\n\nReturns\nNone\n\n\n\n\n\nsource\n\n\nBodypart\n\n Bodypart (bodypart_id:str, df:pandas.core.frame.DataFrame, fps:int)\n\nBundles all information and functions needed to process the data of a single bodypart (i.e. marker id). Requires that the coordinates have already been normalized (translated & rotated) and converted to cm.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nbodypart_id\nstr\nThe ID of the bodypart, i.e. the marker_id\n\n\ndf\nDataFrame\nThe normalized (rotated & translated) & converted (in cm) DataFrame that holds the DLC tracking information about this marker\n\n\nfps\nint\nframes-per-second at which this recording was acquired\n\n\nReturns\nNone"
  },
  {
    "objectID": "twod_04_export.html",
    "href": "twod_04_export.html",
    "title": "twoD/export",
    "section": "",
    "text": "source\n\nexport_immobility_related_bouts\n\n export_immobility_related_bouts (df:pandas.core.frame.DataFrame,\n                                  event_type:str, framerate:float)\n\n\nsource\n\n\nget_all_bout_ids\n\n get_all_bout_ids (df:pandas.core.frame.DataFrame, event_type:str)\n\n\nsource\n\n\nget_bout_duration_per_bout_id\n\n get_bout_duration_per_bout_id (df:pandas.core.frame.DataFrame,\n                                event_type:str, event_ids:List[float])\n\n\nsource\n\n\nget_column_values_at_event_borders\n\n get_column_values_at_event_borders (df:pandas.core.frame.DataFrame,\n                                     event_type:str,\n                                     event_ids:List[float],\n                                     column_name:str)\n\n\nsource\n\n\nget_distance_covered_per_event\n\n get_distance_covered_per_event (df:pandas.core.frame.DataFrame,\n                                 event_type:str, event_ids:List[float],\n                                 marker_id:str)\n\n\nsource\n\n\nget_interval_start_and_end_time_per_event\n\n get_interval_start_and_end_time_per_event\n                                            (df:pandas.core.frame.DataFram\n                                            e, event_type:str,\n                                            event_ids:List[float],\n                                            framerate:float)\n\n\nsource\n\n\nexport_gait_related_bouts\n\n export_gait_related_bouts (df:pandas.core.frame.DataFrame,\n                            event_type:str, framerate:float)\n\n\nsource\n\n\ncreate_session_overview_df\n\n create_session_overview_df (dfs_to_export_with_individual_bout_dfs:Dict[s\n                             tr,pandas.core.frame.DataFrame])\n\n\nsource\n\n\nget_bout_id_splits_depending_on_direction\n\n get_bout_id_splits_depending_on_direction\n                                            (df:pandas.core.frame.DataFram\n                                            e)\n\n\nsource\n\n\nget_column_name_from_substring\n\n get_column_name_from_substring (all_columns:List[str], substring:str)\n\n\nsource\n\n\nadd_results_to_session_overview\n\n add_results_to_session_overview (session_overview:Dict,\n                                  df:pandas.core.frame.DataFrame,\n                                  event_type:str, event_prefix:str,\n                                  bout_ids:List[float])\n\n\nsource\n\n\ncreate_parameter_settings_df\n\n create_parameter_settings_df (logs:Dict)\n\n\nsource\n\n\nwrite_xlsx_file_to_disk\n\n write_xlsx_file_to_disk (base_output_filepath:pathlib.Path,\n                          dfs_to_export:Dict[str,pandas.core.frame.DataFra\n                          me])"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "gait analysis",
    "section": "",
    "text": "This package is currently being developed and subsequent updates will be published in this repository, following the principles of open development. Major achievments will be tagged in the GitHub releases. This project uses nbdev to develop, test, document, and publish its source code."
  },
  {
    "objectID": "index.html#project-status",
    "href": "index.html#project-status",
    "title": "gait analysis",
    "section": "Project status",
    "text": "Project status\nThe main goal of this project is to foster gait analysis of rodents using 3D tracking data as input. However, the project is still in a very initial state and the current implementation focuses solely on a very customized analysis of 2D tracking data. Future versions will gradually increase the implemented analysis methods and their generalizability."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "gait analysis",
    "section": "Install",
    "text": "Install\nSo far only tested for Linux (Ubuntu 20.04.5).\n\nconda:\nconda install -c dennis_segebarth gait_analysis\n\n\npip:\npip install gait_analysis"
  },
  {
    "objectID": "twod_03_detect.html",
    "href": "twod_03_detect.html",
    "title": "twoD/detect",
    "section": "",
    "text": "source\n\ncreate_behavior_df\n\n create_behavior_df (normalized_df:pandas.core.frame.DataFrame,\n                     bodyparts_to_include:List[str])\n\n\nsource\n\n\nadd_orientation_to_behavior_df\n\n add_orientation_to_behavior_df (behavior_df:pandas.core.frame.DataFrame,\n                                 all_bodyparts:Dict, bodyparts_for_directi\n                                 on_front_to_back:List[str])\n\n\nsource\n\n\nadd_immobility_based_on_several_bodyparts_to_behavior_df\n\n add_immobility_based_on_several_bodyparts_to_behavior_df\n                                                           (behavior_df:pa\n                                                           ndas.core.frame\n                                                           .DataFrame, all\n                                                           _bodyparts:Dict\n                                                           , bodyparts_cri\n                                                           tical_for_freez\n                                                           ing:List[str])\n\n\nsource\n\n\nget_immobility_related_events\n\n get_immobility_related_events (behavior_df:pandas.core.frame.DataFrame,\n                                fps:float, min_interval_duration:float,\n                                event_type:str)\n\n\nsource\n\n\ncreate_event_objects\n\n create_event_objects (interval_border_idxs:List[Tuple[int,int]], fps:int,\n                       event_type:str)\n\n\nsource\n\n\nadd_event_bouts_to_behavior_df\n\n add_event_bouts_to_behavior_df (behavior_df:pandas.core.frame.DataFrame,\n                                 event_type:str, events:List[gait_analysis\n                                 .core.EventBout])\n\n\nsource\n\n\nget_gait_events\n\n get_gait_events (all_bodyparts:Dict, fps:int,\n                  gait_min_rolling_speed:float, gait_min_duration:float)\n\n\nsource\n\n\nget_gait_disruption_events\n\n get_gait_disruption_events (behavior_df:pandas.core.frame.DataFrame,\n                             fps:int, gait_events:List[gait_analysis.core.\n                             EventBout],\n                             gait_disruption_max_time_to_immobility:float)\n\n\nsource\n\n\nget_interval_border_idxs_from_event_type_and_id\n\n get_interval_border_idxs_from_event_type_and_id\n                                                  (behavior_df:pandas.core\n                                                  .frame.DataFrame,\n                                                  event_type:str,\n                                                  event_id:int)"
  },
  {
    "objectID": "twod_00_utils.html",
    "href": "twod_00_utils.html",
    "title": "twoD/utils",
    "section": "",
    "text": "source\n\nprocess_all_dlc_tracking_h5s_with_default_settings\n\n process_all_dlc_tracking_h5s_with_default_settings\n                                                     (in_dir_path:pathlib.\n                                                     Path, out_dir_path:pa\n                                                     thlib.Path,\n                                                     week_id:int)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nin_dir_path\nPath\npath to the input directory which contains all DLC tracking data results\n\n\nout_dir_path\nPath\npath to the output directory where all processed results will be saved\n\n\nweek_id\nint\nnumber of weeks post injection\n\n\nReturns\nNone\n\n\n\n\n\nsource\n\n\nget_max_odd_n_frames_for_time_interval\n\n get_max_odd_n_frames_for_time_interval (fps:int, time_interval:0.5)\n\nFor the savgol_filter function of scipy - which will be used during preprocessing to smooth the data - you need an odd integer as the window_length parameter. This function helps to find the maximum odd number of frames that still fit within a specified time interval at a given fps.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nfps\nint\nframes per second of the recording\n\n\ntime_interval\n0.5\ndesired maximal time interval in seconds; default = 0.5 s\n\n\nReturns\nint\n\n\n\n\n\nsource\n\n\nget_column_names\n\n get_column_names (df:pandas.core.frame.DataFrame,\n                   column_identifiers:List[str],\n                   marker_ids:List[str]=['all'])\n\n\nsource\n\n\nget_interval_border_idxs\n\n get_interval_border_idxs (all_matching_idxs:numpy.ndarray,\n                           framerate:float,\n                           min_interval_duration:Optional[float]=None,\n                           max_interval_duration:Optional[float]=None)\n\n\nsource\n\n\ncompute_coverage\n\n compute_coverage (df:pandas.core.frame.DataFrame,\n                   critical_marker_ids:List[str],\n                   likelihood_threshold:float=0.5)\n\n\nsource\n\n\nget_idxs_where_all_markers_exceed_likelihood\n\n get_idxs_where_all_markers_exceed_likelihood\n                                               (df:pandas.core.frame.DataF\n                                               rame, marker_ids:List[str],\n                                               likelihood_threshold:float=\n                                               0.5)"
  },
  {
    "objectID": "twod_01_cam_interfaces.html",
    "href": "twod_01_cam_interfaces.html",
    "title": "twoD/cam_interfaces",
    "section": "",
    "text": "source\n\nTopTracked2DRecording\n\n TopTracked2DRecording (filepath:pathlib.Path, week_id:int)\n\nVery customized subclass of TrackedRecording that was designed to run the gait analysis on 2D tracking data obtained from a single camera with a top-down-view on the subject.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nfilepath\nPath\nthe filepath to the output of DLC (.h5 or .csv file)\n\n\nweek_id\nint\nthe experimental week post injection in which the recording was performed. Has to be an element of the self.valid_week_ids list\n\n\nReturns\nNone\n\n\n\n\n\nsource\n\n\nTopTracked2DRecording.preprocess_tracking\n\n TopTracked2DRecording.preprocess_tracking\n                                            (marker_ids_to_compute_coverag\n                                            e:List[str]=['TailBase',\n                                            'Snout'],\n                                            coverage_threshold:float=0.75,\n                                            max_seconds_to_interpolate:flo\n                                            at=0.5, likelihood_threshold:f\n                                            loat=0.5, marker_ids_to_comput\n                                            e_center_of_gravity:List[str]=\n                                            ['TailBase', 'Snout'], relativ\n                                            e_maze_normalization_error_tol\n                                            erance:float=0.25)\n\nInitiate the preprocessing of the DLC output tracking data. This includes smoothing, interpolation of small intervals with low likelihoods, and creation of additional markers, like a center of gravity. Furthermore, the code will identify the most reliable predicted position of the maze corners and evaluate, whether the reconstructed maze using these most reliable open corner positions yields a maze that is sufficiently similar to how the maze should look like (less than a specified relative error threshold). If it meets this criterion, it will use the open corner from there on to normalize the coordinate system. If not, it will compute everything just based on the closed corners. Either way, the coordinate system will be normalized to the closed left corner, applying rotation and shifting, and eventually convert the coordinates into cm values. As the very last step, self.bodyparts will be created - a dictionary that contains an Bodypart object for each marker id. Logs will save all parameters specified upon calling the function to make it easily traceable, which parameter settings were used to obtain a given result (see also the documentation of the export_results() method.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmarker_ids_to_compute_coverage\ntyping.List[str]\n[‘TailBase’, ‘Snout’]\nList of marker_ids on base of which the tracking coverage will be computed\n\n\ncoverage_threshold\nfloat\n0.75\nIf coverage of the above defined markers is lower than this threshold, the recording will be excluded from the analysis and therefore not further processed\n\n\nmax_seconds_to_interpolate\nfloat\n0.5\nMaximum time interval in which consecutive nan´s will be interpolated\n\n\nlikelihood_threshold\nfloat\n0.5\nMinimum prediction likelihood of DLC that is required to acceppt predicted marker position as valid\n\n\nmarker_ids_to_compute_center_of_gravity\ntyping.List[str]\n[‘TailBase’, ‘Snout’]\nmarker ids that will be used to compute the center of gravity\n\n\nrelative_maze_normalization_error_tolerance\nfloat\n0.25\nrelative error that is tolerated when estimating the maze position for normalizing it´s position\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nTopTracked2DRecording.run_event_detection\n\n TopTracked2DRecording.run_event_detection\n                                            (bodyparts_critical_for_freezi\n                                            ng:List[str]=['Snout',\n                                            'CenterOfGravity'], bodyparts_\n                                            for_direction_front_to_back:Li\n                                            st[str]=['Snout',\n                                            'CenterOfGravity'], immobility\n                                            _max_rolling_speed:float=2.0, \n                                            immobility_min_duration:float=\n                                            0.1, freezing_min_duration:flo\n                                            at=0.5, gait_min_rolling_speed\n                                            :float=3.0,\n                                            gait_min_duration:float=0.5, g\n                                            ait_disruption_max_time_to_imm\n                                            obility:float=0.15, bodyparts_\n                                            to_include_in_behavior_df=['Ce\n                                            nterOfGravity', 'Snout',\n                                            'TailBase'], merge_events_max_\n                                            inbetween_time:float=0.15)\n\nTrigger the detection of “immobility”, “freezing”, “gait”, and “gait disruption” events. All detected events will also be classified “towards open end” True / False, depending on whether the orientation of the mouse was towards the open end of the maze or not. For gait events, this classification will be based on the orientation at the very last frame, while the orientation at the very first frame will be used for all other events (“immobility”, “freezing”, and “gait disruption”). Since the specified parameters used for this step of the analysis are very crucial, they will be documented in the logs and exported once the export_results() method is called. Default parameter selection for immobility speed threshold & freezing minimum duration was based on: https://www.sciencedirect.com/science/article/pii/S0960982216306182\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nbodyparts_critical_for_freezing\ntyping.List[str]\n[‘Snout’, ‘CenterOfGravity’]\nList of marker_ids that need to be classified as “immobile” that the entire mouse is classified as immobile\n\n\nbodyparts_for_direction_front_to_back\ntyping.List[str]\n[‘Snout’, ‘CenterOfGravity’]\nList of exactly two markers_ids that will be used to determine the orientation of the mouse; order of the markers: front, back\n\n\nimmobility_max_rolling_speed\nfloat\n2.0\nA given bodypart will be classified as immobile in all frames, in which its rolling speed is less or equal to this value [cm per s]\n\n\nimmobility_min_duration\nfloat\n0.1\nAn immobility event will be created for each interval that exceeds this threshold [s] and in which all bodyparts_critical_for_freezing are classified as immobile\n\n\nfreezing_min_duration\nfloat\n0.5\nA freezing event will be created for each interval that meets or exceeds this threshold [s] and in which all bodyparts_critical_for_freezing are classified as immobile\n\n\ngait_min_rolling_speed\nfloat\n3.0\nFrames will be classified as gait if the center of gravity meets or exceeds this rolling speed threshold [cm per s]\n\n\ngait_min_duration\nfloat\n0.5\nA gait event will be created for each interval that meets or exceeds this threshold [s] and in which the movement of the center of gravitiy is classified as “gait”\n\n\ngait_disruption_max_time_to_immobility\nfloat\n0.15\nA gait-disruption event will be created if an “immobility” event is found within this time interval [s] after a “gait” event has ended\n\n\nbodyparts_to_include_in_behavior_df\nlist\n[‘CenterOfGravity’, ‘Snout’, ‘TailBase’]\nBodyparts that will be included in the behavior_df. Should include at least all bodyparts_critical_for_freezing, bodyparts_for_direction_front_to_back, and the center of gravity\n\n\nmerge_events_max_inbetween_time\nfloat\n0.15\nNot implemented yet;\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nTopTracked2DRecording.export_results\n\n TopTracked2DRecording.export_results (out_dir_path:pathlib.Path)\n\nCreates an .xlsx file the following tab names that contain the following information: - parameter_settings: The logged parameter settings that were passed (or used by default) during the processing.\n\nimmobility_bouts: Data that describe each individual immobility event that was detected.\nfreezing_bouts: Data that describe each individual freezing event that wes detected.\ngait_bouts: Data that describe each individual gait event that was detected.\ngait_discruption_bouts: Data that describe each individual gait disruption event that was detected.\nsession_overview: Data that summarizes all events of a given type (e.g. freezing) over the entire session. Events from a given type are also futher split according to the determined orientation and are thus always given as “towards_open_”, “towards_closed_”, or as “all_” (e.g. “all_freezing_bouts”, or “towards_open_gait_events”).\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nout_dir_path\nPath\nFilepath to the directory where the results shall be saved\n\n\nReturns\nNone\n\n\n\n\n\nsource\n\n\nTopTracked2DRecording.inspect_processing\n\n TopTracked2DRecording.inspect_processing\n                                           (marker_ids_to_inspect:List[str\n                                           ]=['CenterOfGravity'],\n                                           verbose:bool=False,\n                                           show_plot:bool=False,\n                                           save_plot:bool=True,\n                                           show_legend:bool=False)\n\nSince the normalization of the maze during the preprocessing is a very critical step, this functions allows the user to visually inspect the success of this step at a glanze. It will plot a schematic of how the maze is expected to look like in form of a black box. It will then also plot the “most reliable” estimate of the four maze corners after normalization and the valid tracking positions of all markers specified in marker_ids_to_inspect. To avoid over- loading of this plot, we recommend to pass only a single marker id, for instance the “CenterOfGravity”. If you´d like to see some additional details, consider passing “verbose = True” and/or “show_legend = True”. Note: The filepath where the plots will be saved cannot be changed & they will always be saved in the same directory that was specified when calling the export_results() method, to ensure that they are saved in the same folder as the .xlsx files that contain logged parameter settings.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmarker_ids_to_inspect\ntyping.List[str]\n[‘CenterOfGravity’]\nList of marker ids whose tracked position shall be plotted as scatter plot\n\n\nverbose\nbool\nFalse\nWhether current progress and additional details like the coverages for each marker defined in marker_ids_to_inspect shall be printed\n\n\nshow_plot\nbool\nFalse\nWhether the created plot shall be displayed in the jupyter notebook\n\n\nsave_plot\nbool\nTrue\nWhether the created plot shall be saved (per default, it will be saved in the save directory that was specified when export_results() was called)\n\n\nshow_legend\nbool\nFalse\nWhether a legend shall be added to the plot or not\n\n\nReturns\nNone"
  },
  {
    "objectID": "twod_02_preprocess.html",
    "href": "twod_02_preprocess.html",
    "title": "twoD/preprocess",
    "section": "",
    "text": "source\n\nget_preprocessing_relevant_marker_ids\n\n get_preprocessing_relevant_marker_ids (df:pandas.core.frame.DataFrame,\n                                        marker_ids_to_exclude:Optional[Lis\n                                        t[str]]=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nDataFrame with x, y, and likelihood for tracked marker_ids\n\n\nmarker_ids_to_exclude\ntyping.Optional[typing.List[str]]\nNone\nlist of marker_ids to exclude; optional default None\n\n\nReturns\ntyping.List[str]\n\n\n\n\n\n\nsource\n\n\nget_all_unique_marker_ids\n\n get_all_unique_marker_ids (df:pandas.core.frame.DataFrame)\n\n\nsource\n\n\nsmooth_tracked_coords_and_likelihood\n\n smooth_tracked_coords_and_likelihood (df:pandas.core.frame.DataFrame,\n                                       window_length:int,\n                                       marker_ids:List[str]=['all'],\n                                       polyorder:int=3)\n\nSmoothes the DataFrame basically using the implementation from DLC2kinematics: https://github.com/AdaptiveMotorControlLab/DLC2Kinematics/blob/82e7e60e00e0efb3c51e024c05a5640c91032026/src/dlc2kinematics/preprocess.py#L64 However, with one key change: likelihoods will also be smoothed. In addition, we will not smooth the columns for the tracked LEDs and the MazeCorners.\nNote: window_length has to be an odd integer!\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nDataFrame to smooth\n\n\nwindow_length\nint\n\nOdd integer (!) of sliding window size in frames to consider for smoothing\n\n\nmarker_ids\ntyping.List[str]\n[‘all’]\nList of markers that will be smoothed; optional default [‘all’] to smooth all marker_ids\n\n\npolyorder\nint\n3\nOrder of the polynom used for the savgol filter\n\n\nReturns\nDataFrame\n\n\n\n\n\n\nsource\n\n\ninterpolate_low_likelihood_intervals\n\n interpolate_low_likelihood_intervals (df:pandas.core.frame.DataFrame,\n                                       marker_ids:List[str],\n                                       max_interval_length:int,\n                                       framerate:float)\n\n\nsource\n\n\nget_low_likelihood_interval_border_idxs\n\n get_low_likelihood_interval_border_idxs\n                                          (likelihood_series:pandas.core.s\n                                          eries.Series, framerate:float,\n                                          max_interval_length:int, min_lik\n                                          elihood_threshold:float=0.5)\n\n\nsource\n\n\nadd_new_marker_derived_from_existing_markers\n\n add_new_marker_derived_from_existing_markers\n                                               (df:pandas.core.frame.DataF\n                                               rame,\n                                               existing_markers:List[str],\n                                               new_marker_id:str, likeliho\n                                               od_threshold:float=0.5)\n\n\nsource\n\n\nget_corner_coords_with_likelihoods\n\n get_corner_coords_with_likelihoods (df:pandas.core.frame.DataFrame)\n\n\nsource\n\n\nget_most_reliable_marker_position_with_likelihood\n\n get_most_reliable_marker_position_with_likelihood\n                                                    (df:pandas.core.frame.\n                                                    DataFrame,\n                                                    marker_id:str, percent\n                                                    ile:float=99.95)\n\n\nsource\n\n\nget_translation_vector\n\n get_translation_vector (coords_to_become_origin:numpy.ndarray)\n\n\nsource\n\n\nevaluate_maze_shape_using_open_corners\n\n evaluate_maze_shape_using_open_corners (corners_and_likelihoods:Dict,\n                                         tolerance:float)\n\n\nsource\n\n\ncompute_error_proportion\n\n compute_error_proportion (query_value:float, target_value:float)\n\n\nsource\n\n\ncompute_angle_error\n\n compute_angle_error (a:numpy.ndarray, b:numpy.ndarray, c:numpy.ndarray)\n\n\nsource\n\n\ncompute_distance_ratio_error\n\n compute_distance_ratio_error (corners_and_likelihoods:Dict,\n                               open_corner_marker_id:str, side_id:str)\n\n\nsource\n\n\nget_distance_between_two_points\n\n get_distance_between_two_points (coords_point_a:numpy.ndarray,\n                                  coords_point_b:numpy.ndarray)\n\n\nsource\n\n\nget_conversion_factor_px_to_cm\n\n get_conversion_factor_px_to_cm (coords_point_a:numpy.ndarray,\n                                 coords_point_b:numpy.ndarray,\n                                 distance_in_cm:float)\n\n\nsource\n\n\nget_rotation_angle_with_open_corner\n\n get_rotation_angle_with_open_corner (corners:Dict, side_id:str,\n                                      translation_vector:numpy.ndarray,\n                                      conversion_factor:float)\n\nFunction, that calculates the rotation angle of the maze considering the best matching open corner and the corresponding closed corner on the same side.\nReturns: float: angle in radians\n\nsource\n\n\nget_rotation_angle_with_closed_corners_only\n\n get_rotation_angle_with_closed_corners_only (corners:Dict,\n                                              translation_vector:numpy.nda\n                                              rray,\n                                              conversion_factor:float)\n\n\nsource\n\n\nnormalize_df\n\n normalize_df (df:pandas.core.frame.DataFrame, normalization_parameters)\n\n\nsource\n\n\ntranslate_df\n\n translate_df (df:pandas.core.frame.DataFrame, translation_vector:&lt;built-\n               infunctionarray&gt;)\n\n\nsource\n\n\nrotate_df\n\n rotate_df (df:pandas.core.frame.DataFrame, rotation_angle:float)\n\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nDataFrame with 2D coordinates to be rotated\n\n\nrotation_angle\nfloat\nrotation angle in radians\n\n\nReturns\nDataFrame\n\n\n\n\n\nsource\n\n\nconvert_df_to_cm\n\n convert_df_to_cm (df:pandas.core.frame.DataFrame,\n                   conversion_factor:float)\n\n\nsource\n\n\ncreate_bodypart_objects\n\n create_bodypart_objects (normalized_df:pandas.core.frame.DataFrame,\n                          fps:int)"
  }
]