{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386ef0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from abc import ABC, abstractmethod\n",
    "import pickle\n",
    "from skimage.feature import match_template\n",
    "\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "from skimage.io import imshow, imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28254aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "path220824 = 'C:\\\\Users\\\\MS\\\\Documents\\\\Studium\\\\OpeningTrack\\\\coding\\\\test_data\\\\positions\\\\220824\\\\'\n",
    "path220825 = 'C:\\\\Users\\\\MS\\\\Documents\\\\Studium\\\\OpeningTrack\\\\coding\\\\test_data\\\\positions\\\\220825\\\\'\n",
    "path220826 = 'C:\\\\Users\\\\MS\\\\Documents\\\\Studium\\\\OpeningTrack\\\\coding\\\\test_data\\\\positions\\\\220826\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d527a3f",
   "metadata": {},
   "source": [
    "list of template for each cam --> dict form\n",
    "naming convention: YY/MM/DD_CamID_object-to-match_level_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "480e1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming for positions jpg: YY/MM/DD_Positions_CamID.jpg\n",
    "# naming for template jpg: YY/MM/DD_CamID_ObjectToFind_level1_template.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17fd9b",
   "metadata": {},
   "source": [
    "##  1) using only open cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9018af0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TemplateMatching(ABC):\n",
    "    \"\"\"\n",
    "    input: directory of positions jpg for template matching (e.g. 'C:\\\\user\\\\MS\\\\MouseData\\\\positions220831\\\\')\n",
    "            optional input: visualize_matching = Bool -> shows each plot for template matching\n",
    "    output: dictionary{ camera: {object: coordinates}}, naming of the file: \"results_template_matching.pickle\"\n",
    "    \n",
    "    commands:\n",
    "    \n",
    "    TemplateMatching.run(filepath)\n",
    "        performing template matching. results found in \"results_template_matching.pickle\" and\n",
    "        TemplateMatching.object_coordinates_per_camera\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def template_directory(self) ->str:\n",
    "        # specifies the directory for originally used templates\n",
    "        return r\"C:\\\\Users\\\\MS\\\\Documents\\\\Studium\\\\OpeningTrack\\\\coding\\\\test_data\\\\templates_obj\\\\\"\n",
    "    \n",
    "    @property\n",
    "    def template_naming(self) ->str:\n",
    "        # specifies the naming of the templates\n",
    "        return 'template.jpg'\n",
    "    \n",
    "    @property\n",
    "    def matching_naming(self) -> str:\n",
    "        # specifies the naming of the jpgs to be matched\n",
    "        return 'Positions.jpg'\n",
    "    \n",
    "    @property\n",
    "    def template_matching_threshold(self) ->str:\n",
    "        return 0.95\n",
    "    \n",
    "    @property\n",
    "    def all_cameras(self) ->str:\n",
    "        return ['Bottom', 'Side1', 'Side2', 'Ground1', 'Ground2', 'Top']\n",
    "    \n",
    "    def __init__(self, directory_positions_jpg: str, visualize_matching = False):\n",
    "        \n",
    "        # set path positions.jpgs from input\n",
    "        self.directory_positions_jpg = directory_positions_jpg\n",
    "        self.tm_methods = [cv2.TM_CCOEFF_NORMED, cv2.TM_CCORR_NORMED, cv2.TM_SQDIFF_NORMED]\n",
    "        self.visualize_matching = visualize_matching\n",
    "        \n",
    "        \n",
    "    def run(self) -> dict:    \n",
    "        # create dictionary with {camera: imagepath}\n",
    "        self.cameras_and_paths_positions = self._create_cameras_and_paths_dictionary(self.directory_positions_jpg, \n",
    "                                                                                     self.matching_naming)\n",
    "        print('The following cameras have been found:',self.cameras_and_paths_positions.keys())\n",
    "\n",
    "        # create dictionary {camera: {object: {level: templatepath}}}   \n",
    "        self.cameras_and_paths_template = self._create_cameras_and_paths_dictionary(self.template_directory,\n",
    "                                                                                    self.template_naming)\n",
    "        \n",
    "        # create results dictionary {camera: {(object: x-coordinate, y-coordinate)}}\n",
    "        self.object_coordinates_per_camera = {}\n",
    "        \n",
    "        # main loop    \n",
    "        for camera in self.cameras_and_paths_positions.keys():\n",
    "            \n",
    "            \n",
    "            self.object_coordinates_per_camera[camera] = {}\n",
    "            \n",
    "            # load image\n",
    "            original_image = cv2.imread(self.cameras_and_paths_positions[camera], 0)\n",
    "            \n",
    "            \n",
    "            for object_of_interest in self.cameras_and_paths_template[camera].keys():\n",
    "                \n",
    "                \n",
    "                print('Now working on ', camera, object_of_interest)\n",
    "                \n",
    "                # level 1\n",
    "                image = original_image.copy()\n",
    "                template, location = self._iterate_template_matching(camera = camera, image = image,\n",
    "                                                                     level = str(1), object_of_interest = object_of_interest)\n",
    "\n",
    "                # level 2\n",
    "                ofset = location\n",
    "                image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                template, location = self._iterate_template_matching(image = image, camera = camera,\n",
    "                                                                     level = str(2), object_of_interest = object_of_interest)\n",
    "\n",
    "                \n",
    "                if '3' not in self.cameras_and_paths_template[camera][object_of_interest].keys():\n",
    "                    # save results in self.object_coordinates_per_camera\n",
    "                    coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                    transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                    self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "\n",
    "                else:\n",
    "                    # level 3\n",
    "                    ofset = (ofset[0] + location[0], ofset[1]+location[1])\n",
    "                    image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                    template, location = self._iterate_template_matching(image = image, camera = camera, \n",
    "                                                                         level = str(3), object_of_interest = object_of_interest)\n",
    "                    if '4'not in self.cameras_and_paths_template[camera][object_of_interest].keys():\n",
    "                        # save results in f.object_coordinates_per_camera\n",
    "                        coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                        transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                        self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "                        \n",
    "                    else:\n",
    "                        # level 4\n",
    "                        ofset = (ofset[0] + location[0], ofset[1]+location[1])\n",
    "                        image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                        template, location = self._iterate_template_matching(image = image, camera = camera, \n",
    "                                                                         level = str(4), object_of_interest = object_of_interest)\n",
    "                        coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                        transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                        self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "                        \n",
    "        \n",
    "        # saving self.object_coordinates_per_camera as object_coordinates.pickle\n",
    "        with open(self.directory_positions_jpg + 'results_template_matching.pickle', 'wb') as f:\n",
    "            pickle.dump(self.object_coordinates_per_camera, f, pickle.HIGHEST_PROTOCOL)\n",
    "  \n",
    "        \n",
    "    def _create_cameras_and_paths_dictionary(self, path: str, naming_flag: str) -> dict:\n",
    "        # create a dictionary for easy file loading\n",
    "        \n",
    "        filepaths = [path + elem for elem in os.listdir(path) if elem.endswith(naming_flag)]\n",
    "        \n",
    "        \n",
    "        # templates\n",
    "        if 'level' in filepaths[0]:\n",
    "            files = {}\n",
    "            cameras = []\n",
    "            for filepath in filepaths:\n",
    "                if filepath.endswith(naming_flag):\n",
    "                    split_name = filepath.split(\"_\")\n",
    "                    camera, objecttofind, level = split_name[-4], split_name[-3], split_name[-2]\n",
    "                    cameras.append(camera)\n",
    "                    #objects.append(objecttofind)\n",
    "                    #levels.append(level)\n",
    "            for cam in cameras:\n",
    "                files[cam] = {}\n",
    "                objectstofind = [elem[elem.index(cam)+len(cam)+1:elem.index('_level')] for\n",
    "                                      elem in os.listdir(path) if cam in elem and elem.endswith(naming_flag)]\n",
    "                for objecttofind in objectstofind:\n",
    "                    files[cam][objecttofind] = {}             \n",
    "                    cam_filepaths = [elem for elem in filepaths if cam in elem and str(objecttofind) in elem]\n",
    "                    levels = [elem[elem.index('level')+5:elem.index('level')+6] for elem in os.listdir(path) \n",
    "                              if cam in elem and str(objecttofind) in elem and elem.endswith(naming_flag)]\n",
    "                    for i in range(len(levels)):\n",
    "                        files[cam][objecttofind].update({levels[i]: cam_filepaths[i]})\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            return files\n",
    "        \n",
    "        # images\n",
    "        else:\n",
    "            # list comprehension for getting cameras\n",
    "            cameras = [elem[7:(elem.index(naming_flag)-1)] for elem in os.listdir(path) if elem.endswith(naming_flag)]\n",
    "            return dict(zip(cameras, filepaths)) \n",
    "                                 \n",
    "    def _iterate_template_matching(self, camera: str, image: str, level: str, object_of_interest: str) -> (str, (int, int)):\n",
    "        # use template matching function to perform template matching for each level\n",
    "        \n",
    "        self.template_matched = False\n",
    "        template = cv2.imread(self.cameras_and_paths_template[camera][object_of_interest][level], 0)\n",
    "        \n",
    "        accuracies_and_locations = {}\n",
    "        \n",
    "        for method in self.tm_methods:\n",
    "            # test different template matching methods and select the best one\n",
    "            accuracy, location = self._match_template(image, template, method)\n",
    "            accuracies_and_locations[accuracy] = location\n",
    "        best_accuracy = max(accuracies_and_locations.keys())\n",
    "        self._evaluate_template_matching(best_accuracy)\n",
    "            \n",
    "        if self.template_matched:\n",
    "            # optional: visualize template matching \n",
    "            if self.visualize_matching:\n",
    "                self._visualize_template_matching(image, template, location = accuracies_and_locations[best_accuracy])\n",
    "            return template, location\n",
    "                    \n",
    "        if self.template_matched == False:\n",
    "            print('template is not fit for template matching! Use .create_template to create a new template for this object:', object_of_interest, camera)\n",
    "            self.template_matching_ongoing = False\n",
    "    \n",
    "    \n",
    "    def _match_template(self, image: str, template: str, method: str) -> (int, (int, int)):\n",
    "        # matches template to image and returns accuracy and location of top left corner \n",
    "        img = image.copy()\n",
    "        result = cv2.matchTemplate(image = img, templ = template, method = method)\n",
    "        min_value, max_value, min_location, max_location = cv2.minMaxLoc(result)\n",
    "        \n",
    "        if method == cv2.TM_SQDIFF_NORMED:\n",
    "            # the normed-/sqdiff methods have the position of the matched template in the min location\n",
    "            location = min_location\n",
    "            value = min_value\n",
    "            accuracy = 1-abs(0-value)\n",
    "        else:\n",
    "            # All other methods show the matched template position in the max location\n",
    "            location = max_location\n",
    "            value = max_value\n",
    "            accuracy = value\n",
    "        return  accuracy, location\n",
    "        \n",
    "        \n",
    "    def _visualize_template_matching(self, image: str, template: str, location: (int)):\n",
    "        height_template, width_template = template.shape\n",
    "        bottom_right_corner = (location[0] + width_template, location[1] + height_template)\n",
    "        cv2.rectangle(image, location, bottom_right_corner, color = 0)\n",
    "        cv2.imshow('Template Matched Image', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows\n",
    "        \n",
    "    def _evaluate_template_matching(self, accuracy: int) -> bool:\n",
    "        if accuracy > self.template_matching_threshold:\n",
    "            print('Template matching worked with a ' + str(accuracy) + ' accuracy')\n",
    "            self.template_matched = True\n",
    "        else:\n",
    "             print('Template matching is not ideal, now trying a different method!')\n",
    "    \n",
    "    def _get_mean_coordinates(self, image: str, template: str, location: (int, int)) ->(int, int):\n",
    "        # get coordinates for input image\n",
    "        height_template, width_template = template.shape\n",
    "        center_coordinates =location[0] + width_template/2, location[1] + height_template/2        \n",
    "        return center_coordinates\n",
    "    \n",
    "    def _transpose_coordinates(self, coordinates: (int, int), ofset: (int, int)) ->(int, int):\n",
    "        # transpose coordinates from image slice to original image\n",
    "        return (coordinates[0] + ofset[0], coordinates[1] + ofset[1])\n",
    "    \n",
    "    def _check_whether_analyzed(self):\n",
    "        # Check for pickle file --> has this data already been analyzed? CURRENTLY NON FUNCTIONAL\n",
    "        file_exists = os.path.exists(self.directory_positions_jpg + 'object_coordinates.pickle')\n",
    "        if file_exists:            \n",
    "            inputquesiton = input('This data has already been analysed! \\n\\\n",
    "            Do you really want to reanalyse the data? This would overwrite the old coordinates\\\n",
    "            type \"yes\" or \"no\"')\n",
    "            if inputquesiton:\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea2ead22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following cameras have been found: dict_keys(['Bottom', 'Ground2', 'Side1'])\n",
      "Now working on  Bottom screw1\n",
      "Template matching worked with a 0.9713526964187622 accuracy\n",
      "Template matching worked with a 0.9894607067108154 accuracy\n",
      "Template matching worked with a 0.9960360527038574 accuracy\n",
      "Now working on  Bottom screw2\n",
      "Template matching worked with a 0.9713526964187622 accuracy\n",
      "Template matching worked with a 0.9894607067108154 accuracy\n",
      "Template matching worked with a 0.9957596659660339 accuracy\n",
      "Now working on  Ground2 backcornerleft\n",
      "Template matching worked with a 0.9999387860298157 accuracy\n",
      "Template matching worked with a 0.9998504519462585 accuracy\n",
      "Template matching worked with a 0.9984613656997681 accuracy\n",
      "Now working on  Ground2 screw4\n",
      "Template matching worked with a 0.9999405145645142 accuracy\n",
      "Template matching worked with a 0.9998789429664612 accuracy\n",
      "Template matching worked with a 0.999656081199646 accuracy\n",
      "Now working on  Side1 nut\n",
      "Template matching worked with a 0.9999651312828064 accuracy\n",
      "Template matching worked with a 0.9999403357505798 accuracy\n",
      "Template matching worked with a 0.9983139038085938 accuracy\n",
      "Now working on  Side1 screw2\n",
      "Template matching worked with a 0.9999651312828064 accuracy\n",
      "Template matching worked with a 0.9999300241470337 accuracy\n",
      "Template matching worked with a 0.9997861385345459 accuracy\n",
      "Template matching worked with a 0.9995020031929016 accuracy\n",
      "The following cameras have been found: dict_keys(['Bottom', 'Ground1', 'Side2'])\n",
      "Now working on  Bottom screw1\n",
      "Template matching worked with a 0.9999613761901855 accuracy\n",
      "Template matching worked with a 0.9999275803565979 accuracy\n",
      "Template matching worked with a 0.9998486042022705 accuracy\n",
      "Now working on  Bottom screw2\n",
      "Template matching worked with a 0.9999613761901855 accuracy\n",
      "Template matching worked with a 0.9999275803565979 accuracy\n",
      "Template matching worked with a 0.9997097849845886 accuracy\n",
      "Now working on  Ground1 nut\n",
      "Template matching worked with a 0.9633011221885681 accuracy\n",
      "Template matching worked with a 0.9742250442504883 accuracy\n",
      "Template matching worked with a 0.9744579195976257 accuracy\n",
      "Template matching worked with a 0.9619134068489075 accuracy\n",
      "Now working on  Side2 screw1\n",
      "Template matching worked with a 0.9849935173988342 accuracy\n",
      "Template matching worked with a 0.9999860525131226 accuracy\n",
      "Template matching worked with a 0.9999584555625916 accuracy\n",
      "Template matching worked with a 0.9994745850563049 accuracy\n",
      "The following cameras have been found: dict_keys(['Ground1', 'Side2'])\n",
      "Now working on  Ground1 nut\n",
      "Template matching worked with a 0.9999132752418518 accuracy\n",
      "Template matching worked with a 0.9998708963394165 accuracy\n",
      "Template matching worked with a 0.999844491481781 accuracy\n",
      "Template matching worked with a 0.9986979961395264 accuracy\n",
      "Now working on  Side2 screw1\n",
      "Template matching worked with a 0.9999734163284302 accuracy\n",
      "Template matching worked with a 0.9871295690536499 accuracy\n",
      "Template matching worked with a 0.9858168363571167 accuracy\n",
      "Template matching worked with a 0.9646415710449219 accuracy\n"
     ]
    }
   ],
   "source": [
    "day220824 = TemplateMatching(path220824, visualize_matching= False)\n",
    "day220825 = TemplateMatching(path220825)\n",
    "day220826 = TemplateMatching(path220826)\n",
    "\n",
    "day220824.run()\n",
    "day220825.run()\n",
    "day220826.run()\n",
    "\n",
    "for day in [day220824, day220825, day220826]:\n",
    "    for cam in day.object_coordinates_per_camera.keys():\n",
    "        for obj in day.object_coordinates_per_camera[cam].keys():\n",
    "            image_temp = cv2.imread(day.cameras_and_paths_positions[cam])\n",
    "            coord1 = int(day.object_coordinates_per_camera[cam][obj][0])\n",
    "            coord2 = int(day.object_coordinates_per_camera[cam][obj][1])\n",
    "            cv2.circle(image_temp, (coord1, coord2), 2, (0,0,255), -1)\n",
    "            cv2.imshow('Sanity check for ' + str(cam) + ' ' + str(obj), image_temp)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec905631",
   "metadata": {},
   "source": [
    "## 2) using only scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21cbc9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemplateMatching(ABC):\n",
    "    \"\"\"\n",
    "    input: directory of positions jpg for template matching (e.g. 'C:\\\\user\\\\MS\\\\MouseData\\\\positions220831\\\\')\n",
    "            optional input: visualize_matching = Bool -> shows each plot for template matching\n",
    "    output: dictionary{ camera: {object: coordinates}}, naming of the file: \"results_template_matching.pickle\"\n",
    "    \n",
    "    commands:\n",
    "    \n",
    "    TemplateMatching.run(filepath)\n",
    "        performing template matching. results found in \"results_template_matching.pickle\" and\n",
    "        TemplateMatching.object_coordinates_per_camera\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def template_directory(self) ->str:\n",
    "        # specifies the directory for originally used templates\n",
    "        return r\"C:\\\\Users\\\\MS\\\\Documents\\\\Studium\\\\OpeningTrack\\\\coding\\\\test_data\\\\templates_obj\\\\\"\n",
    "    \n",
    "    @property\n",
    "    def template_naming(self) ->str:\n",
    "        # specifies the naming of the templates\n",
    "        return 'template.jpg'\n",
    "    \n",
    "    @property\n",
    "    def matching_naming(self) -> str:\n",
    "        # specifies the naming of the jpgs to be matched\n",
    "        return 'Positions.jpg'\n",
    "    \n",
    "    @property\n",
    "    def template_matching_threshold(self) ->str:\n",
    "        return 0.95\n",
    "    \n",
    "    @property\n",
    "    def all_cameras(self) ->str:\n",
    "        return ['Bottom', 'Side1', 'Side2', 'Ground1', 'Ground2', 'Top']\n",
    "    \n",
    "    def __init__(self, directory_positions_jpg: str, visualize_matching = False):\n",
    "        \n",
    "        # set path positions.jpgs from input\n",
    "        self.directory_positions_jpg = directory_positions_jpg\n",
    "        self.tm_methods = [cv2.TM_CCOEFF_NORMED, cv2.TM_CCORR_NORMED, cv2.TM_SQDIFF_NORMED]\n",
    "        self.visualize_matching = visualize_matching\n",
    "        \n",
    "        \n",
    "    def run(self) -> dict:    \n",
    "        # create dictionary with {camera: imagepath}\n",
    "        self.cameras_and_paths_positions = self._create_cameras_and_paths_dictionary(self.directory_positions_jpg, \n",
    "                                                                                     self.matching_naming)\n",
    "        print('The following cameras have been found:',self.cameras_and_paths_positions.keys())\n",
    "\n",
    "        # create dictionary {camera: {object: {level: templatepath}}}   \n",
    "        self.cameras_and_paths_template = self._create_cameras_and_paths_dictionary(self.template_directory,\n",
    "                                                                                    self.template_naming)\n",
    "        \n",
    "        # create results dictionary {camera: {(object: x-coordinate, y-coordinate)}}\n",
    "        self.object_coordinates_per_camera = {}\n",
    "        \n",
    "        # main loop    \n",
    "        for camera in self.cameras_and_paths_positions.keys():\n",
    "            \n",
    "            \n",
    "            self.object_coordinates_per_camera[camera] = {}\n",
    "            \n",
    "            # load image\n",
    "            original_image = cv2.imread(self.cameras_and_paths_positions[camera], 0)\n",
    "            \n",
    "            \n",
    "            for object_of_interest in self.cameras_and_paths_template[camera].keys():\n",
    "                \n",
    "                \n",
    "                print('Now working on ', camera, object_of_interest)\n",
    "                \n",
    "                # level 1\n",
    "                image = original_image.copy()\n",
    "                template, location = self._iterate_template_matching(camera = camera, image = image,\n",
    "                                                                     level = str(1), object_of_interest = object_of_interest)\n",
    "\n",
    "                # level 2\n",
    "                ofset = location\n",
    "                image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                template, location = self._iterate_template_matching(image = image, camera = camera,\n",
    "                                                                     level = str(2), object_of_interest = object_of_interest)\n",
    "\n",
    "                \n",
    "                if '3' not in self.cameras_and_paths_template[camera][object_of_interest].keys():\n",
    "                    # save results in self.object_coordinates_per_camera\n",
    "                    coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                    transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                    self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "\n",
    "                else:\n",
    "                    # level 3\n",
    "                    ofset = (ofset[0] + location[0], ofset[1]+location[1])\n",
    "                    image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                    template, location = self._iterate_template_matching(image = image, camera = camera, \n",
    "                                                                         level = str(3), object_of_interest = object_of_interest)\n",
    "                    if '4'not in self.cameras_and_paths_template[camera][object_of_interest].keys():\n",
    "                        # save results in f.object_coordinates_per_camera\n",
    "                        coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                        transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                        self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "                        \n",
    "                    else:\n",
    "                        # level 4\n",
    "                        ofset = (ofset[0] + location[0], ofset[1]+location[1])\n",
    "                        image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                        template, location = self._iterate_template_matching(image = image, camera = camera, \n",
    "                                                                         level = str(4), object_of_interest = object_of_interest)\n",
    "                        coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                        transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                        self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "                        \n",
    "        \n",
    "        # saving self.object_coordinates_per_camera as object_coordinates.pickle\n",
    "        with open(self.directory_positions_jpg + 'results_template_matching.pickle', 'wb') as f:\n",
    "            pickle.dump(self.object_coordinates_per_camera, f, pickle.HIGHEST_PROTOCOL)\n",
    "  \n",
    "        \n",
    "    def _create_cameras_and_paths_dictionary(self, path: str, naming_flag: str) -> dict:\n",
    "        # create a dictionary for easy file loading\n",
    "        \n",
    "        filepaths = [path + elem for elem in os.listdir(path) if elem.endswith(naming_flag)]\n",
    "        \n",
    "        \n",
    "        # templates\n",
    "        if 'level' in filepaths[0]:\n",
    "            files = {}\n",
    "            cameras = []\n",
    "            for filepath in filepaths:\n",
    "                if filepath.endswith(naming_flag):\n",
    "                    split_name = filepath.split(\"_\")\n",
    "                    camera, objecttofind, level = split_name[-4], split_name[-3], split_name[-2]\n",
    "                    cameras.append(camera)\n",
    "                    #objects.append(objecttofind)\n",
    "                    #levels.append(level)\n",
    "            for cam in cameras:\n",
    "                files[cam] = {}\n",
    "                objectstofind = [elem[elem.index(cam)+len(cam)+1:elem.index('_level')] for\n",
    "                                      elem in os.listdir(path) if cam in elem and elem.endswith(naming_flag)]\n",
    "                for objecttofind in objectstofind:\n",
    "                    files[cam][objecttofind] = {}             \n",
    "                    cam_filepaths = [elem for elem in filepaths if cam in elem and str(objecttofind) in elem]\n",
    "                    levels = [elem[elem.index('level')+5:elem.index('level')+6] for elem in os.listdir(path) \n",
    "                              if cam in elem and str(objecttofind) in elem and elem.endswith(naming_flag)]\n",
    "                    for i in range(len(levels)):\n",
    "                        files[cam][objecttofind].update({levels[i]: cam_filepaths[i]})\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            return files\n",
    "        \n",
    "        # images\n",
    "        else:\n",
    "            # list comprehension for getting cameras\n",
    "            cameras = [elem[7:(elem.index(naming_flag)-1)] for elem in os.listdir(path) if elem.endswith(naming_flag)]\n",
    "            return dict(zip(cameras, filepaths)) \n",
    "                                 \n",
    "    def _iterate_template_matching(self, camera: str, image: str, level: str, object_of_interest: str) -> (str, (int, int)):\n",
    "        # use template matching function to perform template matching for each level\n",
    "        \n",
    "        self.template_matched = False\n",
    "        template = cv2.imread(self.cameras_and_paths_template[camera][object_of_interest][level], 0)\n",
    "         # matches template to image and returns accuracy and location of top left corner \n",
    "        img = image.copy()\n",
    "        result = match_template(image, template)\n",
    "        ij = np.unravel_index(np.argmax(result), result.shape)\n",
    "        x,y = ij[::-1]\n",
    "        location = (x,y)\n",
    "        if self.visualize_matching:\n",
    "            self._visualize_template_matching(img, template, location)\n",
    "\n",
    "        return  template, location\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "    def _visualize_template_matching(self, image: str, template: str, location: (int)):\n",
    "        height_template, width_template = template.shape\n",
    "        bottom_right_corner = (location[0] + width_template, location[1] + height_template)\n",
    "        cv2.rectangle(image, location, bottom_right_corner, color = 0)\n",
    "        cv2.imshow('Template Matched Image', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows\n",
    "        \n",
    "    def _evaluate_template_matching(self, accuracy: int) -> bool:\n",
    "        if accuracy > self.template_matching_threshold:\n",
    "            print('Template matching worked with a ' + str(accuracy) + ' accuracy')\n",
    "            self.template_matched = True\n",
    "        else:\n",
    "             print('Template matching is not ideal, now trying a different method!')\n",
    "    \n",
    "    def _get_mean_coordinates(self, image: str, template: str, location: (int, int)) ->(int, int):\n",
    "        # get coordinates for input image\n",
    "        height_template, width_template = template.shape\n",
    "        center_coordinates =location[0] + width_template/2, location[1] + height_template/2        \n",
    "        return center_coordinates\n",
    "    \n",
    "    def _transpose_coordinates(self, coordinates: (int, int), ofset: (int, int)) ->(int, int):\n",
    "        # transpose coordinates from image slice to original image\n",
    "        return (coordinates[0] + ofset[0], coordinates[1] + ofset[1])\n",
    "    \n",
    "    def _check_whether_analyzed(self):\n",
    "        # Check for pickle file --> has this data already been analyzed? CURRENTLY NON FUNCTIONAL\n",
    "        file_exists = os.path.exists(self.directory_positions_jpg + 'object_coordinates.pickle')\n",
    "        if file_exists:            \n",
    "            inputquesiton = input('This data has already been analysed! \\n\\\n",
    "            Do you really want to reanalyse the data? This would overwrite the old coordinates\\\n",
    "            type \"yes\" or \"no\"')\n",
    "            if inputquesiton:\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a7972e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following cameras have been found: dict_keys(['Bottom', 'Ground2', 'Side1'])\n",
      "Now working on  Bottom screw1\n",
      "Now working on  Bottom screw2\n",
      "Now working on  Ground2 backcornerleft\n",
      "Now working on  Ground2 screw4\n",
      "Now working on  Side1 nut\n",
      "Now working on  Side1 screw2\n",
      "The following cameras have been found: dict_keys(['Bottom', 'Ground1', 'Side2'])\n",
      "Now working on  Bottom screw1\n",
      "Now working on  Bottom screw2\n",
      "Now working on  Ground1 nut\n",
      "Now working on  Side2 screw1\n",
      "The following cameras have been found: dict_keys(['Ground1', 'Side2'])\n",
      "Now working on  Ground1 nut\n",
      "Now working on  Side2 screw1\n"
     ]
    }
   ],
   "source": [
    "day220824 = TemplateMatching(path220824, visualize_matching= False)\n",
    "day220825 = TemplateMatching(path220825)\n",
    "day220826 = TemplateMatching(path220826)\n",
    "\n",
    "day220824.run()\n",
    "day220825.run()\n",
    "day220826.run()\n",
    "\n",
    "for day in [day220824, day220825, day220826]:\n",
    "    for cam in day.object_coordinates_per_camera.keys():\n",
    "        for obj in day.object_coordinates_per_camera[cam].keys():\n",
    "            image_temp = cv2.imread(day.cameras_and_paths_positions[cam])\n",
    "            coord1 = int(day.object_coordinates_per_camera[cam][obj][0])\n",
    "            coord2 = int(day.object_coordinates_per_camera[cam][obj][1])\n",
    "            cv2.circle(image_temp, (coord1, coord2), 2, (0,0,255), -1)\n",
    "            cv2.imshow('Sanity check for ' + str(cam) + ' ' + str(obj), image_temp)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c85f95",
   "metadata": {},
   "source": [
    "## 3) Combining open cv and scikit. scikit for iteration 1, then open cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f780a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemplateMatching(ABC):\n",
    "    \"\"\"\n",
    "    input: directory of positions jpg for template matching (e.g. 'C:\\\\user\\\\MS\\\\MouseData\\\\positions220831\\\\')\n",
    "            optional input: visualize_matching = Bool -> shows each plot for template matching\n",
    "    output: dictionary{ camera: {object: coordinates}}, naming of the file: \"results_template_matching.pickle\"\n",
    "    \n",
    "    commands:\n",
    "    \n",
    "    TemplateMatching.run(filepath)\n",
    "        performing template matching. results found in \"results_template_matching.pickle\" and\n",
    "        TemplateMatching.object_coordinates_per_camera\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def template_directory(self) ->str:\n",
    "        # specifies the directory for originally used templates\n",
    "        return r\"C:\\\\Users\\\\MS\\\\Documents\\\\Studium\\\\OpeningTrack\\\\coding\\\\test_data\\\\templates_obj\\\\\"\n",
    "    \n",
    "    @property\n",
    "    def template_naming(self) ->str:\n",
    "        # specifies the naming of the templates\n",
    "        return 'template.jpg'\n",
    "    \n",
    "    @property\n",
    "    def matching_naming(self) -> str:\n",
    "        # specifies the naming of the jpgs to be matched\n",
    "        return 'Positions.jpg'\n",
    "    \n",
    "    @property\n",
    "    def template_matching_threshold(self) ->str:\n",
    "        return 0.95\n",
    "    \n",
    "    @property\n",
    "    def all_cameras(self) ->str:\n",
    "        return ['Bottom', 'Side1', 'Side2', 'Ground1', 'Ground2', 'Top']\n",
    "    \n",
    "    def __init__(self, directory_positions_jpg: str, visualize_matching = False):\n",
    "        \n",
    "        # set path positions.jpgs from input\n",
    "        self.directory_positions_jpg = directory_positions_jpg\n",
    "        self.tm_methods = [cv2.TM_CCOEFF_NORMED, cv2.TM_CCORR_NORMED, cv2.TM_SQDIFF_NORMED]\n",
    "        self.visualize_matching = visualize_matching\n",
    "        \n",
    "        \n",
    "    def run(self) -> dict:    \n",
    "        # create dictionary with {camera: imagepath}\n",
    "        self.cameras_and_paths_positions = self._create_cameras_and_paths_dictionary(self.directory_positions_jpg, \n",
    "                                                                                     self.matching_naming)\n",
    "        print('The following cameras have been found:',self.cameras_and_paths_positions.keys())\n",
    "\n",
    "        # create dictionary {camera: {object: {level: templatepath}}}   \n",
    "        self.cameras_and_paths_template = self._create_cameras_and_paths_dictionary(self.template_directory,\n",
    "                                                                                    self.template_naming)\n",
    "        \n",
    "        # create results dictionary {camera: {(object: x-coordinate, y-coordinate)}}\n",
    "        self.object_coordinates_per_camera = {}\n",
    "        \n",
    "        # main loop    \n",
    "        for camera in self.cameras_and_paths_positions.keys():\n",
    "            \n",
    "            \n",
    "            self.object_coordinates_per_camera[camera] = {}\n",
    "            \n",
    "            # load image\n",
    "            original_image = cv2.imread(self.cameras_and_paths_positions[camera], 0)\n",
    "            \n",
    "            \n",
    "            for object_of_interest in self.cameras_and_paths_template[camera].keys():\n",
    "                \n",
    "                \n",
    "                print('Now working on ', camera, object_of_interest)\n",
    "                \n",
    "                # level 1\n",
    "                image = original_image.copy()\n",
    "                template, location = self._iterate_template_matching(camera = camera, image = image,\n",
    "                                                                     level = str(1), object_of_interest = object_of_interest)\n",
    "\n",
    "                # level 2\n",
    "                ofset = location\n",
    "                image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                template, location = self._iterate_template_matching(image = image, camera = camera,\n",
    "                                                                     level = str(2), object_of_interest = object_of_interest)\n",
    "\n",
    "                \n",
    "                if '3' not in self.cameras_and_paths_template[camera][object_of_interest].keys():\n",
    "                    # save results in self.object_coordinates_per_camera\n",
    "                    coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                    transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                    self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "\n",
    "                else:\n",
    "                    # level 3\n",
    "                    ofset = (ofset[0] + location[0], ofset[1]+location[1])\n",
    "                    image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                    template, location = self._iterate_template_matching(image = image, camera = camera, \n",
    "                                                                         level = str(3), object_of_interest = object_of_interest)\n",
    "                    if '4'not in self.cameras_and_paths_template[camera][object_of_interest].keys():\n",
    "                        # save results in f.object_coordinates_per_camera\n",
    "                        coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                        transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                        self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "                        \n",
    "                    else:\n",
    "                        # level 4\n",
    "                        ofset = (ofset[0] + location[0], ofset[1]+location[1])\n",
    "                        image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                        template, location = self._iterate_template_matching(image = image, camera = camera, \n",
    "                                                                         level = str(4), object_of_interest = object_of_interest)\n",
    "                        coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                        transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                        self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "                        \n",
    "        \n",
    "        # saving self.object_coordinates_per_camera as object_coordinates.pickle\n",
    "        with open(self.directory_positions_jpg + 'results_template_matching.pickle', 'wb') as f:\n",
    "            pickle.dump(self.object_coordinates_per_camera, f, pickle.HIGHEST_PROTOCOL)\n",
    "  \n",
    "        \n",
    "    def _create_cameras_and_paths_dictionary(self, path: str, naming_flag: str) -> dict:\n",
    "        # create a dictionary for easy file loading\n",
    "        \n",
    "        filepaths = [path + elem for elem in os.listdir(path) if elem.endswith(naming_flag)]\n",
    "        \n",
    "        \n",
    "        # templates\n",
    "        if 'level' in filepaths[0]:\n",
    "            files = {}\n",
    "            cameras = []\n",
    "            for filepath in filepaths:\n",
    "                if filepath.endswith(naming_flag):\n",
    "                    split_name = filepath.split(\"_\")\n",
    "                    camera, objecttofind, level = split_name[-4], split_name[-3], split_name[-2]\n",
    "                    cameras.append(camera)\n",
    "                    #objects.append(objecttofind)\n",
    "                    #levels.append(level)\n",
    "            for cam in cameras:\n",
    "                files[cam] = {}\n",
    "                objectstofind = [elem[elem.index(cam)+len(cam)+1:elem.index('_level')] for\n",
    "                                      elem in os.listdir(path) if cam in elem and elem.endswith(naming_flag)]\n",
    "                for objecttofind in objectstofind:\n",
    "                    files[cam][objecttofind] = {}             \n",
    "                    cam_filepaths = [elem for elem in filepaths if cam in elem and str(objecttofind) in elem]\n",
    "                    levels = [elem[elem.index('level')+5:elem.index('level')+6] for elem in os.listdir(path) \n",
    "                              if cam in elem and str(objecttofind) in elem and elem.endswith(naming_flag)]\n",
    "                    for i in range(len(levels)):\n",
    "                        files[cam][objecttofind].update({levels[i]: cam_filepaths[i]})\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            return files\n",
    "        \n",
    "        # images\n",
    "        else:\n",
    "            # list comprehension for getting cameras\n",
    "            cameras = [elem[7:(elem.index(naming_flag)-1)] for elem in os.listdir(path) if elem.endswith(naming_flag)]\n",
    "            return dict(zip(cameras, filepaths)) \n",
    "                                 \n",
    "    def _iterate_template_matching(self, camera: str, image: str, level: str, object_of_interest: str) -> (str, (int, int)):\n",
    "        # use template matching function to perform template matching for each level\n",
    "        \n",
    "        self.template_matched = False\n",
    "        template = cv2.imread(self.cameras_and_paths_template[camera][object_of_interest][level], 0)\n",
    "         # matches template to image and returns accuracy and location of top left corner \n",
    "        img = image.copy()\n",
    "        if level == '1':\n",
    "            result = match_template(image, template)\n",
    "            ij = np.unravel_index(np.argmax(result), result.shape)\n",
    "            x,y = ij[::-1]\n",
    "            location = (x,y)\n",
    "            if self.visualize_matching:\n",
    "                self._visualize_template_matching(img, template, location)\n",
    "\n",
    "            return  template, location\n",
    "        \n",
    "        else:\n",
    "            accuracies_and_locations = {}\n",
    "            for method in self.tm_methods:\n",
    "                # test different template matching methods and select the best one\n",
    "                accuracy, location = self._match_template(image, template, method)\n",
    "                accuracies_and_locations[accuracy] = location\n",
    "            best_accuracy = max(accuracies_and_locations.keys())\n",
    "            self._evaluate_template_matching(best_accuracy)\n",
    "\n",
    "            if self.template_matched:\n",
    "                # optional: visualize template matching \n",
    "                if self.visualize_matching:\n",
    "                    self._visualize_template_matching(image, template, location = accuracies_and_locations[best_accuracy])\n",
    "                return template, location\n",
    "\n",
    "            if self.template_matched == False:\n",
    "                print('template is not fit for template matching! Use .create_template to create a new template for this object:', object_of_interest, camera)\n",
    "                self.template_matching_ongoing = False\n",
    "    \n",
    "    \n",
    "    def _match_template(self, image: str, template: str, method: str) -> (int, (int, int)):\n",
    "        # matches template to image and returns accuracy and location of top left corner \n",
    "        img = image.copy()\n",
    "        result = cv2.matchTemplate(image = img, templ = template, method = method)\n",
    "        min_value, max_value, min_location, max_location = cv2.minMaxLoc(result)\n",
    "        \n",
    "        if method == cv2.TM_SQDIFF_NORMED:\n",
    "            # the normed-/sqdiff methods have the position of the matched template in the min location\n",
    "            location = min_location\n",
    "            value = min_value\n",
    "            accuracy = 1-abs(0-value)\n",
    "        else:\n",
    "            # All other methods show the matched template position in the max location\n",
    "            location = max_location\n",
    "            value = max_value\n",
    "            accuracy = value\n",
    "        return  accuracy, location\n",
    "            \n",
    "        \n",
    "        \n",
    "    def _visualize_template_matching(self, image: str, template: str, location: (int)):\n",
    "        height_template, width_template = template.shape\n",
    "        bottom_right_corner = (location[0] + width_template, location[1] + height_template)\n",
    "        cv2.rectangle(image, location, bottom_right_corner, color = 0)\n",
    "        cv2.imshow('Template Matched Image', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows\n",
    "        \n",
    "    def _evaluate_template_matching(self, accuracy: int) -> bool:\n",
    "        if accuracy > self.template_matching_threshold:\n",
    "            print('Template matching worked with a ' + str(accuracy) + ' accuracy')\n",
    "            self.template_matched = True\n",
    "        else:\n",
    "             print('Template matching is not ideal, now trying a different method!')\n",
    "    \n",
    "    def _get_mean_coordinates(self, image: str, template: str, location: (int, int)) ->(int, int):\n",
    "        # get coordinates for input image\n",
    "        height_template, width_template = template.shape\n",
    "        center_coordinates =location[0] + width_template/2, location[1] + height_template/2        \n",
    "        return center_coordinates\n",
    "    \n",
    "    def _transpose_coordinates(self, coordinates: (int, int), ofset: (int, int)) ->(int, int):\n",
    "        # transpose coordinates from image slice to original image\n",
    "        return (coordinates[0] + ofset[0], coordinates[1] + ofset[1])\n",
    "    \n",
    "    def _check_whether_analyzed(self):\n",
    "        # Check for pickle file --> has this data already been analyzed? CURRENTLY NON FUNCTIONAL\n",
    "        file_exists = os.path.exists(self.directory_positions_jpg + 'object_coordinates.pickle')\n",
    "        if file_exists:            \n",
    "            inputquesiton = input('This data has already been analysed! \\n\\\n",
    "            Do you really want to reanalyse the data? This would overwrite the old coordinates\\\n",
    "            type \"yes\" or \"no\"')\n",
    "            if inputquesiton:\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfe524ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following cameras have been found: dict_keys(['Bottom', 'Ground2', 'Side1'])\n",
      "Now working on  Bottom screw1\n",
      "Template matching worked with a 0.9894607067108154 accuracy\n",
      "Template matching worked with a 0.9960360527038574 accuracy\n",
      "Now working on  Bottom screw2\n",
      "Template matching worked with a 0.9894607067108154 accuracy\n",
      "Template matching worked with a 0.9957596659660339 accuracy\n",
      "Now working on  Ground2 backcornerleft\n",
      "Template matching worked with a 0.9998504519462585 accuracy\n",
      "Template matching worked with a 0.9984613656997681 accuracy\n",
      "Now working on  Ground2 screw4\n",
      "Template matching worked with a 0.9998789429664612 accuracy\n",
      "Template matching worked with a 0.999656081199646 accuracy\n",
      "Now working on  Side1 nut\n",
      "Template matching worked with a 0.9999403357505798 accuracy\n",
      "Template matching worked with a 0.9983139038085938 accuracy\n",
      "Now working on  Side1 screw2\n",
      "Template matching worked with a 0.9999300241470337 accuracy\n",
      "Template matching worked with a 0.9997861385345459 accuracy\n",
      "Template matching worked with a 0.9995020031929016 accuracy\n",
      "The following cameras have been found: dict_keys(['Bottom', 'Ground1', 'Side2'])\n",
      "Now working on  Bottom screw1\n",
      "Template matching worked with a 0.9999275803565979 accuracy\n",
      "Template matching worked with a 0.9998486042022705 accuracy\n",
      "Now working on  Bottom screw2\n",
      "Template matching worked with a 0.9999275803565979 accuracy\n",
      "Template matching worked with a 0.9997097849845886 accuracy\n",
      "Now working on  Ground1 nut\n",
      "Template matching worked with a 0.9742247462272644 accuracy\n",
      "Template matching worked with a 0.9744579195976257 accuracy\n",
      "Template matching worked with a 0.9619134068489075 accuracy\n",
      "Now working on  Side2 screw1\n",
      "Template matching worked with a 0.9999860525131226 accuracy\n",
      "Template matching worked with a 0.9999584555625916 accuracy\n",
      "Template matching worked with a 0.9994745850563049 accuracy\n",
      "The following cameras have been found: dict_keys(['Ground1', 'Side2'])\n",
      "Now working on  Ground1 nut\n",
      "Template matching worked with a 0.9998708963394165 accuracy\n",
      "Template matching worked with a 0.999844491481781 accuracy\n",
      "Template matching worked with a 0.9986979961395264 accuracy\n",
      "Now working on  Side2 screw1\n",
      "Template matching worked with a 0.9871295690536499 accuracy\n",
      "Template matching worked with a 0.9858168363571167 accuracy\n",
      "Template matching worked with a 0.9646415710449219 accuracy\n"
     ]
    }
   ],
   "source": [
    "day220824 = TemplateMatching(path220824, visualize_matching= False)\n",
    "day220825 = TemplateMatching(path220825)\n",
    "day220826 = TemplateMatching(path220826)\n",
    "\n",
    "day220824.run()\n",
    "day220825.run()\n",
    "day220826.run()\n",
    "\n",
    "for day in [day220824, day220825, day220826]:\n",
    "    for cam in day.object_coordinates_per_camera.keys():\n",
    "        for obj in day.object_coordinates_per_camera[cam].keys():\n",
    "            image_temp = cv2.imread(day.cameras_and_paths_positions[cam])\n",
    "            coord1 = int(day.object_coordinates_per_camera[cam][obj][0])\n",
    "            coord2 = int(day.object_coordinates_per_camera[cam][obj][1])\n",
    "            cv2.circle(image_temp, (coord1, coord2), 2, (0,0,255), -1)\n",
    "            cv2.imshow('Sanity check for ' + str(cam) + ' ' + str(obj), image_temp)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc8703",
   "metadata": {},
   "source": [
    "##  Scikit for iteration 1 and 2, then open cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ef3d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemplateMatching(ABC):\n",
    "    \"\"\"\n",
    "    input: directory of positions jpg for template matching (e.g. 'C:\\\\user\\\\MS\\\\MouseData\\\\positions220831\\\\')\n",
    "            optional input: visualize_matching = Bool -> shows each plot for template matching\n",
    "    output: dictionary{ camera: {object: coordinates}}, naming of the file: \"results_template_matching.pickle\"\n",
    "    \n",
    "    commands:\n",
    "    \n",
    "    TemplateMatching.run(filepath)\n",
    "        performing template matching. results found in \"results_template_matching.pickle\" and\n",
    "        TemplateMatching.object_coordinates_per_camera\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def template_directory(self) ->str:\n",
    "        # specifies the directory for originally used templates\n",
    "        return r\"C:\\\\Users\\\\MS\\\\Documents\\\\Studium\\\\OpeningTrack\\\\coding\\\\test_data\\\\templates_obj\\\\\"\n",
    "    \n",
    "    @property\n",
    "    def template_naming(self) ->str:\n",
    "        # specifies the naming of the templates\n",
    "        return 'template.jpg'\n",
    "    \n",
    "    @property\n",
    "    def matching_naming(self) -> str:\n",
    "        # specifies the naming of the jpgs to be matched\n",
    "        return 'Positions.jpg'\n",
    "    \n",
    "    @property\n",
    "    def template_matching_threshold(self) ->str:\n",
    "        return 0.95\n",
    "    \n",
    "    @property\n",
    "    def all_cameras(self) ->str:\n",
    "        return ['Bottom', 'Side1', 'Side2', 'Ground1', 'Ground2', 'Top']\n",
    "    \n",
    "    def __init__(self, directory_positions_jpg: str, visualize_matching = False):\n",
    "        \n",
    "        # set path positions.jpgs from input\n",
    "        self.directory_positions_jpg = directory_positions_jpg\n",
    "        self.tm_methods = [cv2.TM_CCOEFF_NORMED, cv2.TM_CCORR_NORMED, cv2.TM_SQDIFF_NORMED]\n",
    "        self.visualize_matching = visualize_matching\n",
    "        \n",
    "        \n",
    "    def run(self) -> dict:    \n",
    "        # create dictionary with {camera: imagepath}\n",
    "        self.cameras_and_paths_positions = self._create_cameras_and_paths_dictionary(self.directory_positions_jpg, \n",
    "                                                                                     self.matching_naming)\n",
    "        print('The following cameras have been found:',self.cameras_and_paths_positions.keys())\n",
    "\n",
    "        # create dictionary {camera: {object: {level: templatepath}}}   \n",
    "        self.cameras_and_paths_template = self._create_cameras_and_paths_dictionary(self.template_directory,\n",
    "                                                                                    self.template_naming)\n",
    "        \n",
    "        # create results dictionary {camera: {(object: x-coordinate, y-coordinate)}}\n",
    "        self.object_coordinates_per_camera = {}\n",
    "        \n",
    "        # main loop    \n",
    "        for camera in self.cameras_and_paths_positions.keys():\n",
    "            \n",
    "            \n",
    "            self.object_coordinates_per_camera[camera] = {}\n",
    "            \n",
    "            # load image\n",
    "            original_image = cv2.imread(self.cameras_and_paths_positions[camera], 0)\n",
    "            \n",
    "            \n",
    "            for object_of_interest in self.cameras_and_paths_template[camera].keys():\n",
    "                \n",
    "                \n",
    "                print('Now working on ', camera, object_of_interest)\n",
    "                \n",
    "                # level 1\n",
    "                image = original_image.copy()\n",
    "                template, location = self._iterate_template_matching(camera = camera, image = image,\n",
    "                                                                     level = str(1), object_of_interest = object_of_interest)\n",
    "\n",
    "                # level 2\n",
    "                ofset = location\n",
    "                image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                template, location = self._iterate_template_matching(image = image, camera = camera,\n",
    "                                                                     level = str(2), object_of_interest = object_of_interest)\n",
    "\n",
    "                \n",
    "                if '3' not in self.cameras_and_paths_template[camera][object_of_interest].keys():\n",
    "                    # save results in self.object_coordinates_per_camera\n",
    "                    coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                    transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                    self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "\n",
    "                else:\n",
    "                    # level 3\n",
    "                    ofset = (ofset[0] + location[0], ofset[1]+location[1])\n",
    "                    image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                    template, location = self._iterate_template_matching(image = image, camera = camera, \n",
    "                                                                         level = str(3), object_of_interest = object_of_interest)\n",
    "                    if '4'not in self.cameras_and_paths_template[camera][object_of_interest].keys():\n",
    "                        # save results in f.object_coordinates_per_camera\n",
    "                        coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                        transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                        self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "                        \n",
    "                    else:\n",
    "                        # level 4\n",
    "                        ofset = (ofset[0] + location[0], ofset[1]+location[1])\n",
    "                        image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                        template, location = self._iterate_template_matching(image = image, camera = camera, \n",
    "                                                                         level = str(4), object_of_interest = object_of_interest)\n",
    "                        coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                        transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                        self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "                        \n",
    "        \n",
    "        # saving self.object_coordinates_per_camera as object_coordinates.pickle\n",
    "        with open(self.directory_positions_jpg + 'results_template_matching.pickle', 'wb') as f:\n",
    "            pickle.dump(self.object_coordinates_per_camera, f, pickle.HIGHEST_PROTOCOL)\n",
    "  \n",
    "        \n",
    "    def _create_cameras_and_paths_dictionary(self, path: str, naming_flag: str) -> dict:\n",
    "        # create a dictionary for easy file loading\n",
    "        \n",
    "        filepaths = [path + elem for elem in os.listdir(path) if elem.endswith(naming_flag)]\n",
    "        \n",
    "        \n",
    "        # templates\n",
    "        if 'level' in filepaths[0]:\n",
    "            files = {}\n",
    "            cameras = []\n",
    "            for filepath in filepaths:\n",
    "                if filepath.endswith(naming_flag):\n",
    "                    split_name = filepath.split(\"_\")\n",
    "                    camera, objecttofind, level = split_name[-4], split_name[-3], split_name[-2]\n",
    "                    cameras.append(camera)\n",
    "                    #objects.append(objecttofind)\n",
    "                    #levels.append(level)\n",
    "            for cam in cameras:\n",
    "                files[cam] = {}\n",
    "                objectstofind = [elem[elem.index(cam)+len(cam)+1:elem.index('_level')] for\n",
    "                                      elem in os.listdir(path) if cam in elem and elem.endswith(naming_flag)]\n",
    "                for objecttofind in objectstofind:\n",
    "                    files[cam][objecttofind] = {}             \n",
    "                    cam_filepaths = [elem for elem in filepaths if cam in elem and str(objecttofind) in elem]\n",
    "                    levels = [elem[elem.index('level')+5:elem.index('level')+6] for elem in os.listdir(path) \n",
    "                              if cam in elem and str(objecttofind) in elem and elem.endswith(naming_flag)]\n",
    "                    for i in range(len(levels)):\n",
    "                        files[cam][objecttofind].update({levels[i]: cam_filepaths[i]})\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            return files\n",
    "        \n",
    "        # images\n",
    "        else:\n",
    "            # list comprehension for getting cameras\n",
    "            cameras = [elem[7:(elem.index(naming_flag)-1)] for elem in os.listdir(path) if elem.endswith(naming_flag)]\n",
    "            return dict(zip(cameras, filepaths)) \n",
    "                                 \n",
    "    def _iterate_template_matching(self, camera: str, image: str, level: str, object_of_interest: str) -> (str, (int, int)):\n",
    "        # use template matching function to perform template matching for each level\n",
    "        \n",
    "        self.template_matched = False\n",
    "        template = cv2.imread(self.cameras_and_paths_template[camera][object_of_interest][level], 0)\n",
    "         # matches template to image and returns accuracy and location of top left corner \n",
    "        img = image.copy()\n",
    "        if level in ['3', '4']:\n",
    "            result = match_template(image, template)\n",
    "            ij = np.unravel_index(np.argmax(result), result.shape)\n",
    "            x,y = ij[::-1]\n",
    "            location = (x,y)\n",
    "            if self.visualize_matching:\n",
    "                self._visualize_template_matching(img, template, location)\n",
    "\n",
    "            return  template, location\n",
    "        \n",
    "        else:\n",
    "            accuracies_and_locations = {}\n",
    "            for method in self.tm_methods:\n",
    "                # test different template matching methods and select the best one\n",
    "                accuracy, location = self._match_template(image, template, method)\n",
    "                accuracies_and_locations[accuracy] = location\n",
    "            best_accuracy = max(accuracies_and_locations.keys())\n",
    "            self._evaluate_template_matching(best_accuracy)\n",
    "\n",
    "            if self.template_matched:\n",
    "                # optional: visualize template matching \n",
    "                if self.visualize_matching:\n",
    "                    self._visualize_template_matching(image, template, location = accuracies_and_locations[best_accuracy])\n",
    "                return template, location\n",
    "\n",
    "            if self.template_matched == False:\n",
    "                print('template is not fit for template matching! Use .create_template to create a new template for this object:', object_of_interest, camera)\n",
    "                self.template_matching_ongoing = False\n",
    "    \n",
    "    \n",
    "    def _match_template(self, image: str, template: str, method: str) -> (int, (int, int)):\n",
    "        # matches template to image and returns accuracy and location of top left corner \n",
    "        img = image.copy()\n",
    "        result = cv2.matchTemplate(image = img, templ = template, method = method)\n",
    "        min_value, max_value, min_location, max_location = cv2.minMaxLoc(result)\n",
    "        \n",
    "        if method == cv2.TM_SQDIFF_NORMED:\n",
    "            # the normed-/sqdiff methods have the position of the matched template in the min location\n",
    "            location = min_location\n",
    "            value = min_value\n",
    "            accuracy = 1-abs(0-value)\n",
    "        else:\n",
    "            # All other methods show the matched template position in the max location\n",
    "            location = max_location\n",
    "            value = max_value\n",
    "            accuracy = value\n",
    "        return  accuracy, location\n",
    "            \n",
    "        \n",
    "        \n",
    "    def _visualize_template_matching(self, image: str, template: str, location: (int)):\n",
    "        height_template, width_template = template.shape\n",
    "        bottom_right_corner = (location[0] + width_template, location[1] + height_template)\n",
    "        cv2.rectangle(image, location, bottom_right_corner, color = 0)\n",
    "        cv2.imshow('Template Matched Image', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows\n",
    "        \n",
    "    def _evaluate_template_matching(self, accuracy: int) -> bool:\n",
    "        if accuracy > self.template_matching_threshold:\n",
    "            print('Template matching worked with a ' + str(accuracy) + ' accuracy')\n",
    "            self.template_matched = True\n",
    "        else:\n",
    "             print('Template matching is not ideal, now trying a different method!')\n",
    "    \n",
    "    def _get_mean_coordinates(self, image: str, template: str, location: (int, int)) ->(int, int):\n",
    "        # get coordinates for input image\n",
    "        height_template, width_template = template.shape\n",
    "        center_coordinates =location[0] + width_template/2, location[1] + height_template/2        \n",
    "        return center_coordinates\n",
    "    \n",
    "    def _transpose_coordinates(self, coordinates: (int, int), ofset: (int, int)) ->(int, int):\n",
    "        # transpose coordinates from image slice to original image\n",
    "        return (coordinates[0] + ofset[0], coordinates[1] + ofset[1])\n",
    "    \n",
    "    def _check_whether_analyzed(self):\n",
    "        # Check for pickle file --> has this data already been analyzed? CURRENTLY NON FUNCTIONAL\n",
    "        file_exists = os.path.exists(self.directory_positions_jpg + 'object_coordinates.pickle')\n",
    "        if file_exists:            \n",
    "            inputquesiton = input('This data has already been analysed! \\n\\\n",
    "            Do you really want to reanalyse the data? This would overwrite the old coordinates\\\n",
    "            type \"yes\" or \"no\"')\n",
    "            if inputquesiton:\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e386ffc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following cameras have been found: dict_keys(['Bottom', 'Ground2', 'Side1'])\n",
      "Now working on  Bottom screw1\n",
      "Template matching worked with a 0.9713526964187622 accuracy\n",
      "Template matching worked with a 0.9894607067108154 accuracy\n",
      "Now working on  Bottom screw2\n",
      "Template matching worked with a 0.9713526964187622 accuracy\n",
      "Template matching worked with a 0.9894607067108154 accuracy\n",
      "Now working on  Ground2 backcornerleft\n",
      "Template matching worked with a 0.9999387860298157 accuracy\n",
      "Template matching worked with a 0.9998504519462585 accuracy\n",
      "Now working on  Ground2 screw4\n",
      "Template matching worked with a 0.9999405145645142 accuracy\n",
      "Template matching worked with a 0.9998789429664612 accuracy\n",
      "Now working on  Side1 nut\n",
      "Template matching worked with a 0.9999651312828064 accuracy\n",
      "Template matching worked with a 0.9999403357505798 accuracy\n",
      "Now working on  Side1 screw2\n",
      "Template matching worked with a 0.9999651312828064 accuracy\n",
      "Template matching worked with a 0.9999300241470337 accuracy\n",
      "The following cameras have been found: dict_keys(['Bottom', 'Ground1', 'Side2'])\n",
      "Now working on  Bottom screw1\n",
      "Template matching worked with a 0.9999613761901855 accuracy\n",
      "Template matching worked with a 0.9999275803565979 accuracy\n",
      "Now working on  Bottom screw2\n",
      "Template matching worked with a 0.9999613761901855 accuracy\n",
      "Template matching worked with a 0.9999275803565979 accuracy\n",
      "Now working on  Ground1 nut\n",
      "Template matching worked with a 0.9633011221885681 accuracy\n",
      "Template matching worked with a 0.9742250442504883 accuracy\n",
      "Now working on  Side2 screw1\n",
      "Template matching worked with a 0.9849935173988342 accuracy\n",
      "Template matching worked with a 0.9999860525131226 accuracy\n",
      "The following cameras have been found: dict_keys(['Ground1', 'Side2'])\n",
      "Now working on  Ground1 nut\n",
      "Template matching worked with a 0.9999132752418518 accuracy\n",
      "Template matching worked with a 0.9998708963394165 accuracy\n",
      "Now working on  Side2 screw1\n",
      "Template matching worked with a 0.9999734163284302 accuracy\n",
      "Template matching worked with a 0.9871295690536499 accuracy\n"
     ]
    }
   ],
   "source": [
    "day220824 = TemplateMatching(path220824, visualize_matching= False)\n",
    "day220825 = TemplateMatching(path220825)\n",
    "day220826 = TemplateMatching(path220826)\n",
    "\n",
    "day220824.run()\n",
    "day220825.run()\n",
    "day220826.run()\n",
    "\n",
    "for day in [day220824, day220825, day220826]:\n",
    "    for cam in day.object_coordinates_per_camera.keys():\n",
    "        for obj in day.object_coordinates_per_camera[cam].keys():\n",
    "            image_temp = cv2.imread(day.cameras_and_paths_positions[cam])\n",
    "            coord1 = int(day.object_coordinates_per_camera[cam][obj][0])\n",
    "            coord2 = int(day.object_coordinates_per_camera[cam][obj][1])\n",
    "            cv2.circle(image_temp, (coord1, coord2), 2, (0,0,255), -1)\n",
    "            cv2.imshow('Sanity check for ' + str(cam) + ' ' + str(obj), image_temp)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7ae870",
   "metadata": {},
   "source": [
    "## Using only open cv but with Nonuniform Illumination Correction by plantcv WATCH OUT THIS SPAMS IMAGES INTO THE REPOSITORY FOLDER!!! Just don´t run it, it is not worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4802b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantcv import plantcv as pcv\n",
    "pcv.params.debug = \"print\"\n",
    "\n",
    "\n",
    "class TemplateMatching(ABC):\n",
    "    \"\"\"\n",
    "    input: directory of positions jpg for template matching (e.g. 'C:\\\\user\\\\MS\\\\MouseData\\\\positions220831\\\\')\n",
    "            optional input: visualize_matching = Bool -> shows each plot for template matching\n",
    "    output: dictionary{ camera: {object: coordinates}}, naming of the file: \"results_template_matching.pickle\"\n",
    "    \n",
    "    commands:\n",
    "    \n",
    "    TemplateMatching.run(filepath)\n",
    "        performing template matching. results found in \"results_template_matching.pickle\" and\n",
    "        TemplateMatching.object_coordinates_per_camera\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def template_directory(self) ->str:\n",
    "        # specifies the directory for originally used templates\n",
    "        return r\"C:\\\\Users\\\\MS\\\\Documents\\\\Studium\\\\OpeningTrack\\\\coding\\\\test_data\\\\templates_obj\\\\\"\n",
    "    \n",
    "    @property\n",
    "    def template_naming(self) ->str:\n",
    "        # specifies the naming of the templates\n",
    "        return 'template.jpg'\n",
    "    \n",
    "    @property\n",
    "    def matching_naming(self) -> str:\n",
    "        # specifies the naming of the jpgs to be matched\n",
    "        return 'Positions.jpg'\n",
    "    \n",
    "    @property\n",
    "    def template_matching_threshold(self) ->str:\n",
    "        return 0.95\n",
    "    \n",
    "    @property\n",
    "    def all_cameras(self) ->str:\n",
    "        return ['Bottom', 'Side1', 'Side2', 'Ground1', 'Ground2', 'Top']\n",
    "    \n",
    "    def __init__(self, directory_positions_jpg: str, visualize_matching = False):\n",
    "        \n",
    "        # set path positions.jpgs from input\n",
    "        self.directory_positions_jpg = directory_positions_jpg\n",
    "        self.tm_methods = [cv2.TM_CCOEFF_NORMED, cv2.TM_CCORR_NORMED, cv2.TM_SQDIFF_NORMED]\n",
    "        self.visualize_matching = visualize_matching\n",
    "        \n",
    "        \n",
    "    def run(self) -> dict:    \n",
    "        # create dictionary with {camera: imagepath}\n",
    "        self.cameras_and_paths_positions = self._create_cameras_and_paths_dictionary(self.directory_positions_jpg, \n",
    "                                                                                     self.matching_naming)\n",
    "        print('The following cameras have been found:',self.cameras_and_paths_positions.keys())\n",
    "\n",
    "        # create dictionary {camera: {object: {level: templatepath}}}   \n",
    "        self.cameras_and_paths_template = self._create_cameras_and_paths_dictionary(self.template_directory,\n",
    "                                                                                    self.template_naming)\n",
    "        \n",
    "        # create results dictionary {camera: {(object: x-coordinate, y-coordinate)}}\n",
    "        self.object_coordinates_per_camera = {}\n",
    "        \n",
    "        # main loop    \n",
    "        for camera in self.cameras_and_paths_positions.keys():\n",
    "            \n",
    "            \n",
    "            self.object_coordinates_per_camera[camera] = {}\n",
    "            \n",
    "            # load image\n",
    "            original_image = cv2.imread(self.cameras_and_paths_positions[camera], 0)\n",
    "            \n",
    "            \n",
    "            for object_of_interest in self.cameras_and_paths_template[camera].keys():\n",
    "                \n",
    "                \n",
    "                print('Now working on ', camera, object_of_interest)\n",
    "                \n",
    "                # level 1\n",
    "                image = original_image.copy()\n",
    "                template, location = self._iterate_template_matching(camera = camera, image = image,\n",
    "                                                                     level = str(1), object_of_interest = object_of_interest)\n",
    "\n",
    "                # level 2\n",
    "                ofset = location\n",
    "                image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                template, location = self._iterate_template_matching(image = image, camera = camera,\n",
    "                                                                     level = str(2), object_of_interest = object_of_interest)\n",
    "\n",
    "                \n",
    "                if '3' not in self.cameras_and_paths_template[camera][object_of_interest].keys():\n",
    "                    # save results in self.object_coordinates_per_camera\n",
    "                    coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                    transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                    self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "\n",
    "                else:\n",
    "                    # level 3\n",
    "                    ofset = (ofset[0] + location[0], ofset[1]+location[1])\n",
    "                    image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                    template, location = self._iterate_template_matching(image = image, camera = camera, \n",
    "                                                                         level = str(3), object_of_interest = object_of_interest)\n",
    "                    if '4'not in self.cameras_and_paths_template[camera][object_of_interest].keys():\n",
    "                        # save results in f.object_coordinates_per_camera\n",
    "                        coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                        transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                        self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "                        \n",
    "                    else:\n",
    "                        # level 4\n",
    "                        ofset = (ofset[0] + location[0], ofset[1]+location[1])\n",
    "                        image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                        template, location = self._iterate_template_matching(image = image, camera = camera, \n",
    "                                                                         level = str(4), object_of_interest = object_of_interest)\n",
    "                        coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                        transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                        self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "                        \n",
    "        \n",
    "        # saving self.object_coordinates_per_camera as object_coordinates.pickle\n",
    "        with open(self.directory_positions_jpg + 'results_template_matching.pickle', 'wb') as f:\n",
    "            pickle.dump(self.object_coordinates_per_camera, f, pickle.HIGHEST_PROTOCOL)\n",
    "  \n",
    "        \n",
    "    def _create_cameras_and_paths_dictionary(self, path: str, naming_flag: str) -> dict:\n",
    "        # create a dictionary for easy file loading\n",
    "        \n",
    "        filepaths = [path + elem for elem in os.listdir(path) if elem.endswith(naming_flag)]\n",
    "        \n",
    "        \n",
    "        # templates\n",
    "        if 'level' in filepaths[0]:\n",
    "            files = {}\n",
    "            cameras = []\n",
    "            for filepath in filepaths:\n",
    "                if filepath.endswith(naming_flag):\n",
    "                    split_name = filepath.split(\"_\")\n",
    "                    camera, objecttofind, level = split_name[-4], split_name[-3], split_name[-2]\n",
    "                    cameras.append(camera)\n",
    "                    #objects.append(objecttofind)\n",
    "                    #levels.append(level)\n",
    "            for cam in cameras:\n",
    "                files[cam] = {}\n",
    "                objectstofind = [elem[elem.index(cam)+len(cam)+1:elem.index('_level')] for\n",
    "                                      elem in os.listdir(path) if cam in elem and elem.endswith(naming_flag)]\n",
    "                for objecttofind in objectstofind:\n",
    "                    files[cam][objecttofind] = {}             \n",
    "                    cam_filepaths = [elem for elem in filepaths if cam in elem and str(objecttofind) in elem]\n",
    "                    levels = [elem[elem.index('level')+5:elem.index('level')+6] for elem in os.listdir(path) \n",
    "                              if cam in elem and str(objecttofind) in elem and elem.endswith(naming_flag)]\n",
    "                    for i in range(len(levels)):\n",
    "                        files[cam][objecttofind].update({levels[i]: cam_filepaths[i]})\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            return files\n",
    "        \n",
    "        # images\n",
    "        else:\n",
    "            # list comprehension for getting cameras\n",
    "            cameras = [elem[7:(elem.index(naming_flag)-1)] for elem in os.listdir(path) if elem.endswith(naming_flag)]\n",
    "            return dict(zip(cameras, filepaths)) \n",
    "                                 \n",
    "    def _iterate_template_matching(self, camera: str, image: str, level: str, object_of_interest: str) -> (str, (int, int)):\n",
    "        # use template matching function to perform template matching for each level\n",
    "        \n",
    "        self.template_matched = False\n",
    "        template = cv2.imread(self.cameras_and_paths_template[camera][object_of_interest][level], 0)\n",
    "        \n",
    "        accuracies_and_locations = {}\n",
    "        \n",
    "        for method in self.tm_methods:\n",
    "            # test different template matching methods and select the best one\n",
    "            accuracy, location = self._match_template(image, template, method)\n",
    "            accuracies_and_locations[accuracy] = location\n",
    "        best_accuracy = max(accuracies_and_locations.keys())\n",
    "        self._evaluate_template_matching(best_accuracy)\n",
    "            \n",
    "        if self.template_matched:\n",
    "            # optional: visualize template matching \n",
    "            if self.visualize_matching:\n",
    "                self._visualize_template_matching(image, template, location = accuracies_and_locations[best_accuracy])\n",
    "            return template, location\n",
    "                    \n",
    "        if self.template_matched == False:\n",
    "            print('template is not fit for template matching! Use .create_template to create a new template for this object:', object_of_interest, camera)\n",
    "            self.template_matching_ongoing = False\n",
    "            return template, location # usually not passed, but the matching worked really bad xD\n",
    "    \n",
    "    \n",
    "    def _match_template(self, image: str, template: str, method: str) -> (int, (int, int)):\n",
    "        # matches template to image and returns accuracy and location of top left corner \n",
    "        img = image.copy()\n",
    "        # Correct illumination in the image\n",
    "        corrected_img = pcv.transform.nonuniform_illumination(img=img, ksize=31)\n",
    "        corrected_template = pcv.transform.nonuniform_illumination(img=template, ksize=31)\n",
    "        \n",
    "        result = cv2.matchTemplate(image = corrected_img, templ = corrected_template, method = method)\n",
    "        min_value, max_value, min_location, max_location = cv2.minMaxLoc(result)\n",
    "        \n",
    "        if method == cv2.TM_SQDIFF_NORMED:\n",
    "            # the normed-/sqdiff methods have the position of the matched template in the min location\n",
    "            location = min_location\n",
    "            value = min_value\n",
    "            accuracy = 1-abs(0-value)\n",
    "        else:\n",
    "            # All other methods show the matched template position in the max location\n",
    "            location = max_location\n",
    "            value = max_value\n",
    "            accuracy = value\n",
    "        return  accuracy, location\n",
    "        \n",
    "        \n",
    "    def _visualize_template_matching(self, image: str, template: str, location: (int)):\n",
    "        height_template, width_template = template.shape\n",
    "        bottom_right_corner = (location[0] + width_template, location[1] + height_template)\n",
    "        cv2.rectangle(image, location, bottom_right_corner, color = 0)\n",
    "        cv2.imshow('Template Matched Image', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows\n",
    "        \n",
    "    def _evaluate_template_matching(self, accuracy: int) -> bool:\n",
    "        if accuracy > self.template_matching_threshold:\n",
    "            print('Template matching worked with a ' + str(accuracy) + ' accuracy')\n",
    "            self.template_matched = True\n",
    "        else:\n",
    "             print('Template matching is not ideal, now trying a different method!')\n",
    "    \n",
    "    def _get_mean_coordinates(self, image: str, template: str, location: (int, int)) ->(int, int):\n",
    "        # get coordinates for input image\n",
    "        height_template, width_template = template.shape\n",
    "        center_coordinates =location[0] + width_template/2, location[1] + height_template/2        \n",
    "        return center_coordinates\n",
    "    \n",
    "    def _transpose_coordinates(self, coordinates: (int, int), ofset: (int, int)) ->(int, int):\n",
    "        # transpose coordinates from image slice to original image\n",
    "        return (coordinates[0] + ofset[0], coordinates[1] + ofset[1])\n",
    "    \n",
    "    def _check_whether_analyzed(self):\n",
    "        # Check for pickle file --> has this data already been analyzed? CURRENTLY NON FUNCTIONAL\n",
    "        file_exists = os.path.exists(self.directory_positions_jpg + 'object_coordinates.pickle')\n",
    "        if file_exists:            \n",
    "            inputquesiton = input('This data has already been analysed! \\n\\\n",
    "            Do you really want to reanalyse the data? This would overwrite the old coordinates\\\n",
    "            type \"yes\" or \"no\"')\n",
    "            if inputquesiton:\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "day220824 = TemplateMatching(path220824, visualize_matching= False)\n",
    "day220825 = TemplateMatching(path220825)\n",
    "day220826 = TemplateMatching(path220826)\n",
    "\n",
    "day220824.run()\n",
    "day220825.run()\n",
    "day220826.run()\n",
    "\n",
    "for day in [day220824, day220825, day220826]:\n",
    "    for cam in day.object_coordinates_per_camera.keys():\n",
    "        for obj in day.object_coordinates_per_camera[cam].keys():\n",
    "            image_temp = cv2.imread(day.cameras_and_paths_positions[cam])\n",
    "            coord1 = int(day.object_coordinates_per_camera[cam][obj][0])\n",
    "            coord2 = int(day.object_coordinates_per_camera[cam][obj][1])\n",
    "            cv2.circle(image_temp, (coord1, coord2), 2, (0,0,255), -1)\n",
    "            cv2.imshow('Sanity check for ' + str(cam) + ' ' + str(obj), image_temp)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cfdc6e",
   "metadata": {},
   "source": [
    "result: horrible accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeed2b8",
   "metadata": {},
   "source": [
    "## Konstantins image preprocessing before template matching (not working yet, due to conversion issues from open cv to np and backwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac219a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# konstantins image preprocessing function\n",
    "def image_preprocess(img, kernel_name):\n",
    "    #contrast enhancement\n",
    "    img = Image.fromarray(img)\n",
    "    img_contr_obj=ImageEnhance.Contrast(img)\n",
    "    img=img_contr_obj.enhance(2)\n",
    "    img = np.array(img)\n",
    "    \n",
    "    \n",
    "    #kernel application\n",
    "    img = np.array(img)\n",
    "    if kernel_name == \"sharpening\":\n",
    "        kernel = np.array([[0, -1, 0],\n",
    "                        [-1, 5, -1],\n",
    "                        [0, -1, 0]])\n",
    "    elif kernel_name == \"edge_detection\":\n",
    "         kernel = np.array([[0, -1, 0],\n",
    "                        [-1, 4, -1],\n",
    "                        [0, -1, 0]])\n",
    "    \n",
    "    kerneled_single_color_frames = []\n",
    "    for rgb_index in range(3):\n",
    "        image_convolved = convolve2d(img[:,:,rgb_index], kernel, 'valid')\n",
    "        kerneled_single_color_frames.append(image_convolved)\n",
    "\n",
    "    kerneled_frame = np.asarray(kerneled_single_color_frames)\n",
    "    kerneled_frame = np.moveaxis(kerneled_frame, 0, -1)\n",
    "    \n",
    "    img = kerneled_frame\n",
    "    \n",
    "    #binarization\n",
    "    mean = (img.max() + img.min())/2\n",
    "    img = np.where(img < mean, img, 255) \n",
    "    img = np.where(img > mean, img, 0)\n",
    "    img = img.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df06453a",
   "metadata": {},
   "source": [
    "### open cv matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "019d874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_preprocess function already used (in _match_template)\n",
    "\n",
    "class TemplateMatching(ABC):\n",
    "    \"\"\"\n",
    "    input: directory of positions jpg for template matching (e.g. 'C:\\\\user\\\\MS\\\\MouseData\\\\positions220831\\\\')\n",
    "            optional input: visualize_matching = Bool -> shows each plot for template matching\n",
    "    output: dictionary{ camera: {object: coordinates}}, naming of the file: \"results_template_matching.pickle\"\n",
    "    \n",
    "    commands:\n",
    "    \n",
    "    TemplateMatching.run(filepath)\n",
    "        performing template matching. results found in \"results_template_matching.pickle\" and\n",
    "        TemplateMatching.object_coordinates_per_camera\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def template_directory(self) ->str:\n",
    "        # specifies the directory for originally used templates\n",
    "        return r\"C:\\\\Users\\\\MS\\\\Documents\\\\Studium\\\\OpeningTrack\\\\coding\\\\test_data\\\\templates_obj\\\\\"\n",
    "    \n",
    "    @property\n",
    "    def template_naming(self) ->str:\n",
    "        # specifies the naming of the templates\n",
    "        return 'template.jpg'\n",
    "    \n",
    "    @property\n",
    "    def matching_naming(self) -> str:\n",
    "        # specifies the naming of the jpgs to be matched\n",
    "        return 'Positions.jpg'\n",
    "    \n",
    "    @property\n",
    "    def template_matching_threshold(self) ->str:\n",
    "        return 0.95\n",
    "    \n",
    "    @property\n",
    "    def all_cameras(self) ->str:\n",
    "        return ['Bottom', 'Side1', 'Side2', 'Ground1', 'Ground2', 'Top']\n",
    "    \n",
    "    def __init__(self, directory_positions_jpg: str, visualize_matching = False):\n",
    "        \n",
    "        # set path positions.jpgs from input\n",
    "        self.directory_positions_jpg = directory_positions_jpg\n",
    "        self.tm_methods = [cv2.TM_CCOEFF_NORMED, cv2.TM_CCORR_NORMED, cv2.TM_SQDIFF_NORMED]\n",
    "        self.visualize_matching = visualize_matching\n",
    "        \n",
    "        \n",
    "    def run(self) -> dict:    \n",
    "        # create dictionary with {camera: imagepath}\n",
    "        self.cameras_and_paths_positions = self._create_cameras_and_paths_dictionary(self.directory_positions_jpg, \n",
    "                                                                                     self.matching_naming)\n",
    "        print('The following cameras have been found:',self.cameras_and_paths_positions.keys())\n",
    "\n",
    "        # create dictionary {camera: {object: {level: templatepath}}}   \n",
    "        self.cameras_and_paths_template = self._create_cameras_and_paths_dictionary(self.template_directory,\n",
    "                                                                                    self.template_naming)\n",
    "        \n",
    "        # create results dictionary {camera: {(object: x-coordinate, y-coordinate)}}\n",
    "        self.object_coordinates_per_camera = {}\n",
    "        \n",
    "        # main loop    \n",
    "        for camera in self.cameras_and_paths_positions.keys():\n",
    "            \n",
    "            \n",
    "            self.object_coordinates_per_camera[camera] = {}\n",
    "            \n",
    "            # load image\n",
    "            original_image = cv2.imread(self.cameras_and_paths_positions[camera], 0)\n",
    "            \n",
    "            \n",
    "            for object_of_interest in self.cameras_and_paths_template[camera].keys():\n",
    "                \n",
    "                \n",
    "                print('Now working on ', camera, object_of_interest)\n",
    "                \n",
    "                # level 1\n",
    "                image = original_image.copy()\n",
    "                template, location = self._iterate_template_matching(camera = camera, image = image,\n",
    "                                                                     level = str(1), object_of_interest = object_of_interest)\n",
    "\n",
    "                # level 2\n",
    "                ofset = location\n",
    "                image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                template, location = self._iterate_template_matching(image = image, camera = camera,\n",
    "                                                                     level = str(2), object_of_interest = object_of_interest)\n",
    "\n",
    "                \n",
    "                if '3' not in self.cameras_and_paths_template[camera][object_of_interest].keys():\n",
    "                    # save results in self.object_coordinates_per_camera\n",
    "                    coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                    transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                    self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "\n",
    "                else:\n",
    "                    # level 3\n",
    "                    ofset = (ofset[0] + location[0], ofset[1]+location[1])\n",
    "                    image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                    template, location = self._iterate_template_matching(image = image, camera = camera, \n",
    "                                                                         level = str(3), object_of_interest = object_of_interest)\n",
    "                    if '4'not in self.cameras_and_paths_template[camera][object_of_interest].keys():\n",
    "                        # save results in f.object_coordinates_per_camera\n",
    "                        coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                        transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                        self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "                        \n",
    "                    else:\n",
    "                        # level 4\n",
    "                        ofset = (ofset[0] + location[0], ofset[1]+location[1])\n",
    "                        image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                        template, location = self._iterate_template_matching(image = image, camera = camera, \n",
    "                                                                         level = str(4), object_of_interest = object_of_interest)\n",
    "                        coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                        transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                        self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "                        \n",
    "        \n",
    "        # saving self.object_coordinates_per_camera as object_coordinates.pickle\n",
    "        with open(self.directory_positions_jpg + 'results_template_matching.pickle', 'wb') as f:\n",
    "            pickle.dump(self.object_coordinates_per_camera, f, pickle.HIGHEST_PROTOCOL)\n",
    "  \n",
    "        \n",
    "    def _create_cameras_and_paths_dictionary(self, path: str, naming_flag: str) -> dict:\n",
    "        # create a dictionary for easy file loading\n",
    "        \n",
    "        filepaths = [path + elem for elem in os.listdir(path) if elem.endswith(naming_flag)]\n",
    "        \n",
    "        \n",
    "        # templates\n",
    "        if 'level' in filepaths[0]:\n",
    "            files = {}\n",
    "            cameras = []\n",
    "            for filepath in filepaths:\n",
    "                if filepath.endswith(naming_flag):\n",
    "                    split_name = filepath.split(\"_\")\n",
    "                    camera, objecttofind, level = split_name[-4], split_name[-3], split_name[-2]\n",
    "                    cameras.append(camera)\n",
    "                    #objects.append(objecttofind)\n",
    "                    #levels.append(level)\n",
    "            for cam in cameras:\n",
    "                files[cam] = {}\n",
    "                objectstofind = [elem[elem.index(cam)+len(cam)+1:elem.index('_level')] for\n",
    "                                      elem in os.listdir(path) if cam in elem and elem.endswith(naming_flag)]\n",
    "                for objecttofind in objectstofind:\n",
    "                    files[cam][objecttofind] = {}             \n",
    "                    cam_filepaths = [elem for elem in filepaths if cam in elem and str(objecttofind) in elem]\n",
    "                    levels = [elem[elem.index('level')+5:elem.index('level')+6] for elem in os.listdir(path) \n",
    "                              if cam in elem and str(objecttofind) in elem and elem.endswith(naming_flag)]\n",
    "                    for i in range(len(levels)):\n",
    "                        files[cam][objecttofind].update({levels[i]: cam_filepaths[i]})\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            return files\n",
    "        \n",
    "        # images\n",
    "        else:\n",
    "            # list comprehension for getting cameras\n",
    "            cameras = [elem[7:(elem.index(naming_flag)-1)] for elem in os.listdir(path) if elem.endswith(naming_flag)]\n",
    "            return dict(zip(cameras, filepaths)) \n",
    "                                 \n",
    "    def _iterate_template_matching(self, camera: str, image: str, level: str, object_of_interest: str) -> (str, (int, int)):\n",
    "        # use template matching function to perform template matching for each level\n",
    "        \n",
    "        self.template_matched = False\n",
    "        template = cv2.imread(self.cameras_and_paths_template[camera][object_of_interest][level], 0)\n",
    "        \n",
    "        accuracies_and_locations = {}\n",
    "        \n",
    "        for method in self.tm_methods:\n",
    "            # test different template matching methods and select the best one\n",
    "            accuracy, location = self._match_template(image, template, method)\n",
    "            accuracies_and_locations[accuracy] = location\n",
    "        best_accuracy = max(accuracies_and_locations.keys())\n",
    "        self._evaluate_template_matching(best_accuracy)\n",
    "            \n",
    "        if self.template_matched:\n",
    "            # optional: visualize template matching \n",
    "            if self.visualize_matching:\n",
    "                self._visualize_template_matching(image, template, location = accuracies_and_locations[best_accuracy])\n",
    "            return template, location\n",
    "                    \n",
    "        if self.template_matched == False:\n",
    "            print('template is not fit for template matching! Use .create_template to create a new template for this object:', object_of_interest, camera)\n",
    "            self.template_matching_ongoing = False\n",
    "            return template, location # usually not passed, but the matching worked really bad xD\n",
    "    \n",
    "    \n",
    "    def _match_template(self, image: str, template: str, method: str) -> (int, (int, int)):\n",
    "        # matches template to image and returns accuracy and location of top left corner \n",
    "        img = image.copy()\n",
    "        # Correct illumination in the image\n",
    "        corrected_img = image_preprocess(img, \"sharpening\")\n",
    "        corrected_template = image_preprocess(template, \"sharpening\")\n",
    "        \n",
    "        result = cv2.matchTemplate(image = corrected_img, templ = corrected_template, method = method)\n",
    "        min_value, max_value, min_location, max_location = cv2.minMaxLoc(result)\n",
    "        \n",
    "        if method == cv2.TM_SQDIFF_NORMED:\n",
    "            # the normed-/sqdiff methods have the position of the matched template in the min location\n",
    "            location = min_location\n",
    "            value = min_value\n",
    "            accuracy = 1-abs(0-value)\n",
    "        else:\n",
    "            # All other methods show the matched template position in the max location\n",
    "            location = max_location\n",
    "            value = max_value\n",
    "            accuracy = value\n",
    "        return  accuracy, location\n",
    "        \n",
    "        \n",
    "    def _visualize_template_matching(self, image: str, template: str, location: (int)):\n",
    "        height_template, width_template = template.shape\n",
    "        bottom_right_corner = (location[0] + width_template, location[1] + height_template)\n",
    "        cv2.rectangle(image, location, bottom_right_corner, color = 0)\n",
    "        cv2.imshow('Template Matched Image', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows\n",
    "        \n",
    "    def _evaluate_template_matching(self, accuracy: int) -> bool:\n",
    "        if accuracy > self.template_matching_threshold:\n",
    "            print('Template matching worked with a ' + str(accuracy) + ' accuracy')\n",
    "            self.template_matched = True\n",
    "        else:\n",
    "             print('Template matching is not ideal, now trying a different method!')\n",
    "    \n",
    "    def _get_mean_coordinates(self, image: str, template: str, location: (int, int)) ->(int, int):\n",
    "        # get coordinates for input image\n",
    "        height_template, width_template = template.shape\n",
    "        center_coordinates =location[0] + width_template/2, location[1] + height_template/2        \n",
    "        return center_coordinates\n",
    "    \n",
    "    def _transpose_coordinates(self, coordinates: (int, int), ofset: (int, int)) ->(int, int):\n",
    "        # transpose coordinates from image slice to original image\n",
    "        return (coordinates[0] + ofset[0], coordinates[1] + ofset[1])\n",
    "    \n",
    "    def _check_whether_analyzed(self):\n",
    "        # Check for pickle file --> has this data already been analyzed? CURRENTLY NON FUNCTIONAL\n",
    "        file_exists = os.path.exists(self.directory_positions_jpg + 'object_coordinates.pickle')\n",
    "        if file_exists:            \n",
    "            inputquesiton = input('This data has already been analysed! \\n\\\n",
    "            Do you really want to reanalyse the data? This would overwrite the old coordinates\\\n",
    "            type \"yes\" or \"no\"')\n",
    "            if inputquesiton:\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba54b6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following cameras have been found: dict_keys(['Bottom', 'Ground2', 'Side1'])\n",
      "Now working on  Bottom screw1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m day220825 \u001b[38;5;241m=\u001b[39m TemplateMatching(path220825)\n\u001b[0;32m      3\u001b[0m day220826 \u001b[38;5;241m=\u001b[39m TemplateMatching(path220826)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mday220824\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m day220825\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m      7\u001b[0m day220826\u001b[38;5;241m.\u001b[39mrun()\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mTemplateMatching.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# level 1\u001b[39;00m\n\u001b[0;32m     74\u001b[0m image \u001b[38;5;241m=\u001b[39m original_image\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 75\u001b[0m template, location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterate_template_matching\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcamera\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcamera\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_of_interest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobject_of_interest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# level 2\u001b[39;00m\n\u001b[0;32m     79\u001b[0m ofset \u001b[38;5;241m=\u001b[39m location\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mTemplateMatching._iterate_template_matching\u001b[1;34m(self, camera, image, level, object_of_interest)\u001b[0m\n\u001b[0;32m    164\u001b[0m accuracies_and_locations \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtm_methods:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# test different template matching methods and select the best one\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     accuracy, location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_match_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     accuracies_and_locations[accuracy] \u001b[38;5;241m=\u001b[39m location\n\u001b[0;32m    170\u001b[0m best_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(accuracies_and_locations\u001b[38;5;241m.\u001b[39mkeys())\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mTemplateMatching._match_template\u001b[1;34m(self, image, template, method)\u001b[0m\n\u001b[0;32m    187\u001b[0m img \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Correct illumination in the image\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m corrected_img \u001b[38;5;241m=\u001b[39m \u001b[43mimage_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharpening\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m corrected_template \u001b[38;5;241m=\u001b[39m image_preprocess(template, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msharpening\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    192\u001b[0m result \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mmatchTemplate(image \u001b[38;5;241m=\u001b[39m corrected_img, templ \u001b[38;5;241m=\u001b[39m corrected_template, method \u001b[38;5;241m=\u001b[39m method)\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mimage_preprocess\u001b[1;34m(img, kernel_name)\u001b[0m\n\u001b[0;32m     20\u001b[0m kerneled_single_color_frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rgb_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m---> 22\u001b[0m     image_convolved \u001b[38;5;241m=\u001b[39m convolve2d(\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrgb_index\u001b[49m\u001b[43m]\u001b[49m, kernel, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m     kerneled_single_color_frames\u001b[38;5;241m.\u001b[39mappend(image_convolved)\n\u001b[0;32m     25\u001b[0m kerneled_frame \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(kerneled_single_color_frames)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "day220824 = TemplateMatching(path220824, visualize_matching= False)\n",
    "day220825 = TemplateMatching(path220825)\n",
    "day220826 = TemplateMatching(path220826)\n",
    "\n",
    "day220824.run()\n",
    "day220825.run()\n",
    "day220826.run()\n",
    "\n",
    "for day in [day220824, day220825, day220826]:\n",
    "    for cam in day.object_coordinates_per_camera.keys():\n",
    "        for obj in day.object_coordinates_per_camera[cam].keys():\n",
    "            image_temp = cv2.imread(day.cameras_and_paths_positions[cam])\n",
    "            coord1 = int(day.object_coordinates_per_camera[cam][obj][0])\n",
    "            coord2 = int(day.object_coordinates_per_camera[cam][obj][1])\n",
    "            cv2.circle(image_temp, (coord1, coord2), 2, (0,0,255), -1)\n",
    "            cv2.imshow('Sanity check for ' + str(cam) + ' ' + str(obj), image_temp)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca24823d",
   "metadata": {},
   "source": [
    "### Scikit matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fffb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_preprocess function already used (in _match_template)\n",
    "\n",
    "class TemplateMatching(ABC):\n",
    "    \"\"\"\n",
    "    input: directory of positions jpg for template matching (e.g. 'C:\\\\user\\\\MS\\\\MouseData\\\\positions220831\\\\')\n",
    "            optional input: visualize_matching = Bool -> shows each plot for template matching\n",
    "    output: dictionary{ camera: {object: coordinates}}, naming of the file: \"results_template_matching.pickle\"\n",
    "    \n",
    "    commands:\n",
    "    \n",
    "    TemplateMatching.run(filepath)\n",
    "        performing template matching. results found in \"results_template_matching.pickle\" and\n",
    "        TemplateMatching.object_coordinates_per_camera\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def template_directory(self) ->str:\n",
    "        # specifies the directory for originally used templates\n",
    "        return r\"C:\\\\Users\\\\MS\\\\Documents\\\\Studium\\\\OpeningTrack\\\\coding\\\\test_data\\\\templates_obj\\\\\"\n",
    "    \n",
    "    @property\n",
    "    def template_naming(self) ->str:\n",
    "        # specifies the naming of the templates\n",
    "        return 'template.jpg'\n",
    "    \n",
    "    @property\n",
    "    def matching_naming(self) -> str:\n",
    "        # specifies the naming of the jpgs to be matched\n",
    "        return 'Positions.jpg'\n",
    "    \n",
    "    @property\n",
    "    def template_matching_threshold(self) ->str:\n",
    "        return 0.95\n",
    "    \n",
    "    @property\n",
    "    def all_cameras(self) ->str:\n",
    "        return ['Bottom', 'Side1', 'Side2', 'Ground1', 'Ground2', 'Top']\n",
    "    \n",
    "    def __init__(self, directory_positions_jpg: str, visualize_matching = False):\n",
    "        \n",
    "        # set path positions.jpgs from input\n",
    "        self.directory_positions_jpg = directory_positions_jpg\n",
    "        self.tm_methods = [cv2.TM_CCOEFF_NORMED, cv2.TM_CCORR_NORMED, cv2.TM_SQDIFF_NORMED]\n",
    "        self.visualize_matching = visualize_matching\n",
    "        \n",
    "        \n",
    "    def run(self) -> dict:    \n",
    "        # create dictionary with {camera: imagepath}\n",
    "        self.cameras_and_paths_positions = self._create_cameras_and_paths_dictionary(self.directory_positions_jpg, \n",
    "                                                                                     self.matching_naming)\n",
    "        print('The following cameras have been found:',self.cameras_and_paths_positions.keys())\n",
    "\n",
    "        # create dictionary {camera: {object: {level: templatepath}}}   \n",
    "        self.cameras_and_paths_template = self._create_cameras_and_paths_dictionary(self.template_directory,\n",
    "                                                                                    self.template_naming)\n",
    "        \n",
    "        # create results dictionary {camera: {(object: x-coordinate, y-coordinate)}}\n",
    "        self.object_coordinates_per_camera = {}\n",
    "        \n",
    "        # main loop    \n",
    "        for camera in self.cameras_and_paths_positions.keys():\n",
    "            \n",
    "            \n",
    "            self.object_coordinates_per_camera[camera] = {}\n",
    "            \n",
    "            # load image\n",
    "            original_image = cv2.imread(self.cameras_and_paths_positions[camera], 0)\n",
    "            \n",
    "            \n",
    "            for object_of_interest in self.cameras_and_paths_template[camera].keys():\n",
    "                \n",
    "                \n",
    "                print('Now working on ', camera, object_of_interest)\n",
    "                \n",
    "                # level 1\n",
    "                image = original_image.copy()\n",
    "                template, location = self._iterate_template_matching(camera = camera, image = image,\n",
    "                                                                     level = str(1), object_of_interest = object_of_interest)\n",
    "\n",
    "                # level 2\n",
    "                ofset = location\n",
    "                image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                template, location = self._iterate_template_matching(image = image, camera = camera,\n",
    "                                                                     level = str(2), object_of_interest = object_of_interest)\n",
    "\n",
    "                \n",
    "                if '3' not in self.cameras_and_paths_template[camera][object_of_interest].keys():\n",
    "                    # save results in self.object_coordinates_per_camera\n",
    "                    coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                    transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                    self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "\n",
    "                else:\n",
    "                    # level 3\n",
    "                    ofset = (ofset[0] + location[0], ofset[1]+location[1])\n",
    "                    image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                    template, location = self._iterate_template_matching(image = image, camera = camera, \n",
    "                                                                         level = str(3), object_of_interest = object_of_interest)\n",
    "                    if '4'not in self.cameras_and_paths_template[camera][object_of_interest].keys():\n",
    "                        # save results in f.object_coordinates_per_camera\n",
    "                        coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                        transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                        self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "                        \n",
    "                    else:\n",
    "                        # level 4\n",
    "                        ofset = (ofset[0] + location[0], ofset[1]+location[1])\n",
    "                        image = image[location[1]:location[1]+template.shape[0], location[0]:location[0]+template.shape[1]]\n",
    "                        template, location = self._iterate_template_matching(image = image, camera = camera, \n",
    "                                                                         level = str(4), object_of_interest = object_of_interest)\n",
    "                        coordinates = self._get_mean_coordinates(image, template, location)\n",
    "                        transposed_coordinates = self._transpose_coordinates(coordinates, ofset)\n",
    "                        self.object_coordinates_per_camera[camera][object_of_interest] = transposed_coordinates\n",
    "                        \n",
    "        \n",
    "        # saving self.object_coordinates_per_camera as object_coordinates.pickle\n",
    "        with open(self.directory_positions_jpg + 'results_template_matching.pickle', 'wb') as f:\n",
    "            pickle.dump(self.object_coordinates_per_camera, f, pickle.HIGHEST_PROTOCOL)\n",
    "  \n",
    "        \n",
    "    def _create_cameras_and_paths_dictionary(self, path: str, naming_flag: str) -> dict:\n",
    "        # create a dictionary for easy file loading\n",
    "        \n",
    "        filepaths = [path + elem for elem in os.listdir(path) if elem.endswith(naming_flag)]\n",
    "        \n",
    "        \n",
    "        # templates\n",
    "        if 'level' in filepaths[0]:\n",
    "            files = {}\n",
    "            cameras = []\n",
    "            for filepath in filepaths:\n",
    "                if filepath.endswith(naming_flag):\n",
    "                    split_name = filepath.split(\"_\")\n",
    "                    camera, objecttofind, level = split_name[-4], split_name[-3], split_name[-2]\n",
    "                    cameras.append(camera)\n",
    "                    #objects.append(objecttofind)\n",
    "                    #levels.append(level)\n",
    "            for cam in cameras:\n",
    "                files[cam] = {}\n",
    "                objectstofind = [elem[elem.index(cam)+len(cam)+1:elem.index('_level')] for\n",
    "                                      elem in os.listdir(path) if cam in elem and elem.endswith(naming_flag)]\n",
    "                for objecttofind in objectstofind:\n",
    "                    files[cam][objecttofind] = {}             \n",
    "                    cam_filepaths = [elem for elem in filepaths if cam in elem and str(objecttofind) in elem]\n",
    "                    levels = [elem[elem.index('level')+5:elem.index('level')+6] for elem in os.listdir(path) \n",
    "                              if cam in elem and str(objecttofind) in elem and elem.endswith(naming_flag)]\n",
    "                    for i in range(len(levels)):\n",
    "                        files[cam][objecttofind].update({levels[i]: cam_filepaths[i]})\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            return files\n",
    "        \n",
    "        # images\n",
    "        else:\n",
    "            # list comprehension for getting cameras\n",
    "            cameras = [elem[7:(elem.index(naming_flag)-1)] for elem in os.listdir(path) if elem.endswith(naming_flag)]\n",
    "            return dict(zip(cameras, filepaths)) \n",
    "             \n",
    "            \n",
    "        def _iterate_template_matching(self, camera: str, image: str, level: str, object_of_interest: str) -> (str, (int, int)):\n",
    "        # use template matching function to perform template matching for each level\n",
    "        \n",
    "        self.template_matched = False\n",
    "        template = cv2.imread(self.cameras_and_paths_template[camera][object_of_interest][level], 0)\n",
    "         # matches template to image and returns accuracy and location of top left corner \n",
    "        img = image.copy()\n",
    "        preprocessed_image = image_preprocess(img, \"sharpening\")\n",
    "        preprocessed_template = image_preprocess(template, \"sharpening\")\n",
    "        result = match_template(preprocessed_image, preprocessed_template)\n",
    "        ij = np.unravel_index(np.argmax(result), result.shape)\n",
    "        x,y = ij[::-1]\n",
    "        location = (x,y)\n",
    "        if self.visualize_matching:\n",
    "            self._visualize_template_matching(img, template, location)\n",
    "\n",
    "        return  template, location\n",
    "    \n",
    "    \n",
    "    def _match_template(self, image: str, template: str, method: str) -> (int, (int, int)):\n",
    "        # matches template to image and returns accuracy and location of top left corner \n",
    "        img = image.copy()\n",
    "        # Correct illumination in the image\n",
    "        corrected_img = image_preprocess(img, \"sharpening\")\n",
    "        corrected_template = image_preprocess(template, \"sharpening\")\n",
    "        \n",
    "        result = cv2.matchTemplate(image = corrected_img, templ = corrected_template, method = method)\n",
    "        min_value, max_value, min_location, max_location = cv2.minMaxLoc(result)\n",
    "        \n",
    "        if method == cv2.TM_SQDIFF_NORMED:\n",
    "            # the normed-/sqdiff methods have the position of the matched template in the min location\n",
    "            location = min_location\n",
    "            value = min_value\n",
    "            accuracy = 1-abs(0-value)\n",
    "        else:\n",
    "            # All other methods show the matched template position in the max location\n",
    "            location = max_location\n",
    "            value = max_value\n",
    "            accuracy = value\n",
    "        return  accuracy, location\n",
    "        \n",
    "        \n",
    "    def _visualize_template_matching(self, image: str, template: str, location: (int)):\n",
    "        height_template, width_template = template.shape\n",
    "        bottom_right_corner = (location[0] + width_template, location[1] + height_template)\n",
    "        cv2.rectangle(image, location, bottom_right_corner, color = 0)\n",
    "        cv2.imshow('Template Matched Image', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows\n",
    "        \n",
    "    def _evaluate_template_matching(self, accuracy: int) -> bool:\n",
    "        if accuracy > self.template_matching_threshold:\n",
    "            print('Template matching worked with a ' + str(accuracy) + ' accuracy')\n",
    "            self.template_matched = True\n",
    "        else:\n",
    "             print('Template matching is not ideal, now trying a different method!')\n",
    "    \n",
    "    def _get_mean_coordinates(self, image: str, template: str, location: (int, int)) ->(int, int):\n",
    "        # get coordinates for input image\n",
    "        height_template, width_template = template.shape\n",
    "        center_coordinates =location[0] + width_template/2, location[1] + height_template/2        \n",
    "        return center_coordinates\n",
    "    \n",
    "    def _transpose_coordinates(self, coordinates: (int, int), ofset: (int, int)) ->(int, int):\n",
    "        # transpose coordinates from image slice to original image\n",
    "        return (coordinates[0] + ofset[0], coordinates[1] + ofset[1])\n",
    "    \n",
    "    def _check_whether_analyzed(self):\n",
    "        # Check for pickle file --> has this data already been analyzed? CURRENTLY NON FUNCTIONAL\n",
    "        file_exists = os.path.exists(self.directory_positions_jpg + 'object_coordinates.pickle')\n",
    "        if file_exists:            \n",
    "            inputquesiton = input('This data has already been analysed! \\n\\\n",
    "            Do you really want to reanalyse the data? This would overwrite the old coordinates\\\n",
    "            type \"yes\" or \"no\"')\n",
    "            if inputquesiton:\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abe5eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "day220824 = TemplateMatching(path220824, visualize_matching= False)\n",
    "day220825 = TemplateMatching(path220825)\n",
    "day220826 = TemplateMatching(path220826)\n",
    "\n",
    "day220824.run()\n",
    "day220825.run()\n",
    "day220826.run()\n",
    "\n",
    "for day in [day220824, day220825, day220826]:\n",
    "    for cam in day.object_coordinates_per_camera.keys():\n",
    "        for obj in day.object_coordinates_per_camera[cam].keys():\n",
    "            image_temp = cv2.imread(day.cameras_and_paths_positions[cam])\n",
    "            coord1 = int(day.object_coordinates_per_camera[cam][obj][0])\n",
    "            coord2 = int(day.object_coordinates_per_camera[cam][obj][1])\n",
    "            cv2.circle(image_temp, (coord1, coord2), 2, (0,0,255), -1)\n",
    "            cv2.imshow('Sanity check for ' + str(cam) + ' ' + str(obj), image_temp)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c1792",
   "metadata": {},
   "outputs": [],
   "source": [
    "day220824.object_coordinates_per_camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a0ef78",
   "metadata": {},
   "source": [
    "\n",
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6c23b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "day220824 = TemplateMatching(path220824, visualize_matching= False)\n",
    "day220825 = TemplateMatching(path220825)\n",
    "day220826 = TemplateMatching(path220826)\n",
    "\n",
    "day220824.run()\n",
    "day220825.run()\n",
    "day220826.run()\n",
    "\n",
    "for day in [day220824, day220825, day220826]:\n",
    "    for cam in day.object_coordinates_per_camera.keys():\n",
    "        for obj in day.object_coordinates_per_camera[cam].keys():\n",
    "            image_temp = cv2.imread(day.cameras_and_paths_positions[cam])\n",
    "            coord1 = int(day.object_coordinates_per_camera[cam][obj][0])\n",
    "            coord2 = int(day.object_coordinates_per_camera[cam][obj][1])\n",
    "            cv2.circle(image_temp, (coord1, coord2), 2, (0,0,255), -1)\n",
    "            cv2.imshow('Sanity check for ' + str(cam) + ' ' + str(obj), image_temp)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80001fe6",
   "metadata": {},
   "source": [
    "Future notes:\n",
    "- would be great to use the same template for specific objects, like all screws, all backcorners, ...\n",
    "    However, it then is basically a matter of making the code more complicated instead the template folder. I doubt that any option is prefereable here.\n",
    "- build more templates\n",
    "- Switch to scikit for template matching, as open cv does not perform as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10dcab8",
   "metadata": {},
   "source": [
    "Sanity check failed on 220824 Bottom screw1+screw2 and 220826 Side2 screw1. not great."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ca80f6",
   "metadata": {},
   "source": [
    "# Code graveyard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46017300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different, nonfunctional solution for generating template dictionaries\n",
    "for filepath in filepaths:\n",
    "    if filepath.endswith(naming_flag):\n",
    "        split_name = filepath.split(\"_\")\n",
    "        camera, objecttofind, level = split_name[-4], split_name[-3], split_name[-2]\n",
    "        cameras, objects, levels = [], [], []\n",
    "        cameras.append(camera)\n",
    "        objects.append(objecttofind)\n",
    "        levels.append(level)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
