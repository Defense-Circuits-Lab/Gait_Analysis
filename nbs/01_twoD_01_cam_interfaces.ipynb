{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# twoD/cam_interfaces\n",
    "\n",
    "> Analysis of DLC tracking data based on the recordings with individual cameras\n",
    "\n",
    "Currently, only analysis using a camera positioned above the maze is supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp twoD/cam_interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from typing import Tuple, List, Dict, Optional, Union\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gait_analysis.core import TrackedRecording\n",
    "from gait_analysis.twoD import utils, preprocess, detect, export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class TopTracked2DRecording(TrackedRecording):\n",
    "    \"\"\"\n",
    "    Very customized subclass of `TrackedRecording` that was designed to run the gait analysis\n",
    "    on 2D tracking data obtained from a single camera with a top-down-view on the subject.    \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def _load_remaining_metadata(self) -> None:\n",
    "        self.fps = self._get_correct_fps()\n",
    "        self.framerate = 1/self.fps\n",
    "        self.metadata = self._retrieve_metadata(filename = self.filepath.name)\n",
    "        \n",
    "\n",
    "    def _get_correct_fps(self) -> int:\n",
    "        if self.loaded_tracking_df.shape[0] > 25_000:\n",
    "            fps = 80\n",
    "        else:\n",
    "            fps = 30\n",
    "        return fps\n",
    "\n",
    "\n",
    "    def _retrieve_metadata(self, filename: str)->Dict:\n",
    "        \"\"\"\n",
    "        Very much dependent on the following file naming convention:\n",
    "        LLL_FS-SS_YYMMDD_PPP_whatever.h5 (or .csv)\n",
    "        Where:\n",
    "            LLL: three digits mouse line code\n",
    "            FS-SS: the subject ID (must start with capital F) with generation (e.g. F2 for second generation) and the mouse ID as two digits\n",
    "            YYMMDD: the date of the recording as two digits year (YY), month (MM), and day (DD)\n",
    "            PPP: the three letter string of the experimental paradigm\n",
    "        For instance:\n",
    "            196_F7-27_220826_OTT_whatever.h5\n",
    "        \"\"\"\n",
    "        splits = filename.split('_')\n",
    "        line_id, mouse_id, date, paradigm_id, cam_id = splits[0], splits[1], splits[2], splits[3][0:3], 'Top'\n",
    "        self._check_metadata(metadata = (line_id, mouse_id, date, paradigm_id, cam_id))\n",
    "        metadata = {'recording_date': self.recording_date, \n",
    "                    'animal': f'{self.mouse_line}_{self.mouse_id}', \n",
    "                    'paradigm': self.paradigm, \n",
    "                    'cam': self.cam_id}\n",
    "        return metadata\n",
    "    \n",
    "    \n",
    "    # ToDo - replace with something more generalizable that could be put to utils\n",
    "    def _check_metadata(self, \n",
    "                        metadata = Tuple[str]\n",
    "                       ) -> None: \n",
    "        animal_line, animal_id, recording_date, paradigm, cam_id = metadata[0], metadata[1], metadata[2], metadata[3], metadata[4]\n",
    "        self.cam_id = cam_id\n",
    "        if animal_line not in self.valid_mouse_lines:\n",
    "            while True:\n",
    "                entered_input = input(f'Mouse line for {self.filepath}')\n",
    "                if entered_input in self.valid_mouse_lines:\n",
    "                    self.mouse_line = entered_input\n",
    "                    break\n",
    "                else:\n",
    "                    print(f'Entered mouse line does not match any of the defined mouse lines. \\nPlease enter one of the following lines: {self.valid_mouse_lines}')\n",
    "        else:\n",
    "            self.mouse_line = animal_line\n",
    "        if not animal_id.startswith('F'):\n",
    "            while True:\n",
    "                entered_input = input(f'Mouse ID for {self.filepath}')\n",
    "                if entered_input.startswith('F'):\n",
    "                    self.mouse_id = entered_input\n",
    "                    break\n",
    "                else:\n",
    "                    print(f'Animal ID has to start with F. Example: F2-14')\n",
    "        else:\n",
    "            self.mouse_id = animal_id\n",
    "        if paradigm not in self.valid_paradigms:\n",
    "            while True:\n",
    "                entered_input = input(f'Paradigm for {self.filepath}')\n",
    "                if entered_input in self.valid_paradigms:\n",
    "                    self.paradigm = entered_input\n",
    "                    break\n",
    "                else:\n",
    "                    print(f'Entered paradigm does not match any of the defined paradigms. \\nPlease enter one of the following paradigms: {self.valid_paradigms}')\n",
    "        else:\n",
    "            self.paradigm = paradigm\n",
    "        try:\n",
    "            int(recording_date)\n",
    "            self.recording_date = recording_date\n",
    "        except:\n",
    "            while True:\n",
    "                entered_input = input(f'Recording date for {self.filepath}')\n",
    "                try:\n",
    "                    int(recording_date)\n",
    "                    self.recording_date = recording_date\n",
    "                    break\n",
    "                except:\n",
    "                    print(f'Entered recording date has to be an integer in shape YYMMDD. Example: 220812')\n",
    "\n",
    "\n",
    "    def preprocess_tracking(self,\n",
    "                           marker_ids_to_compute_coverage: List[str]=['TailBase', 'Snout'], # List of marker_ids on base of which the tracking coverage will be computed\n",
    "                           coverage_threshold: float=0.75, # If coverage of the above defined markers is lower than this threshold, the recording will be excluded from the analysis and therefore not further processed \n",
    "                           max_seconds_to_interpolate: float=0.5, # Maximum time interval in which consecutive nan´s will be interpolated\n",
    "                           likelihood_threshold: float=0.5, # Minimum prediction likelihood of DLC that is required to acceppt predicted marker position as valid \n",
    "                           marker_ids_to_compute_center_of_gravity: List[str]=['TailBase', 'Snout'], # marker ids that will be used to compute the center of gravity\n",
    "                           relative_maze_normalization_error_tolerance: float=0.25 # relative error that is tolerated when estimating the maze position for normalizing it´s position\n",
    "                           ) -> None:\n",
    "        \"\"\"\n",
    "        Initiate the preprocessing of the DLC output tracking data. This includes smoothing, \n",
    "        interpolation of small intervals with low likelihoods, and creation of additional markers, \n",
    "        like a center of gravity. Furthermore, the code will identify the most reliable \n",
    "        predicted position of the maze corners and evaluate, whether the reconstructed maze using\n",
    "        these most reliable open corner positions yields a maze that is sufficiently similar to how the\n",
    "        maze should look like (less than a specified relative error threshold). If it meets this\n",
    "        criterion, it will use the open corner from there on to normalize the coordinate system.\n",
    "        If not, it will compute everything just based on the closed corners. Either way, the\n",
    "        coordinate system will be normalized to the closed left corner, applying rotation and\n",
    "        shifting, and eventually convert the coordinates into cm values. As the very last step, \n",
    "        self.bodyparts will be created - a dictionary that contains an `Bodypart` object for each\n",
    "        marker id. Logs will save all parameters specified upon calling the function to make it\n",
    "        easily traceable, which parameter settings were used to obtain a given result (see also\n",
    "        the documentation of the `export_results()` method.\n",
    "        \"\"\"\n",
    "        initial_logs_to_add = {'critical_markers_to_compute_coverage': marker_ids_to_compute_coverage,\n",
    "                               'coverage_threshold': coverage_threshold,\n",
    "                               'max_seconds_to_interpolate': max_seconds_to_interpolate,\n",
    "                               'min_likelihood_threshold': likelihood_threshold,\n",
    "                               'center_of_gravity_based_on': marker_ids_to_compute_center_of_gravity, \n",
    "                               'relative_error_tolerance_corner_detection': relative_maze_normalization_error_tolerance}\n",
    "        window_length = utils.get_max_odd_n_frames_for_time_interval(fps = self.fps, time_interval = max_seconds_to_interpolate)\n",
    "        marker_ids_to_preprocess = preprocess.get_preprocessing_relevant_marker_ids(df = self.loaded_tracking_df,\n",
    "                                                                                    marker_ids_to_exclude = self.marker_ids_to_exclude_for_smoothing_and_interpolation)\n",
    "        smoothed_df = preprocess.smooth_tracked_coords_and_likelihood(df = self.loaded_tracking_df, \n",
    "                                                                      window_length = window_length,\n",
    "                                                                      marker_ids = marker_ids_to_preprocess, \n",
    "                                                                      polyorder = 3)\n",
    "        interpolated_df = preprocess.interpolate_low_likelihood_intervals(df = smoothed_df, \n",
    "                                                                          marker_ids = marker_ids_to_preprocess, \n",
    "                                                                          max_interval_length = window_length,\n",
    "                                                                          framerate = self.framerate)\n",
    "        interpolated_df_with_cog = preprocess.add_new_marker_derived_from_existing_markers(df = interpolated_df,\n",
    "                                                                                      existing_markers = marker_ids_to_compute_center_of_gravity,\n",
    "                                                                                      new_marker_id = 'CenterOfGravity',\n",
    "                                                                                      likelihood_threshold = likelihood_threshold)\n",
    "        preprocessed_df = preprocess.interpolate_low_likelihood_intervals(df = interpolated_df_with_cog, \n",
    "                                                                          marker_ids = ['CenterOfGravity'], \n",
    "                                                                          max_interval_length = window_length,\n",
    "                                                                          framerate = self.framerate)        \n",
    "        coverage_critical_markers = utils.compute_coverage(df = preprocessed_df,\n",
    "                                                                critical_marker_ids = marker_ids_to_compute_coverage,\n",
    "                                                                likelihood_threshold = likelihood_threshold)\n",
    "        initial_logs_to_add['coverage_critical_markers'] = coverage_critical_markers\n",
    "        self._add_to_logs(logs_to_add = initial_logs_to_add)\n",
    "        if coverage_critical_markers >= coverage_threshold:\n",
    "            normalization_params = self._get_parameters_to_normalize_maze_coordinates(df = preprocessed_df,\n",
    "                                                                                      relative_error_tolerance = relative_maze_normalization_error_tolerance)\n",
    "            self.normalized_df = preprocess.normalize_df(df = preprocessed_df, normalization_parameters = normalization_params)\n",
    "            self.bodyparts = preprocess.create_bodypart_objects(normalized_df = self.normalized_df, fps = self.fps)\n",
    "            normalized_maze_corner_coords = self._get_normalized_maze_corners(normalization_parameters = normalization_params)\n",
    "            coverage_center_of_gravity = utils.compute_coverage(df = self.normalized_df,\n",
    "                                                                     critical_marker_ids = ['CenterOfGravity'],\n",
    "                                                                     likelihood_threshold = likelihood_threshold)\n",
    "            additional_logs_to_add = {'coverage_CenterOfGravity': coverage_center_of_gravity}\n",
    "            for key, value in normalization_params.items():\n",
    "                additional_logs_to_add[key] = value\n",
    "            for key, value in normalized_maze_corner_coords.items():\n",
    "                additional_logs_to_add[f'normalized_{key}_coords'] = value\n",
    "            self._add_to_logs(logs_to_add = additional_logs_to_add)\n",
    "            \n",
    "    \n",
    "    def _add_to_logs(self,\n",
    "                     logs_to_add: Dict # key-value pairs of things that shall be added to the logs of the recording\n",
    "                    ) -> None:\n",
    "        \"\"\"\n",
    "        At the end of all the processing, the \"logged\" data will be saved in the results .xlsx file.\n",
    "        It thus allows the user to keep track of which settings they used for the respective analysis.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'logs') == False:\n",
    "            self.logs = {}\n",
    "        for key, value in logs_to_add.items():\n",
    "            assert key not in self.logs.keys(), f'{key} is already in self.logs.keys - adding it would result in overwriting the previous entry; please ensure unique naming'\n",
    "            self.logs[key] = value \n",
    "    \n",
    "    \n",
    "    def _get_parameters_to_normalize_maze_coordinates(self, df: pd.DataFrame, relative_error_tolerance: float) -> Dict:\n",
    "        corners = preprocess.get_corner_coords_with_likelihoods(df = df)\n",
    "        translation_vector = preprocess.get_translation_vector(coords_to_become_origin = corners['MazeCornerClosedLeft']['coords'])\n",
    "        best_result = preprocess.evaluate_maze_shape_using_open_corners(corners_and_likelihoods = corners, \n",
    "                                                                        tolerance = relative_error_tolerance)\n",
    "        if best_result['valid']:\n",
    "            side_id = best_result['side_id']\n",
    "            logs_to_add = {'maze_normalization_based_on': f'MazeCornerClosed{side_id}_and_MazeCornerOpen{side_id}'}\n",
    "            conversion_factor = preprocess.get_conversion_factor_px_to_cm(coords_point_a = corners[f'MazeCornerClosed{side_id}']['coords'],\n",
    "                                                                         coords_point_b = corners[f'MazeCornerOpen{side_id}']['coords'],\n",
    "                                                                         distance_in_cm = 50)\n",
    "            rotation_angle = preprocess.get_rotation_angle_with_open_corner(corners = corners,\n",
    "                                                                           side_id = best_result['side_id'],\n",
    "                                                                           translation_vector = translation_vector,\n",
    "                                                                           conversion_factor = conversion_factor)\n",
    "        else:\n",
    "            logs_to_add = {'maze_normalization_based_on': f'MazeCornerClosedRight_and_MazeCornerClosedLeft'}\n",
    "            conversion_factor = preprocess.get_conversion_factor_px_to_cm(coords_point_a = corners['MazeCornerClosedLeft']['coords'],\n",
    "                                                                         coords_point_b = corners['MazeCornerClosedRight']['coords'],\n",
    "                                                                         distance_in_cm = 4)\n",
    "            \n",
    "            \n",
    "            rotation_angle = preprocess.get_rotation_angle_with_closed_corners_only(corners = corners,\n",
    "                                                                               translation_vector = translation_vector,\n",
    "                                                                               conversion_factor = conversion_factor)\n",
    "        self._add_to_logs(logs_to_add = logs_to_add)\n",
    "        return {'translation_vector': translation_vector, 'rotation_angle': rotation_angle, 'conversion_factor': conversion_factor}\n",
    "    \n",
    "    \n",
    "    def _get_normalized_maze_corners(self, normalization_parameters: Dict) -> Dict:\n",
    "        normalized_maze_corner_coordinates = {}\n",
    "        corners = preprocess.get_corner_coords_with_likelihoods(df = self.normalized_df)\n",
    "        for corner_marker_id in corners.keys():\n",
    "            normalized_maze_corner_coordinates[corner_marker_id] = corners[corner_marker_id]['coords']\n",
    "        return normalized_maze_corner_coordinates\n",
    "    \n",
    "    \n",
    "    \n",
    "    def run_event_detection(self,\n",
    "                            bodyparts_critical_for_freezing: List[str]=['Snout', 'CenterOfGravity'], # List of marker_ids that need to be classified as \"immobile\" that the entire mouse is classified as immobile\n",
    "                            bodyparts_for_direction_front_to_back: List[str]=['Snout', 'CenterOfGravity'], # List of exactly two markers_ids that will be used to determine the orientation of the mouse; order of the markers: front, back\n",
    "                            immobility_max_rolling_speed: float=2.0, # A given bodypart will be classified as immobile in all frames, in which its rolling speed is less or equal to this value [cm per s]\n",
    "                            immobility_min_duration: float=0.1, # An immobility event will be created for each interval that exceeds this threshold [s] and in which all `bodyparts_critical_for_freezing` are classified as immobile\n",
    "                            freezing_min_duration: float=0.5, # A freezing event will be created for each interval that meets or exceeds this threshold [s] and in which all `bodyparts_critical_for_freezing` are classified as immobile\n",
    "                            gait_min_rolling_speed: float=3.0, # Frames will be classified as gait if the center of gravity meets or exceeds this rolling speed threshold [cm per s]\n",
    "                            gait_min_duration: float=0.5, # A gait event will be created for each interval that meets or exceeds this threshold [s] and in which the movement of the center of gravitiy is classified as \"gait\"\n",
    "                            gait_disruption_max_time_to_immobility: float=0.15, # A gait-disruption event will be created if an \"immobility\" event is found within this time interval [s] after a \"gait\" event has ended\n",
    "                            bodyparts_to_include_in_behavior_df = ['CenterOfGravity', 'Snout', 'TailBase'], # Bodyparts that will be included in the `behavior_df`. Should include at least all `bodyparts_critical_for_freezing`, `bodyparts_for_direction_front_to_back`, and the center of gravity\n",
    "                            merge_events_max_inbetween_time: float=0.15 # Not implemented yet;\n",
    "                           ) -> None:\n",
    "        \"\"\"\n",
    "        Trigger the detection of \"immobility\", \"freezing\", \"gait\", and \"gait disruption\" events. All\n",
    "        detected events will also be classified \"towards open end\" True / False, depending on whether\n",
    "        the orientation of the mouse was towards the open end of the maze or not. For gait events, \n",
    "        this classification will be based on the orientation at the very last frame, while the orientation\n",
    "        at the very first frame will be used for all other events (\"immobility\", \"freezing\", and \"gait\n",
    "        disruption\"). Since the specified parameters used for this step of the analysis are very crucial,\n",
    "        they will be documented in the logs and exported once the `export_results()` method is called.\n",
    "        Default parameter selection for immobility speed threshold & freezing minimum duration was based\n",
    "        on: https://www.sciencedirect.com/science/article/pii/S0960982216306182\n",
    "        \"\"\"\n",
    "        sliding_window_size = int(round(utils.get_max_odd_n_frames_for_time_interval(fps = self.fps, time_interval = 0.5) / 2, 0))\n",
    "        logs_to_add = {'bodyparts_checked_to_infer_immobility': bodyparts_critical_for_freezing,\n",
    "                       'bodypart_used_to_identify_front': bodyparts_for_direction_front_to_back[0],\n",
    "                       'bodypart_used_to_identify_back': bodyparts_for_direction_front_to_back[1],\n",
    "                       'immobility_max_rolling_speed' : immobility_max_rolling_speed,\n",
    "                       'immobility_min_duration': immobility_min_duration,\n",
    "                       'freezing_min_duration': freezing_min_duration, \n",
    "                       'gait_min_rolling_speed': gait_min_rolling_speed, \n",
    "                       'gait_min_duration': gait_min_duration,\n",
    "                       'gait_disruption_max_time_to_immobility': gait_disruption_max_time_to_immobility,\n",
    "                       #'merge_events_max_inbetween_time': merge_events_max_inbetween_time,\n",
    "                       'sliding_window_size_to_compute_speed': sliding_window_size}\n",
    "        self._add_to_logs(logs_to_add = logs_to_add)\n",
    "        for bodypart in self.bodyparts.values():\n",
    "            bodypart.calculate_speed_and_identify_immobility(sliding_window_size = sliding_window_size, immobility_threshold = immobility_max_rolling_speed)\n",
    "        self.behavior_df = detect.create_behavior_df(normalized_df = self.normalized_df, \n",
    "                                                         bodyparts_to_include = bodyparts_to_include_in_behavior_df)\n",
    "        self.behavior_df = detect.add_orientation_to_behavior_df(behavior_df = self.behavior_df,\n",
    "                                                                     all_bodyparts = self.bodyparts,\n",
    "                                                                     bodyparts_for_direction_front_to_back = bodyparts_for_direction_front_to_back)\n",
    "        self.behavior_df = detect.add_immobility_based_on_several_bodyparts_to_behavior_df(behavior_df = self.behavior_df,\n",
    "                                                                                               all_bodyparts = self.bodyparts,\n",
    "                                                                                               bodyparts_critical_for_freezing = bodyparts_critical_for_freezing)\n",
    "        immobility_events = detect.get_immobility_related_events(behavior_df = self.behavior_df,\n",
    "                                                                     fps = self.fps,\n",
    "                                                                     min_interval_duration = immobility_min_duration,\n",
    "                                                                     event_type = 'immobility_bout')\n",
    "        self.behavior_df = detect.add_event_bouts_to_behavior_df(behavior_df = self.behavior_df,\n",
    "                                                                     event_type = 'immobility_bout',\n",
    "                                                                     events = immobility_events)\n",
    "        freezing_events = detect.get_immobility_related_events(behavior_df = self.behavior_df,\n",
    "                                                                   fps = self.fps,\n",
    "                                                                   min_interval_duration = freezing_min_duration,\n",
    "                                                                   event_type = 'freezing_bout')\n",
    "        self.behavior_df = detect.add_event_bouts_to_behavior_df(behavior_df = self.behavior_df,\n",
    "                                                                     event_type = 'freezing_bout',\n",
    "                                                                     events = freezing_events)\n",
    "        gait_events = detect.get_gait_events(all_bodyparts = self.bodyparts,\n",
    "                                                 fps = self.fps,\n",
    "                                                 gait_min_rolling_speed = gait_min_rolling_speed,\n",
    "                                                 gait_min_duration = gait_min_duration)\n",
    "        self.behavior_df = detect.add_event_bouts_to_behavior_df(behavior_df = self.behavior_df,\n",
    "                                                                     event_type = 'gait_bout',\n",
    "                                                                     events = gait_events)\n",
    "        gait_disruption_events = detect.get_gait_disruption_events(behavior_df = self.behavior_df,\n",
    "                                                                       fps = self.fps,\n",
    "                                                                       gait_events = gait_events, \n",
    "                                                                       gait_disruption_max_time_to_immobility = gait_disruption_max_time_to_immobility)\n",
    "        self.behavior_df = detect.add_event_bouts_to_behavior_df(behavior_df = self.behavior_df,\n",
    "                                                                     event_type = 'gait_disruption_bout',\n",
    "                                                                     events = gait_disruption_events)\n",
    "    \n",
    "    \n",
    "    def export_results(self,\n",
    "                       out_dir_path: Path # Filepath to the directory where the results shall be saved\n",
    "                      ) -> None:\n",
    "        \"\"\"\n",
    "        Creates an .xlsx file the following tab names that contain the following information:\n",
    "        - parameter_settings:\n",
    "            The logged parameter settings that were passed (or used by default) during the processing.\n",
    "            \n",
    "        - immobility_bouts:\n",
    "            Data that describe each individual immobility event that was detected.\n",
    "        \n",
    "        - freezing_bouts:\n",
    "            Data that describe each individual freezing event that wes detected.\n",
    "        \n",
    "        - gait_bouts:\n",
    "            Data that describe each individual gait event that was detected.\n",
    "            \n",
    "        - gait_discruption_bouts:\n",
    "            Data that describe each individual gait disruption event that was detected.\n",
    "            \n",
    "        - session_overview:\n",
    "            Data that summarizes all events of a given type (e.g. freezing) over the entire session.\n",
    "            Events from a given type are also futher split according to the determined orientation and\n",
    "            are thus always given as \"towards_open_<event_type>\", \"towards_closed_<event_type>\", or\n",
    "            as \"all_<event_type>\" (e.g. \"all_freezing_bouts\", or \"towards_open_gait_events\").\n",
    "        \"\"\"\n",
    "        dfs_to_export = {'immobility_bouts': export.export_immobility_related_bouts(df = self.behavior_df, event_type = 'immobility_bout', framerate = self.framerate),\n",
    "                         'freezing_bouts': export.export_immobility_related_bouts(df = self.behavior_df, event_type = 'freezing_bout', framerate = self.framerate), \n",
    "                         'gait_disruption_bouts': export.export_immobility_related_bouts(df = self.behavior_df, event_type = 'gait_disruption_bout', framerate = self.framerate), \n",
    "                         'gait_bouts': export.export_gait_related_bouts(df = self.behavior_df, event_type = 'gait_bout', framerate = self.framerate)}\n",
    "        dfs_to_export['session_overview'] = export.create_session_overview_df(dfs_to_export_with_individual_bout_dfs = dfs_to_export)\n",
    "        dfs_to_export['parameter_settings'] = export.create_parameter_settings_df(logs = self.logs)\n",
    "        self.base_output_filepath = out_dir_path.joinpath(f'{self.metadata[\"animal\"]}_{self.metadata[\"paradigm\"]}_week-{self.week_id}')\n",
    "        export.write_xlsx_file_to_disk(base_output_filepath = self.base_output_filepath, dfs_to_export = dfs_to_export)\n",
    "\n",
    "    \n",
    "    def inspect_processing(self,\n",
    "                           marker_ids_to_inspect: List[str]=['CenterOfGravity'], # List of marker ids whose tracked position shall be plotted as scatter plot\n",
    "                           verbose: bool=False, # Whether current progress and additional details like the coverages for each marker defined in `marker_ids_to_inspect` shall be printed\n",
    "                           show_plot: bool=False, # Whether the created plot shall be displayed in the jupyter notebook\n",
    "                           save_plot: bool=True, # Whether the created plot shall be saved (per default, it will be saved in the save directory that was specified when `export_results()` was called)\n",
    "                           show_legend: bool=False # Whether a legend shall be added to the plot or not\n",
    "                          ) -> None:\n",
    "        \"\"\"\n",
    "        Since the normalization of the maze during the preprocessing is a very critical step, this\n",
    "        functions allows the user to visually inspect the success of this step at a glanze. It will\n",
    "        plot a schematic of how the maze is expected to look like in form of a black box. It will then\n",
    "        also plot the \"most reliable\" estimate of the four maze corners after normalization and the\n",
    "        valid tracking positions of all markers specified in `marker_ids_to_inspect`. To avoid over-\n",
    "        loading of this plot, we recommend to pass only a single marker id, for instance the \n",
    "        \"CenterOfGravity\". If you´d like to see some additional details, consider passing \"verbose = True\"\n",
    "        and/or \"show_legend = True\".\n",
    "        Note: The filepath where the plots will be saved cannot be changed & they will always be saved\n",
    "        in the same directory that was specified when calling the `export_results()` method, to ensure\n",
    "        that they are saved in the same folder as the .xlsx files that contain logged parameter settings.\n",
    "        \"\"\" \n",
    "        if verbose:\n",
    "            print(f'Inspection of file: {self.filepath.name}:')\n",
    "            for marker_id in marker_ids_to_inspect:\n",
    "                coverage = utils.compute_coverage(df = self.bodyparts[marker_id].df, critical_marker_ids = [marker_id])\n",
    "                print(f'... coverage of \"{marker_id}\" was at: {round(coverage*100, 2)} %')\n",
    "        if show_plot or save_plot:\n",
    "            self._plot_selected_marker_ids_on_normalized_maze(marker_ids = marker_ids_to_inspect,\n",
    "                                                              show = show_plot, \n",
    "                                                              save = save_plot, \n",
    "                                                              legend = show_legend)\n",
    "\n",
    "            \n",
    "    def _plot_selected_marker_ids_on_normalized_maze(self, marker_ids: List[str], show: bool=True, save: bool=True, legend: bool=False) -> None:\n",
    "        fig = plt.figure(figsize=(10, 5), facecolor='white')\n",
    "        ax = fig.add_subplot(111)\n",
    "        for corner_marker_id in ['MazeCornerClosedRight', 'MazeCornerClosedLeft', 'MazeCornerOpenRight', 'MazeCornerOpenLeft']:\n",
    "            x, y = self.logs[f'normalized_{corner_marker_id}_coords']\n",
    "            plt.scatter(x, y, label = corner_marker_id)\n",
    "        for marker_id in marker_ids:\n",
    "            plt.scatter(self.bodyparts[marker_id].df['x'], self.bodyparts[marker_id].df['y'], alpha = 0.1, label = marker_id)\n",
    "        plt.plot([0, 0, 50, 50, 0], [0, 4, 4, 0, 0], c = 'black')\n",
    "        ax.set_aspect('equal')\n",
    "        if legend:\n",
    "            plt.legend()\n",
    "        if save:\n",
    "            assert hasattr(self, 'base_output_filepath'), 'You must run \".export_results()\" first if you´d like to save the plot. Alternatively, just opt to show the plot.' \n",
    "            plt.savefig(f'{self.base_output_filepath}.png', dpi = 300)\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/Gait_Analysis/blob/main/gait_analysis/twoD/cam_interfaces.py#L123){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TopTracked2DRecording.preprocess_tracking\n",
       "\n",
       ">      TopTracked2DRecording.preprocess_tracking\n",
       ">                                                 (marker_ids_to_compute_coverag\n",
       ">                                                 e:List[str]=['TailBase',\n",
       ">                                                 'Snout'],\n",
       ">                                                 coverage_threshold:float=0.75,\n",
       ">                                                 max_seconds_to_interpolate:flo\n",
       ">                                                 at=0.5, likelihood_threshold:f\n",
       ">                                                 loat=0.5, marker_ids_to_comput\n",
       ">                                                 e_center_of_gravity:List[str]=\n",
       ">                                                 ['TailBase', 'Snout'], relativ\n",
       ">                                                 e_maze_normalization_error_tol\n",
       ">                                                 erance:float=0.25)\n",
       "\n",
       "Initiate the preprocessing of the DLC output tracking data. This includes smoothing, \n",
       "interpolation of small intervals with low likelihoods, and creation of additional markers, \n",
       "like a center of gravity. Furthermore, the code will identify the most reliable \n",
       "predicted position of the maze corners and evaluate, whether the reconstructed maze using\n",
       "these most reliable open corner positions yields a maze that is sufficiently similar to how the\n",
       "maze should look like (less than a specified relative error threshold). If it meets this\n",
       "criterion, it will use the open corner from there on to normalize the coordinate system.\n",
       "If not, it will compute everything just based on the closed corners. Either way, the\n",
       "coordinate system will be normalized to the closed left corner, applying rotation and\n",
       "shifting, and eventually convert the coordinates into cm values. As the very last step, \n",
       "self.bodyparts will be created - a dictionary that contains an `Bodypart` object for each\n",
       "marker id. Logs will save all parameters specified upon calling the function to make it\n",
       "easily traceable, which parameter settings were used to obtain a given result (see also\n",
       "the documentation of the `export_results()` method.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| marker_ids_to_compute_coverage | typing.List[str] | ['TailBase', 'Snout'] | List of marker_ids on base of which the tracking coverage will be computed |\n",
       "| coverage_threshold | float | 0.75 | If coverage of the above defined markers is lower than this threshold, the recording will be excluded from the analysis and therefore not further processed |\n",
       "| max_seconds_to_interpolate | float | 0.5 | Maximum time interval in which consecutive nan´s will be interpolated |\n",
       "| likelihood_threshold | float | 0.5 | Minimum prediction likelihood of DLC that is required to acceppt predicted marker position as valid |\n",
       "| marker_ids_to_compute_center_of_gravity | typing.List[str] | ['TailBase', 'Snout'] | marker ids that will be used to compute the center of gravity |\n",
       "| relative_maze_normalization_error_tolerance | float | 0.25 | relative error that is tolerated when estimating the maze position for normalizing it´s position |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/Gait_Analysis/blob/main/gait_analysis/twoD/cam_interfaces.py#L123){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TopTracked2DRecording.preprocess_tracking\n",
       "\n",
       ">      TopTracked2DRecording.preprocess_tracking\n",
       ">                                                 (marker_ids_to_compute_coverag\n",
       ">                                                 e:List[str]=['TailBase',\n",
       ">                                                 'Snout'],\n",
       ">                                                 coverage_threshold:float=0.75,\n",
       ">                                                 max_seconds_to_interpolate:flo\n",
       ">                                                 at=0.5, likelihood_threshold:f\n",
       ">                                                 loat=0.5, marker_ids_to_comput\n",
       ">                                                 e_center_of_gravity:List[str]=\n",
       ">                                                 ['TailBase', 'Snout'], relativ\n",
       ">                                                 e_maze_normalization_error_tol\n",
       ">                                                 erance:float=0.25)\n",
       "\n",
       "Initiate the preprocessing of the DLC output tracking data. This includes smoothing, \n",
       "interpolation of small intervals with low likelihoods, and creation of additional markers, \n",
       "like a center of gravity. Furthermore, the code will identify the most reliable \n",
       "predicted position of the maze corners and evaluate, whether the reconstructed maze using\n",
       "these most reliable open corner positions yields a maze that is sufficiently similar to how the\n",
       "maze should look like (less than a specified relative error threshold). If it meets this\n",
       "criterion, it will use the open corner from there on to normalize the coordinate system.\n",
       "If not, it will compute everything just based on the closed corners. Either way, the\n",
       "coordinate system will be normalized to the closed left corner, applying rotation and\n",
       "shifting, and eventually convert the coordinates into cm values. As the very last step, \n",
       "self.bodyparts will be created - a dictionary that contains an `Bodypart` object for each\n",
       "marker id. Logs will save all parameters specified upon calling the function to make it\n",
       "easily traceable, which parameter settings were used to obtain a given result (see also\n",
       "the documentation of the `export_results()` method.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| marker_ids_to_compute_coverage | typing.List[str] | ['TailBase', 'Snout'] | List of marker_ids on base of which the tracking coverage will be computed |\n",
       "| coverage_threshold | float | 0.75 | If coverage of the above defined markers is lower than this threshold, the recording will be excluded from the analysis and therefore not further processed |\n",
       "| max_seconds_to_interpolate | float | 0.5 | Maximum time interval in which consecutive nan´s will be interpolated |\n",
       "| likelihood_threshold | float | 0.5 | Minimum prediction likelihood of DLC that is required to acceppt predicted marker position as valid |\n",
       "| marker_ids_to_compute_center_of_gravity | typing.List[str] | ['TailBase', 'Snout'] | marker ids that will be used to compute the center of gravity |\n",
       "| relative_maze_normalization_error_tolerance | float | 0.25 | relative error that is tolerated when estimating the maze position for normalizing it´s position |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TopTracked2DRecording.preprocess_tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/Gait_Analysis/blob/main/gait_analysis/twoD/cam_interfaces.py#L303){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TopTracked2DRecording.run_event_detection\n",
       "\n",
       ">      TopTracked2DRecording.run_event_detection\n",
       ">                                                 (bodyparts_critical_for_freezi\n",
       ">                                                 ng:List[str]=['Snout',\n",
       ">                                                 'CenterOfGravity'], bodyparts_\n",
       ">                                                 for_direction_front_to_back:Li\n",
       ">                                                 st[str]=['Snout',\n",
       ">                                                 'CenterOfGravity'], immobility\n",
       ">                                                 _max_rolling_speed:float=2.0, \n",
       ">                                                 immobility_min_duration:float=\n",
       ">                                                 0.1, freezing_min_duration:flo\n",
       ">                                                 at=0.5, gait_min_rolling_speed\n",
       ">                                                 :float=3.0,\n",
       ">                                                 gait_min_duration:float=0.5, g\n",
       ">                                                 ait_disruption_max_time_to_imm\n",
       ">                                                 obility:float=0.15, bodyparts_\n",
       ">                                                 to_include_in_behavior_df=['Ce\n",
       ">                                                 nterOfGravity', 'Snout',\n",
       ">                                                 'TailBase'], merge_events_max_\n",
       ">                                                 inbetween_time:float=0.15)\n",
       "\n",
       "Trigger the detection of \"immobility\", \"freezing\", \"gait\", and \"gait disruption\" events. All\n",
       "detected events will also be classified \"towards open end\" True / False, depending on whether\n",
       "the orientation of the mouse was towards the open end of the maze or not. For gait events, \n",
       "this classification will be based on the orientation at the very last frame, while the orientation\n",
       "at the very first frame will be used for all other events (\"immobility\", \"freezing\", and \"gait\n",
       "disruption\"). Since the specified parameters used for this step of the analysis are very crucial,\n",
       "they will be documented in the logs and exported once the `export_results()` method is called.\n",
       "Default parameter selection for immobility speed threshold & freezing minimum duration was based\n",
       "on: https://www.sciencedirect.com/science/article/pii/S0960982216306182\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| bodyparts_critical_for_freezing | typing.List[str] | ['Snout', 'CenterOfGravity'] | List of marker_ids that need to be classified as \"immobile\" that the entire mouse is classified as immobile |\n",
       "| bodyparts_for_direction_front_to_back | typing.List[str] | ['Snout', 'CenterOfGravity'] | List of exactly two markers_ids that will be used to determine the orientation of the mouse; order of the markers: front, back |\n",
       "| immobility_max_rolling_speed | float | 2.0 | A given bodypart will be classified as immobile in all frames, in which its rolling speed is less or equal to this value [cm per s] |\n",
       "| immobility_min_duration | float | 0.1 | An immobility event will be created for each interval that exceeds this threshold [s] and in which all `bodyparts_critical_for_freezing` are classified as immobile |\n",
       "| freezing_min_duration | float | 0.5 | A freezing event will be created for each interval that meets or exceeds this threshold [s] and in which all `bodyparts_critical_for_freezing` are classified as immobile |\n",
       "| gait_min_rolling_speed | float | 3.0 | Frames will be classified as gait if the center of gravity meets or exceeds this rolling speed threshold [cm per s] |\n",
       "| gait_min_duration | float | 0.5 | A gait event will be created for each interval that meets or exceeds this threshold [s] and in which the movement of the center of gravitiy is classified as \"gait\" |\n",
       "| gait_disruption_max_time_to_immobility | float | 0.15 | A gait-disruption event will be created if an \"immobility\" event is found within this time interval [s] after a \"gait\" event has ended |\n",
       "| bodyparts_to_include_in_behavior_df | list | ['CenterOfGravity', 'Snout', 'TailBase'] | Bodyparts that will be included in the `behavior_df`. Should include at least all `bodyparts_critical_for_freezing`, `bodyparts_for_direction_front_to_back`, and the center of gravity |\n",
       "| merge_events_max_inbetween_time | float | 0.15 | Not implemented yet; |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/Gait_Analysis/blob/main/gait_analysis/twoD/cam_interfaces.py#L303){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TopTracked2DRecording.run_event_detection\n",
       "\n",
       ">      TopTracked2DRecording.run_event_detection\n",
       ">                                                 (bodyparts_critical_for_freezi\n",
       ">                                                 ng:List[str]=['Snout',\n",
       ">                                                 'CenterOfGravity'], bodyparts_\n",
       ">                                                 for_direction_front_to_back:Li\n",
       ">                                                 st[str]=['Snout',\n",
       ">                                                 'CenterOfGravity'], immobility\n",
       ">                                                 _max_rolling_speed:float=2.0, \n",
       ">                                                 immobility_min_duration:float=\n",
       ">                                                 0.1, freezing_min_duration:flo\n",
       ">                                                 at=0.5, gait_min_rolling_speed\n",
       ">                                                 :float=3.0,\n",
       ">                                                 gait_min_duration:float=0.5, g\n",
       ">                                                 ait_disruption_max_time_to_imm\n",
       ">                                                 obility:float=0.15, bodyparts_\n",
       ">                                                 to_include_in_behavior_df=['Ce\n",
       ">                                                 nterOfGravity', 'Snout',\n",
       ">                                                 'TailBase'], merge_events_max_\n",
       ">                                                 inbetween_time:float=0.15)\n",
       "\n",
       "Trigger the detection of \"immobility\", \"freezing\", \"gait\", and \"gait disruption\" events. All\n",
       "detected events will also be classified \"towards open end\" True / False, depending on whether\n",
       "the orientation of the mouse was towards the open end of the maze or not. For gait events, \n",
       "this classification will be based on the orientation at the very last frame, while the orientation\n",
       "at the very first frame will be used for all other events (\"immobility\", \"freezing\", and \"gait\n",
       "disruption\"). Since the specified parameters used for this step of the analysis are very crucial,\n",
       "they will be documented in the logs and exported once the `export_results()` method is called.\n",
       "Default parameter selection for immobility speed threshold & freezing minimum duration was based\n",
       "on: https://www.sciencedirect.com/science/article/pii/S0960982216306182\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| bodyparts_critical_for_freezing | typing.List[str] | ['Snout', 'CenterOfGravity'] | List of marker_ids that need to be classified as \"immobile\" that the entire mouse is classified as immobile |\n",
       "| bodyparts_for_direction_front_to_back | typing.List[str] | ['Snout', 'CenterOfGravity'] | List of exactly two markers_ids that will be used to determine the orientation of the mouse; order of the markers: front, back |\n",
       "| immobility_max_rolling_speed | float | 2.0 | A given bodypart will be classified as immobile in all frames, in which its rolling speed is less or equal to this value [cm per s] |\n",
       "| immobility_min_duration | float | 0.1 | An immobility event will be created for each interval that exceeds this threshold [s] and in which all `bodyparts_critical_for_freezing` are classified as immobile |\n",
       "| freezing_min_duration | float | 0.5 | A freezing event will be created for each interval that meets or exceeds this threshold [s] and in which all `bodyparts_critical_for_freezing` are classified as immobile |\n",
       "| gait_min_rolling_speed | float | 3.0 | Frames will be classified as gait if the center of gravity meets or exceeds this rolling speed threshold [cm per s] |\n",
       "| gait_min_duration | float | 0.5 | A gait event will be created for each interval that meets or exceeds this threshold [s] and in which the movement of the center of gravitiy is classified as \"gait\" |\n",
       "| gait_disruption_max_time_to_immobility | float | 0.15 | A gait-disruption event will be created if an \"immobility\" event is found within this time interval [s] after a \"gait\" event has ended |\n",
       "| bodyparts_to_include_in_behavior_df | list | ['CenterOfGravity', 'Snout', 'TailBase'] | Bodyparts that will be included in the `behavior_df`. Should include at least all `bodyparts_critical_for_freezing`, `bodyparts_for_direction_front_to_back`, and the center of gravity |\n",
       "| merge_events_max_inbetween_time | float | 0.15 | Not implemented yet; |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TopTracked2DRecording.run_event_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/Gait_Analysis/blob/main/gait_analysis/twoD/cam_interfaces.py#L424){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TopTracked2DRecording.export_results\n",
       "\n",
       ">      TopTracked2DRecording.export_results (out_dir_path:pathlib.Path)\n",
       "\n",
       "Creates an .xlsx file the following tab names that contain the following information:\n",
       "- parameter_settings:\n",
       "    The logged parameter settings that were passed (or used by default) during the processing.\n",
       "\n",
       "- immobility_bouts:\n",
       "    Data that describe each individual immobility event that was detected.\n",
       "\n",
       "- freezing_bouts:\n",
       "    Data that describe each individual freezing event that wes detected.\n",
       "\n",
       "- gait_bouts:\n",
       "    Data that describe each individual gait event that was detected.\n",
       "\n",
       "- gait_discruption_bouts:\n",
       "    Data that describe each individual gait disruption event that was detected.\n",
       "\n",
       "- session_overview:\n",
       "    Data that summarizes all events of a given type (e.g. freezing) over the entire session.\n",
       "    Events from a given type are also futher split according to the determined orientation and\n",
       "    are thus always given as \"towards_open_<event_type>\", \"towards_closed_<event_type>\", or\n",
       "    as \"all_<event_type>\" (e.g. \"all_freezing_bouts\", or \"towards_open_gait_events\").\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| out_dir_path | Path | Filepath to the directory where the results shall be saved |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/Gait_Analysis/blob/main/gait_analysis/twoD/cam_interfaces.py#L424){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TopTracked2DRecording.export_results\n",
       "\n",
       ">      TopTracked2DRecording.export_results (out_dir_path:pathlib.Path)\n",
       "\n",
       "Creates an .xlsx file the following tab names that contain the following information:\n",
       "- parameter_settings:\n",
       "    The logged parameter settings that were passed (or used by default) during the processing.\n",
       "\n",
       "- immobility_bouts:\n",
       "    Data that describe each individual immobility event that was detected.\n",
       "\n",
       "- freezing_bouts:\n",
       "    Data that describe each individual freezing event that wes detected.\n",
       "\n",
       "- gait_bouts:\n",
       "    Data that describe each individual gait event that was detected.\n",
       "\n",
       "- gait_discruption_bouts:\n",
       "    Data that describe each individual gait disruption event that was detected.\n",
       "\n",
       "- session_overview:\n",
       "    Data that summarizes all events of a given type (e.g. freezing) over the entire session.\n",
       "    Events from a given type are also futher split according to the determined orientation and\n",
       "    are thus always given as \"towards_open_<event_type>\", \"towards_closed_<event_type>\", or\n",
       "    as \"all_<event_type>\" (e.g. \"all_freezing_bouts\", or \"towards_open_gait_events\").\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| out_dir_path | Path | Filepath to the directory where the results shall be saved |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TopTracked2DRecording.export_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/Gait_Analysis/blob/main/gait_analysis/twoD/cam_interfaces.py#L484){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TopTracked2DRecording.inspect_processing\n",
       "\n",
       ">      TopTracked2DRecording.inspect_processing\n",
       ">                                                (marker_ids_to_inspect:List[str\n",
       ">                                                ]=['CenterOfGravity'],\n",
       ">                                                verbose:bool=False,\n",
       ">                                                show_plot:bool=False,\n",
       ">                                                save_plot:bool=True,\n",
       ">                                                show_legend:bool=False)\n",
       "\n",
       "Since the normalization of the maze during the preprocessing is a very critical step, this\n",
       "functions allows the user to visually inspect the success of this step at a glanze. It will\n",
       "plot a schematic of how the maze is expected to look like in form of a black box. It will then\n",
       "also plot the \"most reliable\" estimate of the four maze corners after normalization and the\n",
       "valid tracking positions of all markers specified in `marker_ids_to_inspect`. To avoid over-\n",
       "loading of this plot, we recommend to pass only a single marker id, for instance the \n",
       "\"CenterOfGravity\". If you´d like to see some additional details, consider passing \"verbose = True\"\n",
       "and/or \"show_legend = True\".\n",
       "Note: The filepath where the plots will be saved cannot be changed & they will always be saved\n",
       "in the same directory that was specified when calling the `export_results()` method, to ensure\n",
       "that they are saved in the same folder as the .xlsx files that contain logged parameter settings.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| marker_ids_to_inspect | typing.List[str] | ['CenterOfGravity'] | List of marker ids whose tracked position shall be plotted as scatter plot |\n",
       "| verbose | bool | False | Whether current progress and additional details like the coverages for each marker defined in `marker_ids_to_inspect` shall be printed |\n",
       "| show_plot | bool | False | Whether the created plot shall be displayed in the jupyter notebook |\n",
       "| save_plot | bool | True | Whether the created plot shall be saved (per default, it will be saved in the save directory that was specified when `export_results()` was called) |\n",
       "| show_legend | bool | False | Whether a legend shall be added to the plot or not |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Defense-Circuits-Lab/Gait_Analysis/blob/main/gait_analysis/twoD/cam_interfaces.py#L484){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TopTracked2DRecording.inspect_processing\n",
       "\n",
       ">      TopTracked2DRecording.inspect_processing\n",
       ">                                                (marker_ids_to_inspect:List[str\n",
       ">                                                ]=['CenterOfGravity'],\n",
       ">                                                verbose:bool=False,\n",
       ">                                                show_plot:bool=False,\n",
       ">                                                save_plot:bool=True,\n",
       ">                                                show_legend:bool=False)\n",
       "\n",
       "Since the normalization of the maze during the preprocessing is a very critical step, this\n",
       "functions allows the user to visually inspect the success of this step at a glanze. It will\n",
       "plot a schematic of how the maze is expected to look like in form of a black box. It will then\n",
       "also plot the \"most reliable\" estimate of the four maze corners after normalization and the\n",
       "valid tracking positions of all markers specified in `marker_ids_to_inspect`. To avoid over-\n",
       "loading of this plot, we recommend to pass only a single marker id, for instance the \n",
       "\"CenterOfGravity\". If you´d like to see some additional details, consider passing \"verbose = True\"\n",
       "and/or \"show_legend = True\".\n",
       "Note: The filepath where the plots will be saved cannot be changed & they will always be saved\n",
       "in the same directory that was specified when calling the `export_results()` method, to ensure\n",
       "that they are saved in the same folder as the .xlsx files that contain logged parameter settings.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| marker_ids_to_inspect | typing.List[str] | ['CenterOfGravity'] | List of marker ids whose tracked position shall be plotted as scatter plot |\n",
       "| verbose | bool | False | Whether current progress and additional details like the coverages for each marker defined in `marker_ids_to_inspect` shall be printed |\n",
       "| show_plot | bool | False | Whether the created plot shall be displayed in the jupyter notebook |\n",
       "| save_plot | bool | True | Whether the created plot shall be saved (per default, it will be saved in the save directory that was specified when `export_results()` was called) |\n",
       "| show_legend | bool | False | Whether a legend shall be added to the plot or not |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TopTracked2DRecording.inspect_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
