{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "984017a3-0de6-4ba9-823e-09ee86cf59f3",
   "metadata": {},
   "source": [
    "# **Preliminary pipeline to calibrate all cameras**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c078a0c-7da8-47e1-83de-ac7e808f61d7",
   "metadata": {},
   "source": [
    "#### The goal of this pipeline is to perform and evaluate the calibration of all cameras for opening track experiments. In order to be able to run it, several prerequisites must be given:\n",
    "\n",
    "**Synchronized charuco-board recordings:**\n",
    "\n",
    "Why? Out-of-sync videos can´t be used for calibration, since detected corners of the Charucoboard will be compared across cameras frame by frame. Thus, you must have already synchronized the recordings of the charucoboard with the same fps, e.g. using the `00_synchronize.ipynb` notebook. If not, please synchronize them first! In case any of these videos were cropped, you need to know the cropping indices & whether and how they were flipped.\n",
    "\n",
    "\n",
    "**Intrinsic camera calibrations:**\n",
    "\n",
    "In addition to the synchronized Charucoboard recordings to calibrate the cameras to each other, you will also need an intrinsic calibration for each camera. Why? Each camera has a unique distortion of the recorded image that can reduce the calibration quality between multiple cameras. However, you can determine each camera´s unique intrinsic properties & then \"invert\" these in order to undistort the images. While this can also be done on the Charucoboard recordings within the anipose calibration, it seems to work better using a checkerboard & passing these information along for anipose - especially for a mix of fish-eye and regular cameras. Either option A or option B is required:\n",
    "- Option A: you have the videos for intrinsic calibration of each camera (uncropped recordings of the checkerboard), then you will have to perform them for each camera\n",
    "- Option B: these calibrations were already performed and you can simply load the corresponding file for each camera\n",
    "\n",
    "\n",
    "**Test positions:**\n",
    "\n",
    "Eventually, you also need some ground truth information to evaluate the calibration. Why? In order to quantify the quality of the calibration, we need some meaningful measurements in addition to the \"reprojection error\" that anipose returns, which basically tells us the accuracy in units (voxels/pixels?) of the triangulated reference space. Therefore, we triangulate & compute the distances of a certain set of test position markers in the 3D reference space. Since we know the actual distances of these positions, we can compare the measured ground truth distances and the triangulated 3D distances after the calibration & get an error for all distances in cm! For this, you obviously need to know the distances between a certain set of test position markers:\n",
    "- you either know the distances between certain markers of these test positions, or you can load previously saved test position distances\n",
    "\n",
    "In addition, you will also need one of the following two options:\n",
    "- Option A: you have the coordinates of each marker of a test position that is visible in each camera FOV (e.g. from DLC predictions or from tamplate matching)\n",
    "- Option B: you have images/videos from each camera you would like to calibrate that show the test position markers, then you can manually determine the coordinates of each visible marker id and add it\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de7709-a5fc-47b0-93f1-c70114052a7b",
   "metadata": {},
   "source": [
    "## Step 1) Create an object that holds the test positions ground truth data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710258e1-a1b5-4479-9c58-29d70d9ee1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gait3d.camera_calibration import TestPositionsGroundTruth\n",
    "from pathlib import Path\n",
    "\n",
    "test_positions = TestPositionsGroundTruth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da05796-0daf-46ef-b3d6-417eed29cbfa",
   "metadata": {},
   "source": [
    "As mentioned above, you either have the chance to create such an object and feed it with all the distances you measured (and save it to disk, such that you can reuse it the next time), for instance like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a0407b-4e33-4dcd-9d1d-7fa64593a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positions.add_new_marker_id(marker_id='screw1_bottom', other_marker_ids_with_distances=[('screw2_bottom', 5),\n",
    "                                                                                             ('screw1_top', 8.1),\n",
    "                                                                                             ('screw1_nut', 6.1),\n",
    "                                                                                             ('screw3_bottom', 7),\n",
    "                                                                                             ('screw4_bottom', 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b3bb2-5ed1-44a5-9d2d-6de034307ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positions.add_new_marker_id(marker_id='screw1_nut', other_marker_ids_with_distances=[('screw4_top', 10),\n",
    "                                                                                          ('screw1_top', 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babfb6ba-606d-4a8b-b620-3e797282ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positions.add_new_marker_id(marker_id='screw2_bottom', other_marker_ids_with_distances=[('screw3_bottom', 2),\n",
    "                                                                                             ('screw4_bottom', 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb8d1eb-91c8-4e6a-a2cf-54eb9838f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positions.add_new_marker_id(marker_id='screw2_top', other_marker_ids_with_distances=[('screw1_top', 7.7),\n",
    "                                                                                          ('screw3_top', 1.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f8432d-4cde-4bf0-a347-a38f1350caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positions.add_new_marker_id(marker_id='screw3_bottom', other_marker_ids_with_distances=[('screw4_bottom', 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a12769-b38d-42ff-94e0-d919954a2d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positions.add_new_marker_id(marker_id='screw3_top', other_marker_ids_with_distances=[('screw4_top', 4.6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a03eb22-23c7-4a71-af89-0972cc4a9944",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positions.add_new_marker_id(marker_id='screw4_bottom', other_marker_ids_with_distances=[('screw4_top', 6.1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e70f3-6e73-4cd1-8f4e-db7908d170fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positions.add_new_marker_id(marker_id='x1', other_marker_ids_with_distances=[('maze_corner_open_left', 9.4),\n",
    "                                                                                  ('x2', 16.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99923e-8ba7-4303-b5c2-2e02b7d112f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positions.add_new_marker_id(marker_id='x2', other_marker_ids_with_distances=[('maze_corner_closed_left', 17.4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3691430-20b6-49af-8c1d-77472c525727",
   "metadata": {},
   "source": [
    "You can find a list of all loaded marker ids and their respective distances to other marker ids in the `.marker_ids_with_distances` attribute. Please note, that reciprocal distances are created automatically & that the distances between the maze corners are preloaded already!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf91c55-f384-4c4d-a559-f4b020e0b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positions.marker_ids_with_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b72712-38ed-4331-aaea-82763b2b2a10",
   "metadata": {},
   "source": [
    "In addition, you have to provide at least one distance between two markers, that you would like as reference distance when the triangulated distances are converted to the unit cm. Since the calibration and thus the triangulation performance can (probably will) be different in different regions of the image, it might make sense to provide several reference distances. During the evaluation later on, all of them will be used to convert the triangulated distances to cm & compare them to the ground truth distances you provided above. If these errors are all relatively low, you know that your calibration worked well across the entire recording space! Please note: the reference distances \"maze_length_left\" (between \"maze_corner_open_left\" and \"maze_corner_closed_left\") & \"maze_length_right\" (same idea) are again pre-loaded and don´t have to be added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1836098-52a0-43f9-80dc-38b79bf9f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positions.add_marker_ids_and_distance_id_as_reference_distance(marker_ids=('screw1_bottom', 'screw4_bottom'), distance_id='screw_1-4_bottoms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff64c7-bfae-4b57-8b47-ce337add26f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positions.reference_distance_ids_with_corresponding_marker_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e04173-ed61-4844-bc05-47b6bae17a9e",
   "metadata": {},
   "source": [
    "Finally, if you´d like to have a certain set of marker ids connected in the 3D plot of the triangulation space, feel free to add them like this. Please note, the maze corners will be added automatically again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f432f9-0dfc-4dd4-a7f2-c96bbf3fecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positions.add_marker_ids_to_be_connected_in_3d_plots(marker_ids=('screw1_bottom', 'screw4_bottom', 'screw4_top', 'screw1_nut'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41512acb-706f-4e2a-96ad-599fbfe066d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positions.marker_ids_to_connect_in_3D_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf2cb0c-a091-47ec-8888-13444eabd2ac",
   "metadata": {},
   "source": [
    "Alright, that´s it! Of course, please add as many marker ids, distances, reference distances & marker id combinations to be connected as you´d like! If you are happy with your `TestPositionsGroundTruth` object, you can save it to disk. Please note, this currently does not save the reference distances or the marker ids you´d like to connect, but solely the marker ids and the distances between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04924d87-1bb4-419b-8138-8f547bf30287",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('/mnt/c/Users/dsege/Downloads/220825/220825/test_positions_ground_truth.p')\n",
    "test_positions.save_to_disk(filepath = filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682bf8a4-6207-4399-8e2d-0d6097dc5f4a",
   "metadata": {},
   "source": [
    "Well, alternatively, if all these information have already been saved, you can of course simply load them. Please be aware, that only the default reference distances (\"maze_length_left\" and \"maze_length_right\") and the default marker ids to connect (all maze corners) will be loaded - however, of course all the marker ids & distances between them are also included:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9569298-5d1c-4e50-89e9-ec42a731d347",
   "metadata": {},
   "source": [
    "test_positions_loaded = TestPositionsGroundTruth()\n",
    "filepath = Path('/mnt/c/Users/dsege/Downloads/220825/220825/test_positions_ground_truth.p')\n",
    "test_positions_loaded.load_from_disk(filepath = filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c8670-3a86-4174-9859-7469fc581ad6",
   "metadata": {},
   "source": [
    "test_positions_loaded.reference_distance_ids_with_corresponding_marker_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424a3496-3dc2-4d00-a1de-5713e7d467b6",
   "metadata": {},
   "source": [
    "test_positions_loaded.marker_ids_to_connect_in_3D_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e220e-b492-4d9b-a34e-a3f7955eb534",
   "metadata": {},
   "source": [
    "test_positions_loaded.marker_ids_with_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28d3b44-b4d4-42a7-984a-7d501d2ebcf6",
   "metadata": {},
   "source": [
    "## Step 2) Prepare the data for each single camera you´d like to include in the calibration / triangulation:\n",
    "\n",
    "The following steps have to be performed for each camera individually, such that you end up with as many `SingleCamDataForAnipose` objects, as you have cameras. Of course, you can adapt the input for each camera individually! Let´s go through the process for the top cam. First, we initialize the object with a unique cam ID and the filepath of the synchronized calibration video that is to be used for the calibration between the set of cameras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e0ec79-7b55-4483-ac05-f049ded55322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gait3d.camera_calibration import SingleCamDataForAnipose\n",
    "from gait3d.utils import plot_image, plot_single_frame_of_video\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ffeac1-8cb4-4e08-82dd-347138af5c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsic_calibrations_dir = Path(os.getcwd()).joinpath('intrinsic_camera_calibrations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef4fd5-b9ee-4817-b71d-7a7cefa6e2a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Top cam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37daa56a-99ef-4ace-93b0-44c250f82d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('/mnt/c/Users/dsege/Downloads/220825/220825/Top_cam_synchronized_for_calibration_all_parts.mp4')\n",
    "top_cam = SingleCamDataForAnipose(cam_id = 'Top', filepath_synchronized_calibration_video = filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff7028-d48e-4dca-b05f-6ec9379723b1",
   "metadata": {},
   "source": [
    "Next, it makes sense to add all additional metadata about your camera, like the offset of the cropping indices that you noted during cropping in ICCapture & whether and how the video stream was flipped. If you did neither crop the video nor flip it, you can simply skip these functions and the default values (offsets = (0, 0) and both flippings = False) will be loaded automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b72718-16c7-42fb-b3fa-d418d20f6711",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cam.add_cropping_offsets(x_or_column_offset=0, y_or_row_offset=0)\n",
    "top_cam.add_flipping_details(flipped_horizontally=False, flipped_vertically=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf5337b-ea3d-4576-a05a-f76119723950",
   "metadata": {},
   "source": [
    "Let´s stay with the properties of the camera also for the next step: the intrinsic camera calibration (see some explanation of what this is and why it is neccessary at the very top of this notebook). You can either run it (see the following cell - don´t worry, the calibration results will automatically be saved in the same directory where the checkerboard video is) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f84ec2-6884-4940-afa2-5a1890bc2e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath_checkerboard_recording = Path('/mnt/c/Users/dsege/Downloads/220825/220825/Checkerboard_Calibration/Top_checkerboard.AVI')\n",
    "#top_cam.run_intrinsic_camera_calibration(filepath_checkerboard_video=filepath_checkerboard_recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac79cec8-84d0-4761-8a6c-acf817bf6545",
   "metadata": {},
   "source": [
    "... or load it from disk, if you have previously performed the calibration already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d95354-ab24-4919-9e9c-4af45aaaa802",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_intrinsic_calibration = intrinsic_calibrations_dir.joinpath('Top_checkerboard_intrinsic_calibration_results.p')\n",
    "top_cam.load_intrinsic_camera_calibration(filepath_intrinsic_calibration = filepath_intrinsic_calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fdf825-f377-4639-9f33-1b55d02f890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "top_cam.inspect_intrinsic_calibration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eece30-559f-4f6e-adc2-1b1d5443de28",
   "metadata": {},
   "source": [
    "Great! All relevant metadata are now loaded and stored in the `SingleCamDataForAnipose` object & we will have them readily with us, wherever we move the object - eventually, this will be to the anipose calibration. But before we get there, we have some more work to do. We need to also add the information to our object, which markers of the test positions it can see & where they are in the image. This can be either done automatically (to be implemented / trained) - or manually. For this, we will load the test positions image (or the first frame of the positions video in case of the top cam) from the corresponding camera and manually determine & load the marker ids & their pixel coordinates: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a7f7c-dd41-4079-b6b7-8a87a17d9b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plot_single_frame_of_video(filepath='/mnt/c/Users/dsege/Downloads/220825/220825/220825_Top_Positions002.AVI', frame_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee750896-d0c1-4889-8f67-77cc3bde4ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cam.add_manual_test_position_marker(marker_id = 'maze_corner_closed_left', x_or_column_idx = 360 , y_or_row_idx = 375, likelihood=0.999)\n",
    "top_cam.add_manual_test_position_marker(marker_id = 'maze_corner_closed_right', x_or_column_idx = 383 , y_or_row_idx = 375, likelihood=0.999)\n",
    "top_cam.add_manual_test_position_marker(marker_id = 'maze_corner_open_left', x_or_column_idx = 351 , y_or_row_idx = 63, likelihood=0.999)\n",
    "top_cam.add_manual_test_position_marker(marker_id = 'maze_corner_open_right', x_or_column_idx = 374 , y_or_row_idx = 63, likelihood=0.999)\n",
    "top_cam.add_manual_test_position_marker(marker_id = 'screw1_top', x_or_column_idx = 360, y_or_row_idx = 132, likelihood=0.999)\n",
    "top_cam.add_manual_test_position_marker(marker_id = 'screw1_nut', x_or_column_idx = 358, y_or_row_idx = 136, likelihood=0.999)\n",
    "top_cam.add_manual_test_position_marker(marker_id = 'screw2_top', x_or_column_idx = 359, y_or_row_idx = 180, likelihood=0.999)\n",
    "top_cam.add_manual_test_position_marker(marker_id = 'screw3_top', x_or_column_idx = 360, y_or_row_idx = 194, likelihood=0.999)\n",
    "top_cam.add_manual_test_position_marker(marker_id = 'screw4_top', x_or_column_idx = 360, y_or_row_idx = 216, likelihood=0.999)\n",
    "top_cam.add_manual_test_position_marker(marker_id = 'x1', x_or_column_idx = 340, y_or_row_idx = 121, likelihood=0.999)\n",
    "top_cam.add_manual_test_position_marker(marker_id = 'x2', x_or_column_idx = 344, y_or_row_idx = 247, likelihood=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d5371f-59e5-4de5-9e24-3f11a1da20c1",
   "metadata": {},
   "source": [
    "In order to save them & also bring them into the correct DataFrame format, run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9ce84a-1f45-4a89-b079-df8d010f6a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cam.validate_and_save_manual_marker_coords_as_fake_dlc_output(test_positions_gt=test_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd9e13-3426-43d5-826a-44a4ed58e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_cam.save_manual_marker_coords_as_fake_dlc_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a9b34-28c4-4508-9224-112e1a0f480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cam.test_position_markers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf0a65-4be9-472f-893c-4116899a489e",
   "metadata": {},
   "source": [
    "Most likely, you will not be able to see all the test position markers from the individual camera FOV. Simply add those that you can see & eventually run the following method to validate them, which: a) adds those markers that are present in the test positions ground truth object but are missing in your current camera object with a likelihood of 0; and b) removes all marker ids that you added to your camera object, but are not present in the ground truth (to avoid typos, ..). Of course, you will be notified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee4e203-31c9-4c7f-b423-08de25275436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_cam.validate_test_position_marker_ids(test_positions_gt=test_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf6ed81-859c-44b2-933a-fe4bee0a761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_cam.test_position_markers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdc8316-0f31-4088-9e07-65810ceb48d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bottom cam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9f2451-7f4c-4e1c-a43d-684bbae58877",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('/mnt/c/Users/dsege/Downloads/220825/220825/Bottom_cam_synchronized_for_calibration_all_parts.mp4')\n",
    "bottom_cam = SingleCamDataForAnipose(cam_id = 'Bottom', filepath_synchronized_calibration_video = filepath, fisheye = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fee5d3-0dbf-4dbc-87a0-703b6a4735ea",
   "metadata": {},
   "source": [
    "Next, it makes sense to add all additional metadata about your camera, like the offset of the cropping indices that you noted during cropping in ICCapture & whether and how the video stream was flipped. If you did neither crop the video nor flip it, you can simply skip these functions and the default values (offsets = (0, 0) and both flippings = False) will be loaded automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4262058d-29b8-4940-a954-e456458d9f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_cam.add_cropping_offsets(x_or_column_offset=136, y_or_row_offset=452)\n",
    "bottom_cam.add_flipping_details(flipped_horizontally=False, flipped_vertically=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4ac342-69b3-4e31-a544-a21810dde3a1",
   "metadata": {},
   "source": [
    "Let´s stay with the properties of the camera also for the next step: the intrinsic camera calibration (see some explanation of what this is and why it is neccessary at the very top of this notebook). You can either run it (see the following cell - don´t worry, the calibration results will automatically be saved in the same directory where the checkerboard video is) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49297f16-635e-4b8f-ac16-fdeeee6e9986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath_checkerboard_recording = Path('/mnt/c/Users/dsege/Downloads/220825/220825/Checkerboard_Calibration/Bottom_checkerboard.mp4')\n",
    "#bottom_cam.run_intrinsic_camera_calibration(filepath_checkerboard_video=filepath_checkerboard_recording, max_frame_count=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82167ed3-1014-49ff-ba54-37cee1d7b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_intrinsic_calibration = intrinsic_calibrations_dir.joinpath('Bottom_checkerboard_intrinsic_calibration_results_1000frames.p')\n",
    "bottom_cam.load_intrinsic_camera_calibration(filepath_intrinsic_calibration = filepath_intrinsic_calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58264684-68aa-49c1-9546-9c38f817fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "bottom_cam.inspect_intrinsic_calibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5339ecdd-e3d1-47c0-9a88-e6e05034b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plot_single_frame_of_video(filepath='/mnt/c/Users/dsege/Downloads/220825/220825/220825_Bottom_Positions.jpg', frame_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee023aa8-1eb7-4003-9ad7-39593779e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_cam.add_manual_test_position_marker(marker_id = 'maze_corner_closed_left', x_or_column_idx = 859, y_or_row_idx = 30, likelihood=0.999)\n",
    "bottom_cam.add_manual_test_position_marker(marker_id = 'maze_corner_closed_right', x_or_column_idx = 857, y_or_row_idx = 102, likelihood=0.999)\n",
    "bottom_cam.add_manual_test_position_marker(marker_id = 'maze_corner_open_left', x_or_column_idx = 24, y_or_row_idx = 18, likelihood=0.999)\n",
    "bottom_cam.add_manual_test_position_marker(marker_id = 'maze_corner_open_right', x_or_column_idx = 28, y_or_row_idx = 80, likelihood=0.999)\n",
    "bottom_cam.add_manual_test_position_marker(marker_id = 'x1', x_or_column_idx = 134, y_or_row_idx = 1, likelihood=0.999)\n",
    "bottom_cam.add_manual_test_position_marker(marker_id = 'x2', x_or_column_idx = 517, y_or_row_idx = 1, likelihood=0.999)\n",
    "bottom_cam.add_manual_test_position_marker(marker_id = 'screw1_bottom', x_or_column_idx = 191, y_or_row_idx = 42, likelihood=0.999)\n",
    "bottom_cam.add_manual_test_position_marker(marker_id = 'screw2_bottom', x_or_column_idx = 281, y_or_row_idx = 46, likelihood=0.999)\n",
    "bottom_cam.add_manual_test_position_marker(marker_id = 'screw3_bottom', x_or_column_idx = 330, y_or_row_idx = 47, likelihood=0.999)\n",
    "bottom_cam.add_manual_test_position_marker(marker_id = 'screw4_bottom', x_or_column_idx = 403, y_or_row_idx = 42, likelihood=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cdaef1-adf0-49bf-a9f8-ea6360481cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_cam.validate_and_save_manual_marker_coords_as_fake_dlc_output(test_positions_gt=test_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef9825-f041-4c80-b911-602a75f04229",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_cam.test_position_markers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c290e4-6028-4175-a8dc-30b7d97e634a",
   "metadata": {},
   "source": [
    "Most likely, you will not be able to see all the test position markers from the individual camera FOV. Simply add those that you can see & eventually run the following method to validate them, which: a) adds those markers that are present in the test positions ground truth object but are missing in your current camera object with a likelihood of 0; and b) removes all marker ids that you added to your camera object, but are not present in the ground truth (to avoid typos, ..). Of course, you will be notified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bead4-7bb4-4fd0-9441-d5a0be009631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bottom_cam.validate_test_position_marker_ids(test_positions_gt=test_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ec8ce-7aae-4a8a-bd0b-7c9eef1e3133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bottom_cam.test_position_markers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea12498c-f436-4104-b329-79adfb8f0e9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Side1 cam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bba5c39-e58f-47f7-89b2-cbf1943ed24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('/mnt/c/Users/dsege/Downloads/220825/220825/Side1_cam_synchronized_for_calibration_all_parts.mp4')\n",
    "side1_cam = SingleCamDataForAnipose(cam_id = 'Side1', filepath_synchronized_calibration_video = filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee930571-b35a-4a22-b509-79ae812864ba",
   "metadata": {},
   "source": [
    "Next, it makes sense to add all additional metadata about your camera, like the offset of the cropping indices that you noted during cropping in ICCapture & whether and how the video stream was flipped. If you did neither crop the video nor flip it, you can simply skip these functions and the default values (offsets = (0, 0) and both flippings = False) will be loaded automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ce6a7-90fc-4558-b7f8-6e71e910d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "side1_cam.add_cropping_offsets(x_or_column_offset=84, y_or_row_offset=132)\n",
    "side1_cam.add_flipping_details(flipped_horizontally=True, flipped_vertically=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77676d29-3637-42ee-8286-854c3a899977",
   "metadata": {},
   "source": [
    "Let´s stay with the properties of the camera also for the next step: the intrinsic camera calibration (see some explanation of what this is and why it is neccessary at the very top of this notebook). You can either run it (see the following cell - don´t worry, the calibration results will automatically be saved in the same directory where the checkerboard video is) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c292f-3d48-4010-9782-39e0a079ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath_checkerboard_recording = Path('/mnt/c/Users/dsege/Downloads/220825/220825/Checkerboard_Calibration/Side1_checkerboard.mp4')\n",
    "#side1_cam.run_intrinsic_camera_calibration(filepath_checkerboard_video=filepath_checkerboard_recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc83ca4a-4107-4803-a648-591f62c88335",
   "metadata": {},
   "source": [
    "... or load it from disk, if you have previously performed the calibration already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e43d8a-8e33-4d8d-ac56-a43823f24a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_intrinsic_calibration = intrinsic_calibrations_dir.joinpath('Side1_checkerboard_intrinsic_calibration_results.p')\n",
    "side1_cam.load_intrinsic_camera_calibration(filepath_intrinsic_calibration = filepath_intrinsic_calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee988082-f360-4427-94e9-80e5db95fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "side1_cam.inspect_intrinsic_calibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab0dde4-44ab-405b-9355-1650e6bd9685",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plot_single_frame_of_video(filepath='/mnt/c/Users/dsege/Downloads/220825/220825/220825_Side1_Positions.jpg', frame_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f86f69-a64b-47f2-9bc4-2089078ce651",
   "metadata": {},
   "outputs": [],
   "source": [
    "side1_cam.add_manual_test_position_marker(marker_id = 'maze_corner_open_left', x_or_column_idx = 134, y_or_row_idx = 169, likelihood=0.999)\n",
    "side1_cam.add_manual_test_position_marker(marker_id = 'x1', x_or_column_idx = 398, y_or_row_idx = 129, likelihood=0.999)\n",
    "side1_cam.add_manual_test_position_marker(marker_id = 'screw1_bottom', x_or_column_idx = 475, y_or_row_idx = 130, likelihood=0.999)\n",
    "side1_cam.add_manual_test_position_marker(marker_id = 'screw1_nut', x_or_column_idx = 460, y_or_row_idx = 14, likelihood=0.999)\n",
    "side1_cam.add_manual_test_position_marker(marker_id = 'screw2_bottom', x_or_column_idx = 562, y_or_row_idx = 123, likelihood=0.999)\n",
    "side1_cam.add_manual_test_position_marker(marker_id = 'screw2_top', x_or_column_idx = 559, y_or_row_idx = 75, likelihood=0.999)\n",
    "side1_cam.add_manual_test_position_marker(marker_id = 'screw3_bottom', x_or_column_idx = 597, y_or_row_idx = 120, likelihood=0.999)\n",
    "side1_cam.add_manual_test_position_marker(marker_id = 'screw3_top', x_or_column_idx = 589, y_or_row_idx = 72, likelihood=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ce683f-2f36-4c6e-8035-7511f5ec9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "side1_cam.validate_and_save_manual_marker_coords_as_fake_dlc_output(test_positions_gt=test_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b48baa-aed5-496c-bffb-c6f8488af847",
   "metadata": {},
   "outputs": [],
   "source": [
    "side1_cam.test_position_markers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478d4c0-cb03-452b-9350-1ff20bb0da74",
   "metadata": {},
   "source": [
    "Most likely, you will not be able to see all the test position markers from the individual camera FOV. Simply add those that you can see & eventually run the following method to validate them, which: a) adds those markers that are present in the test positions ground truth object but are missing in your current camera object with a likelihood of 0; and b) removes all marker ids that you added to your camera object, but are not present in the ground truth (to avoid typos, ..). Of course, you will be notified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488005d-8e49-4fb6-999d-2cf4720f510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#side1_cam.validate_test_position_marker_ids(test_positions_gt=test_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa3e370-a671-41c3-be23-5ee5c8271019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#side1_cam.test_position_markers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b3bda5-608c-4eb0-88f3-c24dd97fbe62",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Side2 cam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39e7e2-37a4-4cc8-9eb2-0876f035d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('/mnt/c/Users/dsege/Downloads/220825/220825/Side2_cam_synchronized_for_calibration_all_parts.mp4')\n",
    "side2_cam = SingleCamDataForAnipose(cam_id = 'Side2', filepath_synchronized_calibration_video = filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b49193a-f931-4c28-a952-97bd3846251f",
   "metadata": {},
   "source": [
    "Next, it makes sense to add all additional metadata about your camera, like the offset of the cropping indices that you noted during cropping in ICCapture & whether and how the video stream was flipped. If you did neither crop the video nor flip it, you can simply skip these functions and the default values (offsets = (0, 0) and both flippings = False) will be loaded automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e0011-4ab5-4976-a0f1-a27d58f1f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "side2_cam.add_cropping_offsets(x_or_column_offset=104, y_or_row_offset=156)\n",
    "side2_cam.add_flipping_details(flipped_horizontally=True, flipped_vertically=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219c1f8-b647-41b5-adaf-cb56ae9ceb53",
   "metadata": {},
   "source": [
    "Let´s stay with the properties of the camera also for the next step: the intrinsic camera calibration (see some explanation of what this is and why it is neccessary at the very top of this notebook). You can either run it (see the following cell - don´t worry, the calibration results will automatically be saved in the same directory where the checkerboard video is) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8381afb-42bf-4b00-a63e-08102b53f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath_checkerboard_recording = Path('/mnt/c/Users/dsege/Downloads/220825/220825/Checkerboard_Calibration/Side2_checkerboard.mp4')\n",
    "#side2_cam.run_intrinsic_camera_calibration(filepath_checkerboard_video=filepath_checkerboard_recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4d724-315f-4f3f-8711-7f7990ff25f4",
   "metadata": {},
   "source": [
    "... or load it from disk, if you have previously performed the calibration already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a644789f-9f6e-460e-b575-c916b2e2e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_intrinsic_calibration = intrinsic_calibrations_dir.joinpath('Side2_checkerboard_intrinsic_calibration_results.p')\n",
    "side2_cam.load_intrinsic_camera_calibration(filepath_intrinsic_calibration = filepath_intrinsic_calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27923d30-ca0d-450d-847b-6ca6a5793600",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "side2_cam.inspect_intrinsic_calibration(frame_idx = 380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4933ff-bcf3-434e-b92f-628271a80e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plot_single_frame_of_video(filepath='/mnt/c/Users/dsege/Downloads/220825/220825/220825_Side2_Positions.jpg', frame_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f838990-b226-4695-9440-11c27651570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "side2_cam.add_manual_test_position_marker(marker_id = 'maze_corner_closed_left', x_or_column_idx = 646, y_or_row_idx = 168, likelihood=0.999)\n",
    "side2_cam.add_manual_test_position_marker(marker_id = 'maze_corner_closed_right', x_or_column_idx = 614, y_or_row_idx = 168, likelihood=0.999)\n",
    "side2_cam.add_manual_test_position_marker(marker_id = 'screw1_bottom', x_or_column_idx = 19, y_or_row_idx = 176, likelihood=0.999)\n",
    "side2_cam.add_manual_test_position_marker(marker_id = 'screw1_nut', x_or_column_idx = 16, y_or_row_idx = 71, likelihood=0.999)\n",
    "side2_cam.add_manual_test_position_marker(marker_id = 'screw1_top', x_or_column_idx = 22, y_or_row_idx = 31, likelihood=0.999)\n",
    "side2_cam.add_manual_test_position_marker(marker_id = 'screw2_bottom', x_or_column_idx = 98, y_or_row_idx = 173, likelihood=0.999)\n",
    "side2_cam.add_manual_test_position_marker(marker_id = 'screw2_top', x_or_column_idx = 99, y_or_row_idx = 121, likelihood=0.999)\n",
    "side2_cam.add_manual_test_position_marker(marker_id = 'screw3_bottom', x_or_column_idx = 135, y_or_row_idx = 171, likelihood=0.999)\n",
    "side2_cam.add_manual_test_position_marker(marker_id = 'screw3_top', x_or_column_idx = 133, y_or_row_idx = 119, likelihood=0.999)\n",
    "side2_cam.add_manual_test_position_marker(marker_id = 'screw4_bottom', x_or_column_idx = 197, y_or_row_idx = 174, likelihood=0.999)\n",
    "side2_cam.add_manual_test_position_marker(marker_id = 'screw4_top', x_or_column_idx = 194, y_or_row_idx = 50, likelihood=0.999)\n",
    "side2_cam.add_manual_test_position_marker(marker_id = 'x2', x_or_column_idx = 286, y_or_row_idx = 162, likelihood=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92473a4e-a86c-4569-84a5-34a80d08f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "side2_cam.validate_and_save_manual_marker_coords_as_fake_dlc_output(test_positions_gt=test_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c4836-d455-4bc8-bc08-00908dce8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "side2_cam.test_position_markers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d81ae2-7bf3-4dee-a00c-92dc3122faa6",
   "metadata": {},
   "source": [
    "Most likely, you will not be able to see all the test position markers from the individual camera FOV. Simply add those that you can see & eventually run the following method to validate them, which: a) adds those markers that are present in the test positions ground truth object but are missing in your current camera object with a likelihood of 0; and b) removes all marker ids that you added to your camera object, but are not present in the ground truth (to avoid typos, ..). Of course, you will be notified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea99759a-bd93-4362-96bc-a7c7a1c67ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#side2_cam.validate_test_position_marker_ids(test_positions_gt=test_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f905b551-3b0a-43d3-aef1-66551a6dd346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#side2_cam.test_position_markers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b993e9a-4680-436c-ada3-30ade5d9dcc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ground1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6eabc8-c57d-45ce-8faf-05299d6643f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('/mnt/c/Users/dsege/Downloads/220825/220825/Ground1_cam_synchronized_for_calibration_all_parts.mp4')\n",
    "ground1_cam = SingleCamDataForAnipose(cam_id = 'Ground1', filepath_synchronized_calibration_video = filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedc53f6-f862-4224-8999-f3befa16cc9c",
   "metadata": {},
   "source": [
    "Next, it makes sense to add all additional metadata about your camera, like the offset of the cropping indices that you noted during cropping in ICCapture & whether and how the video stream was flipped. If you did neither crop the video nor flip it, you can simply skip these functions and the default values (offsets = (0, 0) and both flippings = False) will be loaded automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb822cbe-5539-458b-9aaf-59a18d53ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground1_cam.add_cropping_offsets(x_or_column_offset=32, y_or_row_offset=44)\n",
    "ground1_cam.add_flipping_details(flipped_horizontally=False, flipped_vertically=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb85ca9-e9f6-47ad-a1b5-52ef52730e48",
   "metadata": {},
   "source": [
    "Let´s stay with the properties of the camera also for the next step: the intrinsic camera calibration (see some explanation of what this is and why it is neccessary at the very top of this notebook). You can either run it (see the following cell - don´t worry, the calibration results will automatically be saved in the same directory where the checkerboard video is) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f73ddd-d445-4295-a465-cd1cdd4942d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath_checkerboard_recording = Path('/mnt/c/Users/dsege/Downloads/220825/220825/Checkerboard_Calibration/Ground1_checkerboard.mp4')\n",
    "#ground1_cam.run_intrinsic_camera_calibration(filepath_checkerboard_video=filepath_checkerboard_recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8082948-c691-41ad-9e76-68d9fdfaf4d7",
   "metadata": {},
   "source": [
    "... or load it from disk, if you have previously performed the calibration already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e78b2-07a0-4974-8e9e-683457c60c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_intrinsic_calibration = intrinsic_calibrations_dir.joinpath('Ground1_checkerboard_intrinsic_calibration_results.p')\n",
    "ground1_cam.load_intrinsic_camera_calibration(filepath_intrinsic_calibration = filepath_intrinsic_calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f268bb44-97ff-4eec-9d2f-50c95a639657",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "ground1_cam.inspect_intrinsic_calibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5c5bee-6c01-4c2b-a260-3990f34a1c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plot_single_frame_of_video(filepath='/mnt/c/Users/dsege/Downloads/220825/220825/220825_Ground1_Positions.jpg', frame_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c562ca-bd21-471c-b4d8-0e12a18479e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground1_cam.add_manual_test_position_marker(marker_id = 'maze_corner_closed_right', x_or_column_idx = 590, y_or_row_idx = 223, likelihood=0.999)\n",
    "ground1_cam.add_manual_test_position_marker(marker_id = 'maze_corner_open_left', x_or_column_idx = 66, y_or_row_idx = 46, likelihood=0.999)\n",
    "ground1_cam.add_manual_test_position_marker(marker_id = 'maze_corner_open_right', x_or_column_idx = 35, y_or_row_idx = 165, likelihood=0.999)\n",
    "ground1_cam.add_manual_test_position_marker(marker_id = 'screw1_bottom', x_or_column_idx = 390, y_or_row_idx = 119, likelihood=0.999)\n",
    "ground1_cam.add_manual_test_position_marker(marker_id = 'screw1_nut', x_or_column_idx = 311, y_or_row_idx = 77, likelihood=0.999)\n",
    "ground1_cam.add_manual_test_position_marker(marker_id = 'screw1_top', x_or_column_idx = 282, y_or_row_idx = 69, likelihood=0.999)\n",
    "ground1_cam.add_manual_test_position_marker(marker_id = 'screw2_bottom', x_or_column_idx = 443, y_or_row_idx = 135, likelihood=0.999)\n",
    "ground1_cam.add_manual_test_position_marker(marker_id = 'screw3_bottom', x_or_column_idx = 466, y_or_row_idx = 139, likelihood=0.999)\n",
    "ground1_cam.add_manual_test_position_marker(marker_id = 'screw4_bottom', x_or_column_idx = 493, y_or_row_idx = 146, likelihood=0.999)\n",
    "ground1_cam.add_manual_test_position_marker(marker_id = 'screw4_top', x_or_column_idx = 422, y_or_row_idx = 102, likelihood=0.999)\n",
    "ground1_cam.add_manual_test_position_marker(marker_id = 'x1', x_or_column_idx = 340, y_or_row_idx = 54, likelihood=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b822db-e9f8-4f83-9d11-662e8f681e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground1_cam.validate_and_save_manual_marker_coords_as_fake_dlc_output(test_positions_gt=test_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db4b9e-b474-40b9-8f16-b2d365a2434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground1_cam.test_position_markers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03232d96-737b-4f6b-b1e1-1d5c2bffab38",
   "metadata": {},
   "source": [
    "Most likely, you will not be able to see all the test position markers from the individual camera FOV. Simply add those that you can see & eventually run the following method to validate them, which: a) adds those markers that are present in the test positions ground truth object but are missing in your current camera object with a likelihood of 0; and b) removes all marker ids that you added to your camera object, but are not present in the ground truth (to avoid typos, ..). Of course, you will be notified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2478561-7e3a-4a07-b284-2631920ee491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground1_cam.validate_test_position_marker_ids(test_positions_gt=test_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1dc258-3834-4a84-b189-b9f0525507cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground1_cam.test_position_markers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed1c866-a109-410b-9f9e-50492e81d568",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ground2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149185ff-4d95-4dfa-924a-a2ad90431146",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('/mnt/c/Users/dsege/Downloads/220825/220825/Ground2_cam_synchronized_for_calibration_all_parts.mp4')\n",
    "ground2_cam = SingleCamDataForAnipose(cam_id = 'Ground2', filepath_synchronized_calibration_video = filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d797a6a6-46c3-4e1c-87dc-6dea142e4686",
   "metadata": {},
   "source": [
    "Next, it makes sense to add all additional metadata about your camera, like the offset of the cropping indices that you noted during cropping in ICCapture & whether and how the video stream was flipped. If you did neither crop the video nor flip it, you can simply skip these functions and the default values (offsets = (0, 0) and both flippings = False) will be loaded automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfb77ff-5fa5-4f86-a490-503f14ccd261",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground2_cam.add_cropping_offsets(x_or_column_offset=0, y_or_row_offset=52)\n",
    "ground2_cam.add_flipping_details(flipped_horizontally=False, flipped_vertically=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13137c1-95c3-41d2-9e0f-447ac74d6947",
   "metadata": {},
   "source": [
    "Let´s stay with the properties of the camera also for the next step: the intrinsic camera calibration (see some explanation of what this is and why it is neccessary at the very top of this notebook). You can either run it (see the following cell - don´t worry, the calibration results will automatically be saved in the same directory where the checkerboard video is) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c25cf-0323-4b9f-8ecf-7c053596f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath_checkerboard_recording = Path('/mnt/c/Users/dsege/Downloads/220825/220825/Checkerboard_Calibration/Ground2_checkerboard.mp4')\n",
    "#ground2_cam.run_intrinsic_camera_calibration(filepath_checkerboard_video=filepath_checkerboard_recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb40aa97-1f79-4d3b-9f12-4bca268dcd88",
   "metadata": {},
   "source": [
    "... or load it from disk, if you have previously performed the calibration already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae86c7a-d708-4381-87d5-c7ffdf694abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_intrinsic_calibration = intrinsic_calibrations_dir.joinpath('Ground2_checkerboard_intrinsic_calibration_results.p')\n",
    "ground2_cam.load_intrinsic_camera_calibration(filepath_intrinsic_calibration = filepath_intrinsic_calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a992aa8-08c4-4207-9c5e-a0437da6427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "ground2_cam.inspect_intrinsic_calibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd395d-f2c4-4cb1-8d83-14757b50cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plot_single_frame_of_video(filepath='/mnt/c/Users/dsege/Downloads/220825/220825/220825_Ground2_Positions.jpg', frame_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c221a023-714d-4e01-a132-2d04726695e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground2_cam.add_manual_test_position_marker(marker_id = 'maze_corner_closed_left', x_or_column_idx = 689, y_or_row_idx = 37, likelihood=0.999)\n",
    "ground2_cam.add_manual_test_position_marker(marker_id = 'maze_corner_closed_right', x_or_column_idx = 685, y_or_row_idx = 89, likelihood=0.999)\n",
    "ground2_cam.add_manual_test_position_marker(marker_id = 'maze_corner_open_right', x_or_column_idx = 5, y_or_row_idx = 233, likelihood=0.999)\n",
    "ground2_cam.add_manual_test_position_marker(marker_id = 'screw1_bottom', x_or_column_idx = 107, y_or_row_idx = 148, likelihood=0.999)\n",
    "ground2_cam.add_manual_test_position_marker(marker_id = 'screw1_nut', x_or_column_idx = 130, y_or_row_idx = 86, likelihood=0.999)\n",
    "ground2_cam.add_manual_test_position_marker(marker_id = 'screw1_top', x_or_column_idx = 141, y_or_row_idx = 67, likelihood=0.999)\n",
    "ground2_cam.add_manual_test_position_marker(marker_id = 'screw2_bottom', x_or_column_idx = 167, y_or_row_idx = 132, likelihood=0.999)\n",
    "ground2_cam.add_manual_test_position_marker(marker_id = 'screw2_top', x_or_column_idx = 179, y_or_row_idx = 102, likelihood=0.999)\n",
    "ground2_cam.add_manual_test_position_marker(marker_id = 'screw3_bottom', x_or_column_idx = 192, y_or_row_idx = 123, likelihood=0.999)\n",
    "ground2_cam.add_manual_test_position_marker(marker_id = 'screw3_top', x_or_column_idx = 202, y_or_row_idx = 93, likelihood=0.999)\n",
    "ground2_cam.add_manual_test_position_marker(marker_id = 'screw4_bottom', x_or_column_idx = 239, y_or_row_idx = 111, likelihood=0.999)\n",
    "ground2_cam.add_manual_test_position_marker(marker_id = 'screw4_top', x_or_column_idx = 251, y_or_row_idx = 36, likelihood=0.999)\n",
    "ground2_cam.add_manual_test_position_marker(marker_id = 'x2', x_or_column_idx = 296, y_or_row_idx = 68, likelihood=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c516399-b622-490b-972d-c2f2e427457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground2_cam.validate_and_save_manual_marker_coords_as_fake_dlc_output(test_positions_gt=test_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fcbb8c-3f59-4ea7-922b-30b3d556370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground2_cam.test_position_markers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9d92f-7634-4874-a68c-71606872935c",
   "metadata": {},
   "source": [
    "Most likely, you will not be able to see all the test position markers from the individual camera FOV. Simply add those that you can see & eventually run the following method to validate them, which: a) adds those markers that are present in the test positions ground truth object but are missing in your current camera object with a likelihood of 0; and b) removes all marker ids that you added to your camera object, but are not present in the ground truth (to avoid typos, ..). Of course, you will be notified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfd9166-9393-4333-8cad-ae2c93a9e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground2_cam.validate_test_position_marker_ids(test_positions_gt=test_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b20a6cc-c62f-466a-a330-8df78edcfa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground2_cam.test_position_markers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbe8a75-c6eb-4c5b-92c1-ea5155341664",
   "metadata": {},
   "source": [
    "## Step 3) Run and evaluate cross-camera calibration for pose estimation using anipose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860faeb-7e73-4652-8ec7-f8c0312976c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gait3d.camera_calibration import CalibrationForAnipose3DTracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae5b844-3783-4fdb-9d4c-627a726907ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cams = [ground1_cam, ground2_cam, side1_cam, side2_cam, top_cam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13247b5-7163-414d-93d6-3b65710d2d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anipose_calibration = CalibrationForAnipose3DTracking(single_cams_to_calibrate = single_cams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e638260f-aee7-4cfd-bc0f-f8fc918a07bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "anipose_calibration.calibration_video_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31817d6-3780-497d-ba9e-08a30126296e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anipose_calibration.run_calibration(use_own_intrinsic_calibration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9835f720-6dab-4489-9d53-daa43d33fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "anipose_calibration.evaluate_triangulation_of_test_position_markers(test_positions_gt = test_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd2c064-40fd-4d3d-b852-e93ad2489d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "anipose_calibration.save_calibration(filepath = Path('/mnt/c/Users/dsege/Downloads/220825/220825/anipose_calibration_all_cams.toml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2ee66b-f243-4bde-900c-c705a82abc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('/mnt/c/Users/dsege/Downloads/220825/220825/anipose_calibration_all_cams.toml').as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b0dd44-0de3-432e-8dc1-f03bae89182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "anipose_calibration.load_calibration(filepath = filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33772b1-a471-4f60-ae93-f3737070ff5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0254a7b-af3e-47c8-bcb9-4dc90fad48f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "\n",
    "\n",
    "it.combinations(anipose_io, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd627a4b-c970-4340-bf03-42b82abb4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "anipose_io['bodyparts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa767f-f78b-49cd-abbe-d9aa001a67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "anipose_calibration.anipose_io['reprojection_errors_test_position_markers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51616b30-644e-4444-848c-0d790ffd8f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aniposelib as ap_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2510d328-5c9d-48a2-9dfd-6b45c117b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_dict = {}\n",
    "for single_cam in anipose_calibration.single_cam_objects:\n",
    "    fname_dict[single_cam.cam_id] = single_cam.filepath_test_position_marker_prediction\n",
    "anipose_io = ap_lib.utils.load_pose2d_fnames(fname_dict = fname_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13c1fcb-2277-4bbe-8309-310dcae0aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df4254-cafe-4980-8352-dcd63fc5b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "anipose_io['bodyparts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f9ee22-1f15-41ac-89e6-d10bb801fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "?ap_lib.utils.load_pose2d_fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5559a-f1c4-4e1f-8086-2e5fcf04c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_hdf('/mnt/c/Users/dsege/Downloads/220825/220825/Ground1_manual_test_position_marker_fake.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b75fb-3915-4841-acb5-aa94c81d95b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, bodyparts, key in df.columns:\n",
    "    if key == 'x':\n",
    "        print(bodyparts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92ff93e-1c80-43d6-bc3c-18d973342a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "anipose_io['bodyparts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d007ea0-c7b0-41b8-8880-1738968a584c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25252eb6-ce96-45b5-8021-5277bf7d12c5",
   "metadata": {},
   "source": [
    "## For each camera:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92f342d-338c-4cda-a204-7ed6648f883d",
   "metadata": {},
   "source": [
    "bottom_cam = camera_calibration.SingleCamDataForAnipose(cam_id = 'bottom', filepath = Path('bums'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0981ea-60ac-4263-9237-89d67a0fc8e3",
   "metadata": {},
   "source": [
    "bottom_cam.add_manual_test_position_marker(marker_id = 'maze_corner_closed_left', x_or_column_idx = 490, y_or_column_idx = 10)\n",
    "bottom_cam.add_manual_test_position_marker(marker_id = 'maze_corner_closed_left', x_or_column_idx = 490, y_or_column_idx = 10)\n",
    "bottom_cam.add_manual_test_position_marker(marker_id = 'maze_corner_closed_left', x_or_column_idx = 490, y_or_column_idx = 10)\n",
    "bottom_cam.add_manual_test_position_marker(marker_id = 'maze_corner_closed_left', x_or_column_idx = 490, y_or_column_idx = 10)\n",
    "bottom_cam.save_manual_marker_coords_as_fake_dlc_output()\n",
    "\n",
    "# or:\n",
    "bottom_cam.load_test_position_markers_df_from_dlc_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5362da-4aec-41b7-a1d7-d694f18e102a",
   "metadata": {},
   "source": [
    "bottom_cam.validate_test_position_marker_ids(test_positions_gt = test_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4fbee1-60a3-4ad2-aabf-c6208d8321bb",
   "metadata": {},
   "source": [
    "bottom_cam.run_intrinsic_camera_calibration(filepath_checkerboard_video, fisheye_cam = True, save, max_frame_count = 300)\n",
    "# or:\n",
    "bottom_cam.load_intrinsic_camera_calibration(filepath_intrinsic_calibration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157fe86e-b867-47cd-b8ef-ff200f323121",
   "metadata": {},
   "source": [
    "## Calibration for Anipose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8eb052-4d8a-4e75-a1d1-c9877d0dc1e7",
   "metadata": {},
   "source": [
    "calibration_for_anipose = CalibrationForAnipose3DTracking(single_cams_to_calibrate = [bottom_cam, top_cam...])\n",
    "calibration_for_anipose.run_calibration()\n",
    "calibration_for_anipose.save(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3ecd4-ec5e-4028-836d-78db5a901761",
   "metadata": {},
   "source": [
    "calibration_for_anipose.evaluate_triangulation_of_test_position_markers(test_positions_gt = test_positions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
