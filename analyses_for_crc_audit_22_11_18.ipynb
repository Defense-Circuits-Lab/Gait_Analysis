{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab4c2d3-51f8-4291-87e4-16165b90524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List, Tuple, Dict, Optional, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca797f-f539-4233-894c-96c3597723fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_only_matching_xlsx_files(dir_path: Path, paradigm_id: str, week_id: Optional[int]=None) -> List[Path]:\n",
    "    filtered_filepaths = []\n",
    "    for filepath in dir_path.iterdir():\n",
    "        if filepath.name.endswith('.xlsx') and (paradigm_id in filepath.name):\n",
    "            if week_id != None:\n",
    "                if f'week-{week_id}.' in filepath.name:\n",
    "                    filtered_filepaths.append(filepath)\n",
    "            else:\n",
    "                filtered_filepaths.append(filepath)\n",
    "    return filtered_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a197b8-e33c-4aef-bbae-e1e307e8d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_from_filename(filepath_session_results: Path, filepath_group_assignment: Path=Path('test_data/group_assignment.xlsx')) -> Dict:\n",
    "    metadata = {}\n",
    "    metadata['line_id'], mouse_id, metadata['paradigm_id'], week_string_with_file_extension = filepath_session_results.name.split('_')\n",
    "    metadata['subject_id'] = f'{metadata[\"line_id\"]}_{mouse_id}'\n",
    "    metadata['week_id'] = week_string_with_file_extension[week_string_with_file_extension.find('-') + 1:week_string_with_file_extension.find('.')]\n",
    "    df_group_assignment = pd.read_excel(filepath_group_assignment)\n",
    "    if metadata['subject_id'] in df_group_assignment['subject_id'].unique():\n",
    "        metadata['group_id'] = df_group_assignment.loc[df_group_assignment['subject_id'] == metadata['subject_id'], 'group_id'].iloc[0]\n",
    "    elif metadata['subject_id'] in df_group_assignment['alternative_subject_id'].unique():\n",
    "        metadata['group_id'] = df_group_assignment.loc[df_group_assignment['alternative_subject_id'] == metadata['subject_id'], 'group_id'].iloc[0]    \n",
    "    else:\n",
    "        metadata['group_id'] = 'unknown'\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a34f7e-4565-450c-a864-2820d75ba32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_availability(root_dir_path: Path, all_week_ids: List[int], all_paradigm_ids: List[str]) -> pd.DataFrame:\n",
    "    df = pd.DataFrame({}, index=all_week_ids)\n",
    "    root_dir_path = root_dir_path\n",
    "    for week_id in all_week_ids:\n",
    "        for paradigm_id in all_paradigm_ids:\n",
    "            all_matching_filepaths = get_only_matching_xlsx_files(dir_path = root_dir_path, paradigm_id = paradigm_id, week_id = week_id)\n",
    "            for filepath in all_matching_filepaths:\n",
    "                subject_id = get_metadata_from_filename(filepath)['subject_id']\n",
    "                if f'{subject_id}_{paradigm_id}' not in df.columns:\n",
    "                    df[f'{subject_id}_{paradigm_id}'] = False\n",
    "                df.loc[week_id, f'{subject_id}_{paradigm_id}'] = True\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273bcfff-636f-4eba-8c47-2b53160d537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_available_data(root_dir_path: Path, paradigm_ids: List[str], week_ids: List[str], sheet_name: str) -> pd.DataFrame:\n",
    "    all_recording_results_dfs = []\n",
    "    for week_id in week_ids:\n",
    "        for paradigm_id in paradigm_ids:\n",
    "            tmp_matching_filepaths = get_only_matching_xlsx_files(dir_path = root_dir_path, paradigm_id = paradigm_id, week_id = week_id)\n",
    "            for filepath in tmp_matching_filepaths:\n",
    "                metadata = get_metadata_from_filename(filepath_session_results = filepath)\n",
    "                tmp_xlsx = pd.ExcelFile(filepath)\n",
    "                tmp_df = pd.read_excel(tmp_xlsx, sheet_name = sheet_name, index_col = 0)\n",
    "                for key, value in metadata.items():\n",
    "                    tmp_df[key] = value\n",
    "                all_recording_results_dfs.append(tmp_df)\n",
    "    df = pd.concat(all_recording_results_dfs)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c16ca6-7663-4c19-9692-c87cdbe1cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe(df: pd.DataFrame, filter_criteria: List[Tuple]) -> pd.DataFrame:\n",
    "    # assert all list have equal lenghts\n",
    "    valid_idxs_per_criterion = []\n",
    "    for column_name, comparison_method, reference_value in filter_criteria:\n",
    "        # assert valid key in comparison methods\n",
    "        # assert column name exists\n",
    "        if comparison_method == 'greater':\n",
    "            valid_idxs_per_criterion.append(df.loc[df[column_name] > reference_value].index.values)\n",
    "        elif comparison_method == 'smaller':\n",
    "            valid_idxs_per_criterion.append(df.loc[df[column_name] < reference_value].index.values)\n",
    "        elif comparison_method == 'equal_to':\n",
    "            valid_idxs_per_criterion.append(df.loc[df[column_name] == reference_value].index.values)\n",
    "        elif comparison_method == 'is_in_list':\n",
    "            valid_idxs_per_criterion.append(df.loc[df[column_name].isin(reference_value)].index.values)\n",
    "        elif comparison_method == 'is_nan':\n",
    "            valid_idxs_per_criterion.append(df.loc[df[column_name].isnull()].index.values)\n",
    "    shared_valid_idxs_across_all_criteria = valid_idxs_per_criterion[0]\n",
    "    if len(valid_idxs_per_criterion) > 1:\n",
    "        for i in range(1, len(valid_idxs_per_criterion)):\n",
    "            shared_valid_idxs_across_all_criteria = np.intersect1d(shared_valid_idxs_across_all_criteria, valid_idxs_per_criterion[i])\n",
    "    df_filtered = df.loc[shared_valid_idxs_across_all_criteria, :].copy()\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1429139-aac0-4ef2-b72f-dda5f2b04032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df: pd.DataFrame, x_column: str, y_column: str, plot_type: str='violinplot', hue_column: Optional[str]=None, hide_legend: bool=True):\n",
    "    fig = plt.figure(figsize = (8, 5), facecolor = 'white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    if plot_type == 'violinplot':\n",
    "        sns.violinplot(data = df, x = x_column, y = y_column, hue = hue_column)\n",
    "        if df.shape[0] < 2_000:\n",
    "            sns.stripplot(data = df, x = x_column, y = y_column, hue = hue_column, dodge = True, color = 'black', alpha = 0.3)\n",
    "    elif plot_type == 'stripplot':\n",
    "        sns.stripplot(data = df, x = x_column, y = y_column, hue = hue_column, dodge = True)\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    if hide_legend:\n",
    "        ax.get_legend().remove()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a3dee0-effc-4af2-8c6d-d2e25f2b89a5",
   "metadata": {},
   "source": [
    "## Example usage:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f582b7f-f391-4ce5-b055-8049f6f07ff1",
   "metadata": {},
   "source": [
    "### 1) Load all data:\n",
    "\n",
    "This obviously assumes that you were using the \"run_2d_gait_analysis_with_top_cam.ipynb\" notebook and created the corresponding result exports. You will now have to provide the filepath to these Excel files as `root_dir_path` as a Path object (see exmaple below). You can also specify if you´d like to right away filter only for a certain set of weeks or paradigms (you can also just pass a list with a single value for each). Please note that you have to provide the exact name of the respective Excel Tab you are interested in as:  `sheet_name` <br>\n",
    "For instance, if you´d like to inspect the overall session overview, use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae394a0-8968-465f-a157-0f803d44f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = collect_all_available_data(root_dir_path = Path('/mnt/c/Users/dsege/Downloads/DLC_data/22_11_14/analyses/'),\n",
    "                                paradigm_ids = ['OTR', 'OTT', 'OTE'],\n",
    "                                week_ids = [1, 8, 12, 14],\n",
    "                                sheet_name = 'session_overview')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd8eb18-bd81-47f4-8af8-611968efff71",
   "metadata": {},
   "source": [
    "### 2) Filter your data (optional):\n",
    "\n",
    "You might want to filter your data to only inspect a specific proportion of it. You can do so quite easily by using the `filter_dataframe()` funtion. <br>\n",
    "For this, you need to specify your filter criteria in a list of tuples, for which each tuple follows this schema:\n",
    "> (`column_name`, `comparison_method`, `reference_value`)\n",
    "\n",
    "So for instance, if you´d like to filter your dataframe by selecting only those rows in which the paradigm_id is \"OTE\" and in which the mouse line is one of a list (e.g. \"206\" and \"209\"), your filter criteria would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda2788-c7e9-4592-a6a3-eff35c374137",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_criteria = [('paradigm_id', 'equal_to', 'OTE'),\n",
    "                   ('line_id', 'is_in_list', ['206', '209'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d41f5e-e1bc-4abc-be36-47cfc3f36517",
   "metadata": {},
   "source": [
    "You can add as many tuples (= criteria) you´d like. Currently implemented comparison methods include:\n",
    "- \"greater\": selects only rows in which the values of the column are greater than the reference value\n",
    "- \"smaller\": selects only rows in which the values of the column are smaller than the reference value\n",
    "- \"equal_to\": selects only rows in which the values of the column are equal to the reference value\n",
    "- \"is_in_list\": selects only rows in which the values of the column are matching to an element in the reference value (which has to be a list, in this case)\n",
    "- \"is_nan\": selects only rows in which the values of the column are NaN\n",
    "\n",
    "You can then pass the `filter_criteria` along your dataframe to the `filter_dataframe()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf591e-4042-4447-8a5b-90906f1efcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = filter_dataframe(df = df, filter_criteria = filter_criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f3de1-b048-4920-aa5b-b08619c94054",
   "metadata": {},
   "source": [
    "### 3) Plotting:\n",
    "\n",
    "Eventually, you can also plot your data, filtering it even more, if you´d like to. When you´re using the `plot()` function, you can specify the following parameters:\n",
    "\n",
    "- df: the datafram you´d like to plot (e.g. your filtered dataframe)\n",
    "- x_column: the column name of the data that should be visualized on the x-axis\n",
    "- y_column: the column name of the data that should be visualized on the y-axis\n",
    "- plot_type: currently only \"violinplot\" and \"stripplot\" are implemented\n",
    "- hue_column (optional): if you´d like to use the data of a column to color-code the plotted, you can specify it here (see example below)\n",
    "- hide_legend (optional): pass along as `False` if you´d like the legend of the plot to be displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b684a-fd7f-403c-bf2e-0a01336f6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df = df_filtered, x_column = 'group_id', y_column = 'CenterOfGravity_x_at_bout_start', plot_type = 'violinplot', hue_column='week_id', hide_legend = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
