{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36ae279",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox, HBox, interactive\n",
    "import math\n",
    "import matplotlib.image as img\n",
    "import cv2\n",
    "from IPython.display import clear_output, display\n",
    "from tkinter import Tk, filedialog\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "#import pingouin as pg\n",
    "#import itertools\n",
    "#import statistics as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6effd3ea",
   "metadata": {},
   "source": [
    "This notebook consists of the following classes:\n",
    "  \n",
    "    \n",
    "    class main\n",
    "    class subjects\n",
    "    class session\n",
    "    class side_cam\n",
    "    class bottom_cam\n",
    "    class top_cam\n",
    "    class maze corner\n",
    "    class clean_df\n",
    "    class df_functions\n",
    "    class stats\n",
    "    \n",
    "    class gui\n",
    "        class main_gui\n",
    "        class subject_gui\n",
    "        class bc_gui\n",
    "        class tc_gui\n",
    "        class sc_gui\n",
    "        class maze_corner_gui\n",
    "        class clean_df_gui\n",
    "        class select_functions\n",
    "        class stats_gui\n",
    "        \n",
    "    class defish\n",
    "\n",
    "\n",
    "Name all of your .csv/.mp4/.avi files strictly like this: \n",
    "\n",
    "                        210_F1-83_220518_OTT_bottom\n",
    "                        211_F3-04_211123_OTR_top\n",
    "\n",
    "                        Line_ID_Date_Paradigm_Camera                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c74159",
   "metadata": {},
   "outputs": [],
   "source": [
    "class main: \n",
    "    path = \"\" \n",
    "    framerate = {}\n",
    "    l_maze_corners_bc = []\n",
    "    l_maze_corners_tc = []\n",
    "    dict_cams_used = {}\n",
    "\n",
    "    def __init__(self):\n",
    "        gui.main_gui()\n",
    "        \n",
    "    def all_information_given(self):\n",
    "        self.l_session_IDs = np.unique(np.array([file for file in set ([elem[0:-11] for elem in os.listdir(self.path) if elem.endswith('bottom.csv')]+[elem[0:-8] for elem in os.listdir(self.path) if elem.endswith('top.csv')]+[elem[0:-9] for elem in os.listdir(self.path) if elem.endswith('side.csv')])])).tolist()\n",
    "        self.l_sessions = [session(session_ID) for session_ID in self.l_session_IDs]\n",
    "        self.l_subject_IDs = ([session.subject_ID for session in self.l_sessions])\n",
    "        self.l_subjects = [subject(subject_ID) for subject_ID in self.l_subject_IDs]\n",
    "        gui.subject_gui()\n",
    "        \n",
    "    def get_maze_corners(self):\n",
    "        if self.dict_cams_used[\"bottom_cam\"] & self.all_files_there:\n",
    "            self.l_maze_corners_bc = [session.bc.mc for session in self.l_sessions]\n",
    "        if self.dict_cams_used[\"top_cam\"] & self.all_files_there:\n",
    "            self.l_maze_corners_tc = [session.tc.mc for session in self.l_sessions]\n",
    "        \n",
    "        if self.dict_cams_used[\"bottom_cam\"] or self.dict_cams_used[\"top_cam\"]:\n",
    "            self.l_maze_corners = self.l_maze_corners_bc + self.l_maze_corners_tc\n",
    "            gui.maze_corner_gui()\n",
    "        elif self.dict_cams_used[\"side_cam\"]:\n",
    "            self.get_clean_df_gui(main)\n",
    "            \n",
    "    def get_clean_df_gui(self):\n",
    "        if self.dict_cams_used[\"bottom_cam\"]:\n",
    "            gui.clean_df_gui(\"bottom_cam\")\n",
    "        if self.dict_cams_used[\"top_cam\"]:\n",
    "            gui.clean_df_gui(\"top_cam\")\n",
    "        if self.dict_cams_used[\"side_cam\"]:\n",
    "            pass\n",
    "                   \n",
    "    def get_processed_dfs(self, DLC_likelihood_threshold, cam):\n",
    "        self.dict_bodyparts = {}\n",
    "        if cam == \"bottom_cam\":\n",
    "            #processed_dfs nicht in main_liste setzen, sondern zu den session objects\n",
    "            for session in self.l_sessions:\n",
    "                session.bc.processed_df = clean_df(session.bc.df, session.bc.mc.results, DLC_likelihood_threshold, cam).df \n",
    "        elif cam ==\"top_cam\":\n",
    "            for session in self.l_sessions:\n",
    "                session.tc.processed_df = clean_df(session.tc.df, session.tc.mc.results, DLC_likelihood_threshold, cam).df\n",
    "        elif cam == \"side_cam\":\n",
    "            pass        \n",
    "        gui.select_functions()\n",
    "        \n",
    "    #vor execute functions erst andere cams analysieren\n",
    "    def execute_functions(self, dict_selected_functions):\n",
    "        self.get_col_in_master_df_and_main_dataframe(self, dict_selected_functions)\n",
    "        for subject in self.l_subjects:\n",
    "            for session in subject.l_sessions:\n",
    "                session.master_df = df_functions(subject, session, dict_selected_functions).master_df\n",
    "                self.append_session_to_d_data(self, subject, session, dict_selected_functions)\n",
    "        gui.stats_gui(dict_selected_functions)\n",
    "        \n",
    "    def get_col_in_master_df_and_main_dataframe(self, dict_selected_functions):\n",
    "        self.d_data = {'subject_ID': [], 'group_ID': [], 'paradigm': [], 'trialnumber': [], }\n",
    "        self.col_in_master_df = [('subject_ID', ('subject_ID', '')),\n",
    "                    ('group_ID', ('group_ID', '')),\n",
    "                    ('paradigm', ('paradigm', '')),\n",
    "                    ('trialnumber', ('trialnumber', '')),\n",
    "                    ('time', ('time', '')),\n",
    "                    ('exclude', ('all', 'exclude')), \n",
    "                    ('CenterOfGravity_x_norm_cm', ('CenterOfGravity', 'x_norm_cm')),\n",
    "                    ('CenterOfGravity_y_norm_cm', ('CenterOfGravity', 'y_norm_cm')),                    \n",
    "                    ('CenterOfGravity_rolling_speed_px_per_s', ('CenterOfGravity', 'rolling_speed_px_per_s'))]\n",
    "        if dict_selected_functions[\"Anxiety\"]:              \n",
    "            d_data_anx = { 'count_freezing_bouts': [],\n",
    "                       'mean_freezing_bout_duration': [],\n",
    "                       'percentage_of_time_spent_freezing': [],\n",
    "                       'mean_freezing_bouts_y_position': [],\n",
    "                       'median_freezing_bouts_y_position': [],\n",
    "                       'wall_endzone_mean_freezing_bouts_y_position': [], \n",
    "                       'wall_endzone_median_freezing_bouts_y_position': [], \n",
    "                       'wall_endzone_stddev_freezing_bouts_y_position': [], \n",
    "                       'wall_endzone_count_freezing_bouts': [],}\n",
    "            self.d_data = self.d_data | d_data_anx\n",
    "            self.col_in_master_df.extend([('freezing', ('Freezing_bout', '')),\n",
    "                    ('freezing_bout_count', ('Freezing_bout', 'count')),\n",
    "                    ('freezing_bout_duration', ('Freezing_bout', 'duration')),\n",
    "                    ('freezing_bout_mean_x_norm_cm', ('Freezing_bout', 'mean_x_norm_cm')),\n",
    "                    ('freezing_bout_mean_y_norm_cm', ('Freezing_bout', 'mean_y_norm_cm')),\n",
    "                    ('Percentage_time_spent_freezing_session', ('whole_session', 'percentage_time_spent_freezing')),\n",
    "                    ('Median_freezing_bout_duration_session', ('whole_session', 'median_freezing_bout_duration')),\n",
    "                    ('Median_x_norm_cm_all_freezing_bouts_session', ('whole_session', 'median_x_norm_cm_all_freezing_bouts')),\n",
    "                    ('Median_y_norm_cm_all_freezing_bouts_session', ('whole_session', 'median_y_norm_cm_all_freezing_bouts'))])\n",
    "                      \n",
    "        if dict_selected_functions[\"Parkinson\"]:\n",
    "            d_data_pd =  {'count_gait_disruption_bouts_all': [],\n",
    "                       #'count_gait_disruption_bouts_in': [],\n",
    "                       #'count_gait_disruption_bouts_out': [],\n",
    "                       'mean_gait_disruption_bout_duration_all': [], \n",
    "                       #'mean_gait_disruption_bout_duration_in': [], \n",
    "                       #'mean_gait_disruption_bout_duration_out': [],\n",
    "                       'percentage_of_time_spent_gait_disrupted_all': [],\n",
    "                       'mean_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'mean_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'mean_gait_disruption_bouts_y_position_out': [], \n",
    "                       'median_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'median_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'median_gait_disruption_bouts_y_position_out': [], \n",
    "                       'wall_endzone_mean_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'wall_endzone_mean_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'wall_endzone_mean_gait_disruption_bouts_y_position_out': [],\n",
    "                       'wall_endzone_median_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'wall_endzone_median_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'wall_endzone_median_gait_disruption_bouts_y_position_out': [],\n",
    "                       'wall_endzone_stddev_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'wall_endzone_stddev_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'wall_endzone_stddev_gait_disruption_bouts_y_position_out': [],\n",
    "                       'wall_endzone_count_gait_disruption_bouts_all': [],\n",
    "                       #'wall_endzone_count_gait_disruption_bouts_in': [],\n",
    "                       #'wall_endzone_count_gait_disruption_bouts_out': [], \n",
    "                         }\n",
    "            self.d_data = self.d_data | d_data_pd\n",
    "            self.col_in_master_df.extend([('gaitdisruption', ('GaitDisruption_bout', '')),\n",
    "                    ('gaitdisruption_bout_count', ('GaitDisruption_bout', 'count')),\n",
    "                    ('gaitdisruption_bout_duration', ('GaitDisruption_bout', 'duration')),\n",
    "                    ('gaitdisruption_bout_mean_x_norm_cm', ('GaitDisruption_bout', 'mean_x_norm_cm')),\n",
    "                    ('gaitdisruption_bout_mean_y_norm_cm', ('GaitDisruption_bout', 'mean_y_norm_cm')),\n",
    "                    ('gaitdisruption_bout_direction_bool', ('GaitDisruption_bout', 'direction_bool')),\n",
    "                    ('gaitdisruption_bout_direction_mean', ('GaitDisruption_bout', 'direction_mean')),\n",
    "                    ('Percentage_time_spent_gaitdisrupted_session', ('whole_session', 'percentage_time_spent_gait_disrupted')),\n",
    "                    ('Median_gaitdisruption_bout_duration_session', ('whole_session', 'median_gait_disruption_bout_duration')),\n",
    "                    ('Median_x_norm_cm_all_gaitdisruption_bouts_session', ('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')),\n",
    "                    ('Median_y_norm_cm_all_gaitdisruption_bouts_session', ('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts'))])\n",
    "        \n",
    "        if dict_selected_functions[\"Catwalk\"]:\n",
    "            d_data_cat = {'mean_angle_secondfinger_hindpawright_hindkneeright' : [], \n",
    "                      'mean_angle_secondfinger_hindpawleft_hindkneeleft' : [], \n",
    "                      'mean_angle_hindpawright_hindkneeright_CoG': [], \n",
    "                      'mean_angle_hindpawleft_hindkneeleft_CoG': [], \n",
    "                      'mean_distance_hindpawrightsecondfinger_hindpawright': [], \n",
    "                      'mean_distance_hindpawleftsecondfinger_hindpawleft': [],\n",
    "                      'mean_area_hindpawright': [], \n",
    "                      'mean_area_hindpawleft': [], } \n",
    "            self.d_data = self.d_data | d_data_cat\n",
    "            self.col_in_master_df.extend([(\"mean_angle_secondfinger_hindpawright_hindkneeright\"), \n",
    "                                          (\"mean_angle_secondfinger_hindpawleft_hindkneeleft\"),\n",
    "                                          (\"mean_angle_hindpawright_hindkneeright_CoG\"),\n",
    "                                          (\"mean_angle_hindpawleft_hindkneeleft_CoG\"),\n",
    "                                          (\"mean_distance_hindpawrightsecondfinger_hindpawright\"),\n",
    "                                          (\"mean_distance_hindpawleftsecondfinger_hindpawleft\"),\n",
    "                                          (\"mean_area_hindpawright\"),\n",
    "                                          (\"mean_area_hindpawleft\")])\n",
    "            \n",
    "            \n",
    "    def append_session_to_d_data(self, subject, session, dict_selected_functions): \n",
    "            wall_end_position = 35 #in cm\n",
    "            \n",
    "            self.d_data['subject_ID'].append(session.subject_ID)\n",
    "            self.d_data['group_ID'].append(subject.group_ID)\n",
    "            self.d_data['paradigm'].append(session.paradigm)\n",
    "            self.d_data['trialnumber'].append(subject.trialnumber)\n",
    "            \n",
    "            if dict_selected_functions[\"Anxiety\"]: \n",
    "                self.d_data['count_freezing_bouts'].append(self.get_total_bount_count(session.master_df['freezing_bout_count'].unique()))\n",
    "                self.d_data['mean_freezing_bout_duration'].append(session.master_df['freezing_bout_duration'].mean())\n",
    "                self.d_data['percentage_of_time_spent_freezing'].append(session.master_df['Percentage_time_spent_freezing_session'].unique()[0])\n",
    "                self.d_data['mean_freezing_bouts_y_position'].append(session.master_df['freezing_bout_mean_y_norm_cm'].mean())\n",
    "                self.d_data['median_freezing_bouts_y_position'].append(session.master_df['freezing_bout_mean_y_norm_cm'].median())\n",
    "                \n",
    "                mean_pos_freezing, median_pos_freezing, std_dev_freezing, bout_count_freezing = self.get_fuzziness(session.master_df, wall_end_position, 10)\n",
    "                \n",
    "                self.d_data['wall_endzone_mean_freezing_bouts_y_position'].append(mean_pos_freezing)\n",
    "                self.d_data['wall_endzone_median_freezing_bouts_y_position'].append(median_pos_freezing)\n",
    "                self.d_data['wall_endzone_stddev_freezing_bouts_y_position'].append(std_dev_freezing)\n",
    "                self.d_data['wall_endzone_count_freezing_bouts'].append(bout_count_freezing)\n",
    "            \n",
    "            if dict_selected_functions[\"Parkinson\"]: \n",
    "                self.d_data['count_gait_disruption_bouts_all'].append(self.get_total_bount_count(session.master_df['gaitdisruption_bout_count'].unique()))\n",
    "                #self.d_data['count_gait_disruption_bouts_in'].append(self.get_total_bount_count(df_temp_in['gaitdisruption_bout_count'].unique()))\n",
    "                #self.d_data['count_gait_disruption_bouts_out'].append(self.get_total_bount_count(df_temp_out['gaitdisruption_bout_count'].unique()))\n",
    "\n",
    "\n",
    "                self.d_data['mean_gait_disruption_bout_duration_all'].append(session.master_df['gaitdisruption_bout_duration'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bout_duration_in'].append(df_temp_in['gaitdisruption_bout_duration'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bout_duration_out'].append(df_temp_out['gaitdisruption_bout_duration'].mean())\n",
    "\n",
    "\n",
    "                self.d_data['percentage_of_time_spent_gait_disrupted_all'].append(session.master_df['Percentage_time_spent_gaitdisrupted_session'].unique()[0])\n",
    "\n",
    "\n",
    "                self.d_data['mean_gait_disruption_bouts_y_position_all'].append(session.master_df['gaitdisruption_bout_mean_y_norm_cm'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bouts_y_position_in'].append(df_temp_in['gaitdisruption_bout_mean_y_norm_cm'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bouts_y_position_out'].append(df_temp_out['gaitdisruption_bout_mean_y_norm_cm'].mean())\n",
    "\n",
    "\n",
    "                self.d_data['median_gait_disruption_bouts_y_position_all'].append(session.master_df['gaitdisruption_bout_mean_y_norm_cm'].median())\n",
    "                #self.d_data['median_gait_disruption_bouts_y_position_in'].append(df_temp_in['gaitdisruption_bout_mean_y_norm_cm'].median())\n",
    "                #self.d_data['median_gait_disruption_bouts_y_position_out'].append(df_temp_out['gaitdisruption_bout_mean_y_norm_cm'].median())\n",
    "\n",
    "\n",
    "                mean_pos_gait_all, median_pos_gait_all, std_dev_gait_all, bout_count_gait_all = self.get_fuzziness(session.master_df, wall_end_position, 10)\n",
    "                #mean_pos_gait_in, median_pos_gait_in, std_dev_gait_in, bout_count_gait_in = self.get_fuzziness(df_temp_in, wall_end_position, 10)\n",
    "                #mean_pos_gait_out, median_pos_gait_out, std_dev_gait_out, bout_count_gait_out = self.get_fuzziness(df_temp_out, wall_end_position, 10)\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_mean_gait_disruption_bouts_y_position_all'].append(mean_pos_gait_all)\n",
    "                #self.d_data['wall_endzone_mean_gait_disruption_bouts_y_position_in'].append(mean_pos_gait_in)\n",
    "                #self.d_data['wall_endzone_mean_gait_disruption_bouts_y_position_out'].append(mean_pos_gait_out)\n",
    "\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_median_gait_disruption_bouts_y_position_all'].append(median_pos_gait_all)\n",
    "                #self.d_data['wall_endzone_median_gait_disruption_bouts_y_position_in'].append(median_pos_gait_in)\n",
    "                #self.d_data['wall_endzone_median_gait_disruption_bouts_y_position_out'].append(median_pos_gait_out)\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_stddev_gait_disruption_bouts_y_position_all'].append(std_dev_gait_all)\n",
    "                #self.d_data['wall_endzone_stddev_gait_disruption_bouts_y_position_in'].append(std_dev_gait_in)\n",
    "                #self.d_data['wall_endzone_stddev_gait_disruption_bouts_y_position_out'].append(std_dev_gait_out)\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_count_gait_disruption_bouts_all'].append(bout_count_gait_all)\n",
    "                #self.d_data['wall_endzone_count_gait_disruption_bouts_in'].append(bout_count_gait_in)\n",
    "                #self.d_data['wall_endzone_count_gait_disruption_bouts_out'].append(bout_count_gait_out)\n",
    "            \n",
    "            if dict_selected_functions[\"Catwalk\"]:\n",
    "                self.d_data['mean_angle_secondfinger_hindpawright_hindkneeright'].append(session.master_df['angle_hindpawright_hindkneeright_CoG'].mean())\n",
    "                self.d_data['mean_angle_secondfinger_hindpawleftt_hindkneeleft'].append(session.master_df['angle_hindpawleft_hindkneeleft_CoG'].mean())\n",
    "                self.d_data['mean_angle_hindpawright_hindkneeright_CoG'].append(session.master_df['angle_secondfinger_hindpawright_hindkneeright'].mean())\n",
    "                self.d_data['mean_angle_hindpawleft_hindkneeleft_CoG'].append(session.master_df['angle_secondfinger_hindpawleft_hindkneeleft'].mean())\n",
    "                self.d_data['mean_distance_hindpawrightsecondfinger_hindpawright'].append(session.master_df['distance_secondfinger_hindpawright'].mean())\n",
    "                self.d_data['mean_distance_hindpawleftsecondfinger_hindpawleft'].append(session.master_df['distance_secondfinger_hindpawleft'].mean())\n",
    "                self.d_data['mean_area_hindpawright'].append(session.master_df['area_HindPawRight'].mean())\n",
    "                self.d_data['mean_area_hindpawleft'].append(session.master_df['area_HindPawLeft'].mean())\n",
    "                \n",
    "            self.dataframe = pd.DataFrame(data = self.d_data)   \n",
    "            \n",
    "    def get_total_bount_count(uniques):\n",
    "        uniques = uniques[~np.isnan(uniques)]\n",
    "        return uniques.shape[0]\n",
    "\n",
    "    #was ist half_window_size, ist es fix auf 10?\n",
    "    def get_fuzziness(df_tmp, wall_end_position, half_window_size):\n",
    "        mean_pos = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                              (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].mean()\n",
    "\n",
    "        median_pos = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                                (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].median()\n",
    "\n",
    "        std_dev = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                             (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].std()\n",
    "\n",
    "        bout_count = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                                (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].shape[0]\n",
    "\n",
    "        if bout_count < 3:\n",
    "            mean_pos = np.NaN\n",
    "            std_dev = np.NaN    \n",
    "    \n",
    "        return mean_pos, median_pos, std_dev, bout_count\n",
    "        \n",
    "        \n",
    "    def calculate_stats(self, output_path, l_selected_data_col_dict):\n",
    "        for dict_stats in l_selected_data_col_dict:\n",
    "            stats.total_count_stats(self, dict_stats[\"data_col\"], dict_stats[\"independent_variable\"], dict_stats[\"hue\"], output_path)\n",
    "            if \"y_position\" in dict_stats[\"data_col\"]:\n",
    "                stats.position_stats(self, dict_stats[\"data_col\"], dict_stats[\"independent_variable\"], dict_stats[\"hue\"], output_path)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5350d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class subject(main):\n",
    "    def __init__(self, subject_ID):\n",
    "        self.subject_ID = subject_ID\n",
    "        self.l_sessions = [session for session in main.l_sessions if session.subject_ID == self.subject_ID]\n",
    "        #if len(self.l_sessions) > 1:\n",
    "            #self.l_paradigms = [session.paradigm for session in self.l_sessions]\n",
    "        self.dict_date_paradigm = {session.date:session.paradigm for session in self.l_sessions}\n",
    "        self.trialnumber = 1 #muss noch implementiert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c17da831",
   "metadata": {},
   "outputs": [],
   "source": [
    "class session(subject):\n",
    "    def __init__(self, session_ID):\n",
    "        self.session_ID = session_ID\n",
    "        if 'OTE' in self.session_ID:\n",
    "            self.paradigm = 'exponential'\n",
    "        elif 'OTT'  in self.session_ID:\n",
    "            self.paradigm  = 'triangle'\n",
    "        elif 'OTR'  in self.session_ID:\n",
    "            self.paradigm = 'rectangle'\n",
    "        self.subject_ID_date = self.session_ID[0:-4] \n",
    "        #falls andere Paradigmen eingebaut werden, die nicht drei spaces in der Benennung haben, muss das geändert werden\n",
    "        #generisch: self.session_ID[self.session_ID.index('')+1:self.session_ID.index('')]\n",
    "        self.date = datetime.strptime(self.subject_ID_date[-6:], '%y%m%d')\n",
    "        self.subject_ID = self.subject_ID_date[0:-7]\n",
    "        bc_csv = self.session_ID in set([elem[0:-11] for elem in os.listdir(main.path) if elem.endswith('_bottom.csv')])\n",
    "        bc_mp4 = self.session_ID in set([elem[0:-11] for elem in os.listdir(main.path) if elem.endswith('_bottom.mp4')]) \n",
    "        tc_csv = self.session_ID in set([elem[0:-8] for elem in os.listdir(main.path) if elem.endswith('_top.csv')])\n",
    "        tc_mp4 = self.session_ID in set([elem[0:-8] for elem in os.listdir(main.path) if elem.endswith('_top.mp4') or elem.endswith('_top.avi')])\n",
    "        sc_csv = self.session_ID in set([elem[0:-9] for elem in os.listdir(main.path) if elem.endswith('_side.csv')])\n",
    "        sc_mp4 = self.session_ID in set([elem[0:-9] for elem in os.listdir(main.path) if elem.endswith('_side.mp4')])\n",
    "        \n",
    "        main.all_files_there = True\n",
    "        missing_files_statement = \"\\nPlease name your files like as the following: 210_F1-83_220518_OTT_bottom.mp4 \\nLine_ID_Date_Paradigm_Camera_ending\"\n",
    "        if main.dict_cams_used[\"bottom_cam\"]:\n",
    "            if bc_csv == False:\n",
    "                print(\"Missing _bottom.csv file for session {} in {}!\".format(self.session_ID, main.path), missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            elif bc_mp4 == False:\n",
    "                print(\"Missing _bottom.mp4 file for session {} in {}!\".format(self.session_ID, main.path), missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            else:\n",
    "                bc_video_filename = session_ID + \"_bottom.mp4\"\n",
    "                bc_csv_filename = session_ID + \"_bottom.csv\"\n",
    "                bc_df = pd.read_csv(main.path + bc_csv_filename, skiprows=1, index_col=0, header=[0, 1])\n",
    "                self.bc = bottom_cam(self.session_ID, bc_df)\n",
    "\n",
    "        if main.dict_cams_used[\"top_cam\"]:\n",
    "            if tc_csv ==False:\n",
    "                print(\"Missing _top.csv file for session {} in {}!\".format(self.session_ID, main.path), missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            elif tc_mp4 == False:\n",
    "                print(\"Missing top.mp4 file for session {} in {}!\".format(self.session_ID, main.path), missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            else:  \n",
    "                tc_video_filename = session_ID + \"_top.mp4\"\n",
    "                tc_csv_filename = session_ID + \"_top.csv\"\n",
    "                tc_df = pd.read_csv(main.path + tc_csv_filename, skiprows=1, index_col=0, header=[0, 1])\n",
    "                self.tc = top_cam(self.session_ID, tc_df)\n",
    "            \n",
    "        if main.dict_cams_used[\"side_cam\"]:\n",
    "            if sc_csv == False:\n",
    "                print(\"Missing _side.csv file for session {} in {}!\".format(self.session_ID, main.path), missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            elif sc_mp4 == False:\n",
    "                print(\"Missing side.mp4 file for session {} in {}!\".format(self.session_ID, main.path),missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            else:\n",
    "                sc_video_filename = session_ID + \"_side.mp4\"\n",
    "                sc_csv_filename = session_ID + \"_side.csv\"\n",
    "                sc_df = pd.read_csv(main.path + sc_csv_filename, skiprows=1, index_col=0, header=[0, 1])\n",
    "                #create side_cam object\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "620c7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottom_cam(session):\n",
    "    def __init__(self, session_ID, df):\n",
    "        self.session_ID = session_ID\n",
    "        self.df = df\n",
    "        path_avi = main.path + session_ID + \"_bottom.AVI\"\n",
    "        path_mp4 = main.path + session_ID + \"_bottom.mp4\"\n",
    "        if os.path.exists(path_avi):\n",
    "            self.mc = maze_corners(path_avi)\n",
    "        elif os.path.exists(path_mp4):\n",
    "            self.mc = maze_corners(path_mp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13d7d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class top_cam:\n",
    "    def __init__(self, session_ID, df):\n",
    "        self.session_ID = session_ID\n",
    "        self.df = df\n",
    "        path_avi = main.path + session_ID + \"_top.AVI\"\n",
    "        path_mp4 = main.path + session_ID + \"_top.mp4\"\n",
    "        if os.path.exists(path_avi):\n",
    "            self.mc = maze_corners(path_avi)\n",
    "        elif os.path.exists(path_mp4):\n",
    "            self.mc = maze_corners(path_mp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168e62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class side_cam:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        #stitch()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5456523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class clean_df(session): #get_time, identify duplicates, exclude_frames, rotate, translate, normalize\n",
    "    def __init__(self, df, results, threshold, cam):\n",
    "        #side cams geben keine results weil sie kein mazecorner objekt haben\n",
    "        self.threshold = threshold\n",
    "        self.framerate = main.framerate[cam]\n",
    "        self.results = results\n",
    "        self.l_bodyparts = [elem[0] for elem in df.columns[::3]]\n",
    "        main.dict_bodyparts[cam] = self.l_bodyparts\n",
    "        df = self.get_time(df)\n",
    "        df = self.identify_duplicates(df)\n",
    "        df[('all', 'exclude')] = False\n",
    "        df = self.exclude_frames(df)\n",
    "        if \"CenterOfGravity\" not in self.l_bodyparts:\n",
    "            df = self.get_center_of_gravity(df)\n",
    "        df = self.normalize_coordinates(df)\n",
    "        self.df = df\n",
    "        \n",
    "    def get_time(self, df):\n",
    "        df['time'] = np.NaN\n",
    "        df['time'] = df['EarRight'].index/self.framerate\n",
    "\n",
    "        return df\n",
    "        # in future version: check for NaN\n",
    "        \n",
    "    def identify_duplicates(self, df):\n",
    "        l_indices = list(df.index)\n",
    "        l_unique_indices = list(set(l_indices))\n",
    "\n",
    "        if len(l_indices) != len(l_unique_indices):\n",
    "            l_duplicates = []\n",
    "            for index in l_unique_indices:\n",
    "                if l_indices.count(index) > 1:\n",
    "                    l_duplicates.append(index)\n",
    "            df.loc[l_duplicates, ('all', 'exclude')] = True\n",
    "\n",
    "        return df\n",
    "\n",
    "    def exclude_frames(self, df):\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            df.loc[:, (bodypart, 'exclude')] = False\n",
    "            df.loc[df[bodypart]['likelihood'] < self.threshold, (bodypart, 'exclude')] = True\n",
    "            df.loc[df[('all', 'exclude')] == True, (bodypart, 'exclude')] = True\n",
    "        return df\n",
    "    \n",
    "    def rotate(self, xy, theta):\n",
    "        cos_theta, sin_theta = math.cos(theta), math.sin(theta)\n",
    "\n",
    "        return (\n",
    "            xy[0] * cos_theta - xy[1] * sin_theta,\n",
    "            xy[0] * sin_theta + xy[1] * cos_theta\n",
    "        )\n",
    "\n",
    "    def translate(self, xy, offset):\n",
    "        return xy[0] + offset[0], xy[1] + offset[1]\n",
    "\n",
    "\n",
    "    def normalize_coordinates(self, df):\n",
    "        length = self.results['length']\n",
    "        width = self.results['width']\n",
    "        offset_to_standard = (-self.results['offset_x'], -self.results['offset_y'])\n",
    "        offset_from_standard = (self.results['offset_x'], self.results['offset_y'])\n",
    "        theta_to_standard = -self.results['theta']\n",
    "\n",
    "\n",
    "        length_in_px = length\n",
    "        cm_per_px = main.maze_length_in_cm/length_in_px\n",
    "\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            df[(bodypart, 'x_norm')] = self.translate(self.rotate((df[(bodypart,'x')], df[(bodypart,'y')]), theta_to_standard), offset_to_standard)[0]\n",
    "            df[(bodypart, 'y_norm')] = self.translate(self.rotate((df[(bodypart,'x')], df[(bodypart,'y')]), theta_to_standard), offset_to_standard)[1]\n",
    "            df[(bodypart, 'x_norm_cm')] = 3 - (df[(bodypart, 'x_norm')] * cm_per_px)\n",
    "            df[(bodypart, 'y_norm_cm')] = 50 - (df[(bodypart, 'y_norm')] * cm_per_px)\n",
    "\n",
    "        return df    \n",
    "\n",
    "    \n",
    "    def get_center_of_gravity(self, df):\n",
    "        df.loc[(df[('all', 'exclude')] == False) & (df[('EarRight', 'exclude')] == False) & (df[('EarLeft', 'exclude')] == False) & (df[('TailBase', 'exclude')] == False), \n",
    "           ('CenterOfGravity', 'x')] = (df.loc[df[('all', 'exclude')] == False, ('EarRight', 'x')] + \n",
    "                                          df.loc[df[('all', 'exclude')] == False, ('EarLeft', 'x')] + \n",
    "                                          df.loc[df[('all', 'exclude')] == False, ('TailBase', 'x')]) / 3\n",
    "\n",
    "        df.loc[(df[('all', 'exclude')] == False) & (df[('EarRight', 'exclude')] == False) & (df[('EarLeft', 'exclude')] == False) & (df[('TailBase', 'exclude')] == False), \n",
    "           ('CenterOfGravity', 'y')] = (df.loc[df[('all', 'exclude')] == False, ('EarRight', 'y')] + \n",
    "                                          df.loc[df[('all', 'exclude')] == False, ('EarLeft', 'y')] + \n",
    "                                          df.loc[df[('all', 'exclude')] == False, ('TailBase', 'y')]) / 3\n",
    "\n",
    "        df[('CenterOfGravity', 'exclude')] = False\n",
    "        df.loc[(df[('CenterOfGravity', 'x')].isnull()) | (df[('CenterOfGravity', 'y')].isnull()), ('CenterOfGravity', 'exclude')] = True\n",
    "\n",
    "        self.l_bodyparts.append('CenterOfGravity')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e568dea",
   "metadata": {},
   "source": [
    "Zwischenstände Code bzw. Maze Corner Annotation speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4374cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class df_functions(bottom_cam, top_cam, side_cam):\n",
    "    immobility_threshold = 16\n",
    "\n",
    "    min_freezing_duration = 1\n",
    "\n",
    "    TIME_OF_GAIT_BEFORE_DISRUPT = 0.5\n",
    "    TARGET_TIME_GAIT_DISRUPTION = 0.2\n",
    "    \n",
    "    def __init__(self, subject, session, dict_selected_functions):\n",
    "        self.session = session\n",
    "        self.subject = subject\n",
    "        self.dict_selected_functions = dict_selected_functions\n",
    "        self.l_dfs = []\n",
    "        if main.dict_cams_used[\"bottom_cam\"]:\n",
    "            df = session.bc.processed_df\n",
    "            self.l_bodyparts = main.dict_bodyparts[\"bottom_cam\"]\n",
    "            self.framerate = main.framerate[\"bottom_cam\"]\n",
    "            \n",
    "            df = self.get_speed_and_rolling_speed(df)\n",
    "            df = self.get_immobility(df)\n",
    "            if dict_selected_functions[\"Anxiety\"]:\n",
    "                df = self.get_freezing_bouts(df)\n",
    "                df = self.get_freezing_avg(df)\n",
    "            if dict_selected_functions[\"Parkinson\"]:\n",
    "                df = self.get_direction_bc(df)\n",
    "                df = self.get_gait_disruption_bouts(df)\n",
    "                df = self.get_gait_disruption_avg(df)\n",
    "            if dict_selected_functions[\"Catwalk\"]:\n",
    "                df = self.get_bodypart_angles(df)\n",
    "                df = self.get_distance_secondfinger_pawbase(df)\n",
    "                df = self.get_paw_area(df)\n",
    "            self.l_dfs.append(df)\n",
    "            \n",
    "        if main.dict_cams_used[\"top_cam\"]:\n",
    "            self.l_bodyparts = main.dict_bodyparts[\"top_cam\"]\n",
    "            df = session.tc.processed_df\n",
    "            self.framerate = main.framerate[\"top_cam\"]\n",
    "            df = self.get_speed_and_rolling_speed(df)\n",
    "            df = self.get_immobility(df)\n",
    "            if dict_selected_functions[\"Anxiety\"]:\n",
    "                df = self.get_freezing_bouts(df)\n",
    "                df = self.get_freezing_avg(df)\n",
    "            if dict_selected_functions[\"Parkinson\"]:\n",
    "                df = self.get_direction_bc(df)\n",
    "                df = self.get_gait_disruption_bouts(df)\n",
    "                df = self.get_gait_disruption_avg(df)\n",
    "            self.l_dfs.append(df)\n",
    "            \n",
    "            \n",
    "        if main.dict_cams_used[\"side_cam\"]:\n",
    "            self.l_bodyparts = main.dict_bodyparts[\"side_cam\"]\n",
    "            self.framerate = main.framerate[\"side_cam\"]\n",
    "            \n",
    "            self.l_dfs.append(df)\n",
    "        \n",
    "        self.combined_df = self.combine_cam_dfs()\n",
    "        self.combined_df = self.add_metadata(self.combined_df)\n",
    "        self.master_df = self.get_master_df()\n",
    "                \n",
    "    \n",
    "    def get_speed_and_rolling_speed(self, df):\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            df[(bodypart, 'speed_px_per_s')] = np.NaN\n",
    "            df[(bodypart, 'rolling_speed_px_per_s')] = np.NaN\n",
    "\n",
    "            # Limitation: since we have to exclude some frames, these calculations are not made frame by frame (yet for most)\n",
    "            df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'speed_px_per_s')] = (((df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'x')].diff()**2                                                                                                        + df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'y')].diff()**2)**(1/2)) \n",
    "                                                                                                                             / df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), 'time'].diff())\n",
    "            df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'rolling_speed_px_per_s')] = df.loc[df[('all', 'exclude')] == False, (bodypart, 'speed_px_per_s')].rolling(5, min_periods=3, center=True).mean()\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def get_direction_bc(self, df): #used Snout instead of EarLeft & EarRight (less secure parameter?, but better suitable for BottomCam?)\n",
    "            #could also synchronize with top Cam data and use direction from there\n",
    "        df[('moving_towards_maze_end', '')] = False\n",
    "        df.loc[(df[('Snout', 'y_norm')] < df[('TailBase', 'y_norm')]), ('moving_towards_maze_end', '')] = True\n",
    "        #df.loc[(df[('Snout', 'y_norm')] < df[('CenterOfGravity', 'y_norm')]), ('moving_towards_maze_end', '')] = True\n",
    "        return df\n",
    "    \n",
    "    def get_dircetion_tc(self, df):\n",
    "        pass\n",
    "    \n",
    "    def get_direction_sc(self, df):\n",
    "        pass\n",
    "    \n",
    "    def get_immobility(self, df):\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            # create 'immobility' column and set base value to false\n",
    "            df.loc[ :, (bodypart, 'immobility')] = False\n",
    "            df.loc[df[(bodypart,'rolling_speed_px_per_s')] < self.immobility_threshold, (bodypart, 'immobility')] = True\n",
    "        return df\n",
    "        \n",
    "    def get_gait_disruption_bouts(self, df):\n",
    "        df[('GaitDisruption_bout', '')] = False\n",
    "        df[('GaitDisruption_bout', 'count')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'duration')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'mean_x_norm_cm')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'mean_y_norm_cm')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'direction_bool')] = ''\n",
    "        df[('GaitDisruption_bout', 'direction_mean')] = np.NaN\n",
    "\n",
    "        if self.dict_selected_functions[\"Anxiety\"] == False:\n",
    "            df['all_freezing_bodyparts_immobile'] = df[[('EarRight', 'immobility'), ('EarLeft', 'immobility'), ('CenterOfGravity', 'immobility')]].all(axis=1)\n",
    "        \n",
    "        l_timesteps = []\n",
    "        for i in range(self.framerate):\n",
    "            l_timesteps.append(i/self.framerate)\n",
    "\n",
    "        time_gait_disruption = self.find_nearest(np.asarray(l_timesteps), self.TARGET_TIME_GAIT_DISRUPTION)\n",
    "        frames_difference = l_timesteps.index(time_gait_disruption)\n",
    "\n",
    "        gait_disruption_threshold_reached = df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].iloc[np.where(np.round(df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].diff(frames_difference).values, 7) == round(time_gait_disruption, 7))[0]].values\n",
    "\n",
    "        # could still throw an error if only a single frame, because of slicing to find first and last index of each interval?    \n",
    "        if gait_disruption_threshold_reached.shape[0] > 0:\n",
    "            indices = np.asarray(df.loc[df['time'].isin(gait_disruption_threshold_reached)].index)\n",
    "            lower_end = (indices+1)[:-1]\n",
    "            upper_end = indices[1:]\n",
    "            mask = lower_end < upper_end\n",
    "            mask_last = np.concatenate([mask, np.array([True])])\n",
    "            mask_first = np.concatenate([np.array([True]), mask])\n",
    "\n",
    "            last_value_of_intervals = indices[mask_last]\n",
    "            first_value_of_intervals = indices[mask_first]\n",
    "            \n",
    "            first_value_of_intervals = first_value_of_intervals-l_timesteps.index(self.find_nearest(np.asarray(l_timesteps), self.TARGET_TIME_GAIT_DISRUPTION))\n",
    "\n",
    "            interval_ranges = np.column_stack([first_value_of_intervals,last_value_of_intervals])\n",
    "\n",
    "            frames_prior_to_interval_start = l_timesteps.index(self.find_nearest(np.asarray(l_timesteps), self.TIME_OF_GAIT_BEFORE_DISRUPT))\n",
    "            bout_count = 0\n",
    "\n",
    "            if interval_ranges.shape[0] > 0:\n",
    "                for first_idx, last_idx in interval_ranges:\n",
    "                    start_idx_gait_check = first_idx - frames_prior_to_interval_start\n",
    "                    if df.loc[start_idx_gait_check:first_idx-1, 'all_freezing_bodyparts_immobile'].any() == False:\n",
    "                        bout_count = bout_count + 1\n",
    "                        bout_duration = (df.loc[last_idx, 'time'] - df.loc[first_idx, 'time'])[0]\n",
    "                        mean_pos_x_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'x_norm_cm')].mean()\n",
    "                        mean_pos_y_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'y_norm_cm')].mean()\n",
    "                        direction_bool = df.loc[first_idx:last_idx, ('moving_towards_maze_end', '')].all()\n",
    "                        direction_mean = df.loc[first_idx:last_idx, ('moving_towards_maze_end', '')].mean()\n",
    "\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', '')] = True\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'count')] = bout_count\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'duration')] = bout_duration\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'mean_x_norm_cm')] = mean_pos_x_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'mean_y_norm_cm')] = mean_pos_y_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'direction_bool')] = direction_bool\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'direction_mean')] = direction_mean\n",
    "\n",
    "        return df\n",
    "        \n",
    "    def find_nearest(self, array, value):\n",
    "        array = np.asarray(array)\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "        return array[idx]\n",
    "\n",
    "    # für verschiedene Cams anpassen?\n",
    "    def get_freezing_bouts(self, df):\n",
    "        df[('Freezing_bout', '')] = False\n",
    "        df[('Freezing_bout', 'count')] = np.NaN\n",
    "        df[('Freezing_bout', 'duration')] = np.NaN\n",
    "        df[('Freezing_bout', 'mean_x_norm_cm')] = np.NaN\n",
    "        df[('Freezing_bout', 'mean_y_norm_cm')] = np.NaN\n",
    "\n",
    "        df['all_freezing_bodyparts_immobile'] = df[[('EarRight', 'immobility'), ('EarLeft', 'immobility'), ('CenterOfGravity', 'immobility')]].all(axis=1)\n",
    "\n",
    "        times_where_freezing_threshold_was_reached = df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].iloc[np.where(df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].diff(self.framerate).values == 1)[0]].values\n",
    "\n",
    "        # could still throw an error if only a single frame, because of slicing to find first and last index of each interval?\n",
    "        if times_where_freezing_threshold_was_reached.shape[0] > 0:\n",
    "            indices = np.asarray(df.loc[df['time'].isin(times_where_freezing_threshold_was_reached)].index)\n",
    "            lower_end = (indices+1)[:-1]\n",
    "            upper_end = indices[1:]\n",
    "            mask = lower_end < upper_end\n",
    "            mask_last = np.concatenate([mask, np.array([True])])\n",
    "            mask_first = np.concatenate([np.array([True]), mask])\n",
    "\n",
    "            last_value_of_intervals = indices[mask_last]\n",
    "            first_value_of_intervals = indices[mask_first]\n",
    "\n",
    "            first_value_of_intervals = first_value_of_intervals-self.framerate\n",
    "\n",
    "            interval_ranges = np.column_stack([first_value_of_intervals,last_value_of_intervals])\n",
    "\n",
    "            bout_count = 0\n",
    "\n",
    "            if interval_ranges.shape[0] > 0:\n",
    "                for first_idx, last_idx in interval_ranges:\n",
    "                        bout_count = bout_count + 1\n",
    "                        bout_duration = (df.loc[last_idx, 'time'] - df.loc[first_idx, 'time'])[0]\n",
    "                        mean_pos_x_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'x_norm_cm')].mean()\n",
    "                        mean_pos_y_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'y_norm_cm')].mean()\n",
    "\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', '')] = True\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'count')] = bout_count\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'duration')] = bout_duration\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'mean_x_norm_cm')] = mean_pos_x_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'mean_y_norm_cm')] = mean_pos_y_norm_cm\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def get_freezing_avg(self, df):\n",
    "        freezing_bout_count = df[('Freezing_bout', 'count')].unique().shape[0] - 1\n",
    "\n",
    "        if freezing_bout_count > 0:\n",
    "            df[('whole_session', 'percentage_time_spent_freezing')] = (df.loc[df[('Freezing_bout', '')] == True].shape[0] / df.shape[0]) * 100\n",
    "            df[('whole_session', 'median_freezing_bout_duration')] = np.nanmedian(df[('Freezing_bout', 'duration')].unique())\n",
    "            df[('whole_session', 'median_x_norm_cm_all_freezing_bouts')] = np.nanmedian(df[('Freezing_bout', 'mean_x_norm_cm')].unique())\n",
    "            df[('whole_session', 'median_y_norm_cm_all_freezing_bouts')] = np.nanmedian(df[('Freezing_bout', 'mean_y_norm_cm')].unique())\n",
    "        else:\n",
    "            df[('whole_session', 'percentage_time_spent_freezing')] = 0\n",
    "            df[('whole_session', 'median_freezing_bout_duration')] = np.NaN\n",
    "            df[('whole_session', 'median_x_norm_cm_all_freezing_bouts')] = np.NaN\n",
    "            df[('whole_session', 'median_y_norm_cm_all_freezing_bouts')] = np.NaN       \n",
    "            \n",
    "        return df\n",
    "            \n",
    "    def get_gait_disruption_avg(self, df):\n",
    "        gait_disruption_bout_count = df[('GaitDisruption_bout', 'count')].unique().shape[0] - 1\n",
    "\n",
    "        if gait_disruption_bout_count > 0:\n",
    "            df[('whole_session', 'percentage_time_spent_gait_disrupted')] = (df.loc[df[('GaitDisruption_bout', '')] == True].shape[0] / df.shape[0]) * 100\n",
    "            df[('whole_session', 'median_gait_disruption_bout_duration')] = np.nanmedian(df[('GaitDisruption_bout', 'duration')].unique())\n",
    "            df[('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')] = np.nanmedian(df[('GaitDisruption_bout', 'mean_x_norm_cm')].unique())\n",
    "            df[('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts')] = np.nanmedian(df[('GaitDisruption_bout', 'mean_y_norm_cm')].unique())\n",
    "        else:\n",
    "            df[('whole_session', 'percentage_time_spent_gait_disrupted')] = 0\n",
    "            df[('whole_session', 'median_gait_disruption_bout_duration')] = np.NaN\n",
    "            df[('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')] = np.NaN\n",
    "            df[('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts')] = np.NaN\n",
    "\n",
    "        return df\n",
    "\n",
    "    def combine_cam_dfs(self):\n",
    "        if len(self.l_dfs) == 1:\n",
    "            combined_df = self.l_dfs[0]\n",
    "            return combined_df\n",
    "        else:\n",
    "            #crazy function to combine input of all cams using self.l_dfs\n",
    "            #or the bodypart class\n",
    "            #return combined_df \n",
    "            pass\n",
    "        \n",
    "    def add_metadata(self, df):\n",
    "        df['subject_ID'] = self.subject.subject_ID\n",
    "        df['group_ID'] = self.subject.group_ID\n",
    "        df['trialnumber'] = 1 #muss noch implementiert werden!\n",
    "        df['DateOfRecording'] = self.session.date\n",
    "        df['paradigm'] = self.session.paradigm\n",
    "        return df\n",
    "    \n",
    "    def get_master_df(self):\n",
    "        d_for_master_df = {}\n",
    "\n",
    "        for key, col_in_processed_df in main.col_in_master_df:\n",
    "            d_for_master_df[key] = self.combined_df[col_in_processed_df].values\n",
    "\n",
    "        master_df = pd.DataFrame(data=d_for_master_df)\n",
    "        return master_df\n",
    "    \n",
    "    \n",
    "    #Funktionen für Inken:\n",
    "\n",
    "    def get_bodypart_angles(self, df):\n",
    "        df['angle_secondfinger_hindpawright_hindkneeright'] = np.NaN\n",
    "        df['angle_secondfinger_hindpawleft_hindkneeleft'] = np.NaN\n",
    "        df['angle_hindpawright_hindkneeright_CoG'] = np.NaN\n",
    "        df['angle_hindpawleft_hindkneeleft_CoG'] = np.NaN\n",
    "        \n",
    "        #wieso df[all, exclude?] reicht es nicht nach den gewünschten bodyparts zu schauen?\n",
    "        \n",
    "        #HindPawRightSecondFinger\n",
    "        cy = df.loc[(df[('all', 'exclude')] == False) & (df[('HindKneeRight', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindPawRightSecondFinger', 'y_norm_cm')]\n",
    "        cx = df.loc[(df[('all', 'exclude')] == False) & (df[('HindKneeRight', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindPawRightSecondFinger', 'x_norm_cm')]\n",
    "        #HindPawRight\n",
    "        by = df.loc[(df[('all', 'exclude')] == False) & (df[('HindKneeRight', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindPawRight', 'y_norm_cm')]\n",
    "        bx = df.loc[(df[('all', 'exclude')] == False) & (df[('HindKneeRight', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindPawRight', 'x_norm_cm')]\n",
    "        #HindKneeRight\n",
    "        ay = df.loc[(df[('all', 'exclude')] == False) & (df[('HindKneeRight', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindKneeRight', 'y_norm_cm')]\n",
    "        ax = df.loc[(df[('all', 'exclude')] == False) & (df[('HindKneeRight', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindKneeRight', 'x_norm_cm')]\n",
    "        #angle_secondfinger_hindpawright_hindkneeright\n",
    "        df.loc[(df[('all', 'exclude')] == False) & (df[('HindKneeRight', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightSecondFinger', 'exclude')] == False), ('angle_secondfinger_hindpawright_hindkneeright')] = self.getAngle(ax, ay, bx, by, cx, cy)\n",
    "\n",
    "        #HindPawRight\n",
    "        cy = by\n",
    "        cx = bx\n",
    "        #HindKneeRight\n",
    "        by = ay\n",
    "        bx = ax\n",
    "        #CoG\n",
    "        ay = df.loc[(df[('all', 'exclude')] == False) & (df[('CenterOfGravity', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindKneeRight', 'exclude')] == False), ('CenterOfGravity', 'y_norm_cm')] \n",
    "        ax = df.loc[(df[('all', 'exclude')] == False) & (df[('CenterOfGravity', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindKneeRight', 'exclude')] == False), ('CenterOfGravity', 'x_norm_cm')] \n",
    "        #angle_hindpawright_hindkneeright_CoG      \n",
    "        df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('CenterOfGravity', 'exclude')] == False) & (df[('HindKneeRight', 'exclude')] == False), ('angle_hindpawright_hindkneeright_CoG')] = self.getAngle(ax, ay, bx, by, cx, cy)\n",
    "\n",
    "        #HindPawLeftSecondFinger\n",
    "        cy = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindKneeLeft', 'exclude')] == False) & (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindPawLeftSecondFinger', 'y_norm_cm')]\n",
    "        cx = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindKneeLeft', 'exclude')] == False)& (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindPawLeftSecondFinger', 'x_norm_cm')]\n",
    "        #HindPawLeft\n",
    "        by = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindKneeLeft', 'exclude')] == False)& (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindPawLeft', 'y_norm_cm')]\n",
    "        bx = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindKneeLeft', 'exclude')] == False)& (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindPawLeft', 'x_norm_cm')]\n",
    "        #HindKneeLeft\n",
    "        ay = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindKneeLeft', 'exclude')] == False)& (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindKneeLeft', 'y_norm_cm')]\n",
    "        ax = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindKneeLeft', 'exclude')] == False)& (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindKneeLeft', 'x_norm_cm')]\n",
    "        #angle_secondfinger_hindpawLeft_hindkneeLeft\n",
    "        df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindKneeLeft', 'exclude')] == False) & (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('angle_secondfinger_hindpawLeft_hindkneeLeft')] = self.getAngle(ax, ay, bx, by, cx, cy)\n",
    "        \n",
    "        #HindPawLeft\n",
    "        cy = by\n",
    "        cx = bx\n",
    "        #HindKneeLeft\n",
    "        by = ay\n",
    "        bx = ax\n",
    "        #CoG\n",
    "        ay = df.loc[(df[('all', 'exclude')] == False) & (df[('CenterOfGravity', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindKneeLeft', 'exclude')] == False), ('CenterOfGravity', 'y_norm_cm')] \n",
    "        ax = df.loc[(df[('all', 'exclude')] == False) & (df[('CenterOfGravity', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindKneeLeft', 'exclude')] == False), ('CenterOfGravity', 'x_norm_cm')] \n",
    "        #angle_hindpawLeft_hindkneeLeft_CoG      \n",
    "        df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('CenterOfGravity', 'exclude')] == False) & (df[('HindKneeLeft', 'exclude')] == False), ('angle_hindpawLeft_hindkneeLeft_CoG')] = self.getAngle(ax, ay, bx, by, cx, cy)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def getAngle(ax, ay, bx, by, cx, cy):\n",
    "        ang = math.degrees(math.atan2(cy-by, cx-bx) - math.atan2(ay-by, ax-bx))\n",
    "        return ang\n",
    "    \n",
    "    def get_distance_secondfinger_pawbase(self, df):\n",
    "        df['distance_secondfinger_hindpawright'] = np.NaN\n",
    "        df['distance_secondfinger_hindpawleft'] = np.NaN\n",
    "        \n",
    "        df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightSecondFinger', 'exclude')] == False), ('distance_secondfinger_hindpawright')] = math.sqrt((df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindPawRightSecondFinger', 'x_norm_cm')] - df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindPawRight', 'x_norm_cm')])**2 + (df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindPawRightSecondFinger', 'y_norm_cm')]- df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindPawRight', 'y_norm_cm')])**2)\n",
    "        df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('distance_secondfinger_hindpawleft')] = math.sqrt((df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindPawLeftSecondFinger', 'x_norm_cm')] - df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindPawLeft', 'x_norm_cm')])**2 + (df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindPawLeftSecondFinger', 'y_norm_cm')]- df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindPawLeft', 'y_norm_cm')])**2)\n",
    "        return df\n",
    "        \n",
    "    def get_paw_area(self, df):\n",
    "        df['area_HindPawRight'] = np.NaN\n",
    "        df['area_HindPawLeft'] = np.NaN\n",
    "        \n",
    "        #HindPawRightSecondFinger\n",
    "        cy = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightFourthFinger', 'exclude')] == False) & (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindPawRightSecondFinger', 'y_norm_cm')]\n",
    "        cx = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightFourthFinger', 'exclude')] == False)& (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindPawRightSecondFinger', 'x_norm_cm')]\n",
    "        #HindPawRight\n",
    "        by = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightFourthFinger', 'exclude')] == False)& (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindPawRight', 'y_norm_cm')]\n",
    "        bx = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightFourthFinger', 'exclude')] == False)& (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindPawRight', 'x_norm_cm')]\n",
    "        #HindPawRightFourthFinger\n",
    "        ay = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightFourthFinger', 'exclude')] == False)& (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindPawRightFourthFinger', 'y_norm_cm')]\n",
    "        ax = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightFourthFinger', 'exclude')] == False)& (df[('HindPawRightSecondFinger', 'exclude')] == False), ('HindPawRightFourthFinger', 'x_norm_cm')]\n",
    "        #area_secondfinger_hindpawright_fourthfinger\n",
    "        df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawRight', 'exclude')] == False) & (df[('HindPawRightFourthFinger', 'exclude')] == False) & (df[('HindPawRightSecondFinger', 'exclude')] == False), ('area_HindPawRight')] = self.triangle_area(ax, ay, bx, by, cx, cy)\n",
    "        \n",
    "        #HindPawLeftSecondFinger\n",
    "        cy = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindPawLeftFourthFinger', 'exclude')] == False) & (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindPawLeftSecondFinger', 'y_norm_cm')]\n",
    "        cx = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindPawLeftFourthFinger', 'exclude')] == False)& (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindPawLeftSecondFinger', 'x_norm_cm')]\n",
    "        #HindPawLeft\n",
    "        by = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindPawLeftFourthFinger', 'exclude')] == False)& (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindPawLeft', 'y_norm_cm')]\n",
    "        bx = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindPawLeftFourthFinger', 'exclude')] == False)& (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindPawLeft', 'x_norm_cm')]\n",
    "        #HindPawLeftFourthFinger\n",
    "        ay = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindPawLeftFourthFinger', 'exclude')] == False)& (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindPawLeftFourthFinger', 'y_norm_cm')]\n",
    "        ax = df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindPawLeftFourthFinger', 'exclude')] == False)& (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('HindPawLeftFourthFinger', 'x_norm_cm')]\n",
    "        #area_secondfinger_hindpawLeft_fourthfinger\n",
    "        df.loc[(df[('all', 'exclude')] == False) & (df[('HindPawLeft', 'exclude')] == False) & (df[('HindPawLeftFourthFinger', 'exclude')] == False) & (df[('HindPawLeftSecondFinger', 'exclude')] == False), ('area_HindPawLeft')] = self.triangle_area(ax, ay, bx, by, cx, cy)\n",
    "        \n",
    "        return df \n",
    "\n",
    "    \n",
    "    def triangle_area(ax, ay, bx, by, cx, cy):\n",
    "        area = abs(0.5 * (((x2-x1)*(y3-y1))-((x3-x1)*(y2-y1))))    \n",
    "        return area\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e4ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maze_corners(bottom_cam, top_cam):    \n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.cap = cv2.VideoCapture(self.filepath)\n",
    "        self.ret, self.frame = self.cap.read()\n",
    "        self.results = {}\n",
    "        \n",
    "        \n",
    "    def rotate(self, xy, theta):\n",
    "        cos_theta, sin_theta = math.cos(theta), math.sin(theta)\n",
    "\n",
    "        return (\n",
    "            xy[0] * cos_theta - xy[1] * sin_theta,\n",
    "            xy[0] * sin_theta + xy[1] * cos_theta\n",
    "        )\n",
    "\n",
    "    def translate(self, xy, offset):\n",
    "        return xy[0] + offset[0], xy[1] + offset[1]\n",
    "\n",
    "    def f(self, x, y, length, width, degrees):\n",
    "        offset = (x, y)\n",
    "        corners = [(0, 0), (width, 0), (width, length), (0, length)]\n",
    "        rotated_and_shifted_corners = [self.translate(self.rotate(xy, math.radians(degrees)), offset) for xy in corners]\n",
    "\n",
    "        end_right_corner = list(rotated_and_shifted_corners[0]) + ['red']\n",
    "        end_left_corner = list(rotated_and_shifted_corners[1]) + ['orange']\n",
    "        start_left_corner = list(rotated_and_shifted_corners[2]) + ['cyan']\n",
    "        start_right_corner = list(rotated_and_shifted_corners[3]) + ['green']\n",
    "\n",
    "        fig = plt.figure(figsize=(18, 10))\n",
    "        gs = fig.add_gridspec(2, 4)\n",
    "\n",
    "        fig.add_subplot(gs[0:2, 0:2])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.ylim(0,self.frame.shape[0])\n",
    "        plt.xlim(0,self.frame.shape[1])\n",
    "\n",
    "        if len(self.results.keys()) > 0:\n",
    "            saved_current = 'saved'\n",
    "        else:\n",
    "            saved_current = 'missing'\n",
    "\n",
    "        plt.title('current file: {} (analysis {})'.format(self.filepath, saved_current))\n",
    "\n",
    "        l_corners = [start_right_corner, start_left_corner, end_right_corner, end_left_corner]\n",
    "\n",
    "        for corner in l_corners:\n",
    "            plt.scatter(corner[0], corner[1], c=corner[2], s=100)\n",
    "\n",
    "        fig.add_subplot(gs[0, 2])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[0][0], l_corners[0][1], c=l_corners[0][2], s=100)\n",
    "        plt.xlim(l_corners[0][0]-25, l_corners[0][0]+25)\n",
    "        plt.ylim(l_corners[0][1]-25, l_corners[0][1]+25)\n",
    "        plt.title('start right corner')\n",
    "\n",
    "        fig.add_subplot(gs[0, 3])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[1][0], l_corners[1][1], c=l_corners[1][2], s=100)\n",
    "        plt.xlim(l_corners[1][0]-25, l_corners[1][0]+25)\n",
    "        plt.ylim(l_corners[1][1]-25, l_corners[1][1]+25)\n",
    "        plt.title('start left corner')\n",
    "\n",
    "        fig.add_subplot(gs[1, 2])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[2][0], l_corners[2][1], c=l_corners[2][2], s=100)\n",
    "        plt.xlim(l_corners[2][0]-25, l_corners[2][0]+25)\n",
    "        plt.ylim(l_corners[2][1]-25, l_corners[2][1]+25)\n",
    "        plt.title('end right corner')\n",
    "\n",
    "        fig.add_subplot(gs[1, 3])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[3][0], l_corners[3][1], c=l_corners[3][2], s=100)\n",
    "        plt.xlim(l_corners[3][0]-25, l_corners[3][0]+25)\n",
    "        plt.ylim(l_corners[3][1]-25, l_corners[3][1]+25)\n",
    "        plt.title('end left corner')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b694fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gui():\n",
    "    main_tab = widgets.Tab()    \n",
    "    \n",
    "    class main_gui(main):\n",
    "        def __init__(self):             \n",
    "            self.path = \"\"\n",
    "            folder_select = widgets.Button(description=\"Select folder\", layout=widgets.Layout(width=\"auto\"))\n",
    "            folder_select.on_click(self.select_folder)\n",
    "            \n",
    "            select_recording_modalities = widgets.Label(value=\"Select recording modalities\", layout=widgets.Layout(width=\"auto\"))\n",
    "            self.bottom_cam_check = widgets.Checkbox(value=False, description='Bottom Cam', layout=widgets.Layout(width=\"auto\"))\n",
    "            self.top_cam_check = widgets.Checkbox(value=False, description='Top Cam', layout=widgets.Layout(width=\"auto\"))\n",
    "            self.side_cam_check = widgets.Checkbox(value=False, description='Side Cam', disabled = True, layout=widgets.Layout(width=\"auto\"))\n",
    "            \n",
    "            confirm_button = widgets.Button(description = \"Confirm Settings\", layout=widgets.Layout(width=\"auto\"))\n",
    "            confirm_button.on_click(self.confirm_settings)\n",
    "            \n",
    "            col0 = VBox([folder_select])\n",
    "            col1 = VBox([select_recording_modalities, self.bottom_cam_check, self.top_cam_check, self.side_cam_check])\n",
    "            col2 = VBox([confirm_button])\n",
    "            box = HBox([col0, col1, col2])\n",
    "            gui.main_tab.children = [box]\n",
    "            gui.tab_index = 0\n",
    "            gui.main_tab.set_title(gui.tab_index, \"General Settings\")\n",
    "            display(gui.main_tab)\n",
    "            gui.main_tab.selected_index = gui.tab_index\n",
    "\n",
    "        def select_folder(self, b):\n",
    "            root = Tk()\n",
    "            root.withdraw()\n",
    "            root.call('wm', 'attributes', '.', '-topmost', True)\n",
    "            self.path = filedialog.askdirectory() + \"/\"\n",
    "            display(self.path)        \n",
    "            \n",
    "        def confirm_settings(self, b):\n",
    "            if self.path == \"\":\n",
    "                display(\"Set the path before continuing!\")\n",
    "            else:\n",
    "                main.dict_cams_used[\"bottom_cam\"] = self.bottom_cam_check.value\n",
    "                main.dict_cams_used[\"top_cam\"] = self.top_cam_check.value\n",
    "                main.dict_cams_used[\"side_cam\"] = self.side_cam_check.value\n",
    "                main.path = self.path\n",
    "                main.all_information_given(main)\n",
    "        \n",
    "    class subject_gui(main):\n",
    "        def __init__(self):\n",
    "            self.num_of_groups_dropdown = widgets.Dropdown(options=[1, 2, 3, 4, 5, 6], value=2, description='Choose, how many groups you have in your dataset', layout=widgets.Layout(width=\"auto\"), style={'description_width': 'auto'})\n",
    "            confirm_groups_button = widgets.Button(description='Confirm number of groups', layout=widgets.Layout(width=\"auto\"))\n",
    "            confirm_groups_button.on_click(self.name_groups)\n",
    "            row0 = HBox([self.num_of_groups_dropdown, confirm_groups_button])\n",
    "            box = VBox([row0])\n",
    "            gui.main_tab.children += (box, ) \n",
    "            gui.tab_index += 1\n",
    "            gui.main_tab.set_title(gui.tab_index, \"Subjects to groups\")\n",
    "            gui.main_tab.selected_index = gui.tab_index\n",
    "            \n",
    "        def name_groups(self, b):\n",
    "            self.num_of_groups = self.num_of_groups_dropdown.value\n",
    "            self.l_group_texts = [widgets.Text(value = 'group {}'.format(n), description='Name of group {}'.format(n), layout=widgets.Layout(width=\"auto\"), style = {'description_width': 'auto'}) for n in range (self.num_of_groups)]\n",
    "            name_subjects_button = widgets.Button(description = \"Confirm name of the groups\", layout=widgets.Layout(width=\"auto\"))\n",
    "            name_subjects_button.on_click(self.subjects_to_groups)\n",
    "            box = HBox([VBox(self.l_group_texts), name_subjects_button])\n",
    "            gui.main_tab.children[gui.tab_index].children += (box,)\n",
    "\n",
    "            \n",
    "        def subjects_to_groups(self, b):\n",
    "            l_subject_label = [widgets.Label(value=subject.subject_ID, layout=widgets.Layout(width=\"auto\")) for subject in main.l_subjects]\n",
    "            self.l_group_toggle_buttons = [widgets.ToggleButtons(options = [text.value for text in self.l_group_texts], layout=widgets.Layout(width=\"auto\")) for subject in range(len(main.l_subjects))]\n",
    "            continue_button = widgets.Button(description = \"All subjects in the right group\", layout=widgets.Layout(width=\"auto\"))\n",
    "            continue_button.on_click(self.next_step)\n",
    "            col0 = VBox(l_subject_label)\n",
    "            col1 = VBox(self.l_group_toggle_buttons)\n",
    "            box = HBox([col0, col1, continue_button])\n",
    "            gui.main_tab.children[gui.tab_index].children += (box,)\n",
    "            \n",
    "        def next_step(self, b):\n",
    "            main.l_groups = [self.l_group_texts[n].value for n in range(len(self.l_group_texts))]\n",
    "            for subject in range(len(main.l_subjects)):\n",
    "                main.l_subjects[subject].group_ID = self.l_group_toggle_buttons[subject].value\n",
    "            main.get_maze_corners(main)\n",
    "        \n",
    "    class bc_gui(main):\n",
    "        def __init__(self):\n",
    "            #defish\n",
    "            pass\n",
    "                \n",
    "            \n",
    "    class tc_gui(main):\n",
    "        def __init__(self):\n",
    "            #?\n",
    "            pass\n",
    "    class sc_gui(main):\n",
    "        def __init__(self):\n",
    "            # stitch\n",
    "            pass\n",
    "\n",
    "    class maze_corner_gui(main):\n",
    "        def __init__(self):\n",
    "            self.maze_corner_idx = 0\n",
    "            self.actualize()\n",
    "            self.create_gui()\n",
    "\n",
    "        def on_load_next_button_click(self, b):\n",
    "            if self.results_saved:\n",
    "                if self.maze_corner_idx >= (len(main.l_maze_corners)-1):\n",
    "                    print(\"Maze Corners for all videos set.\")\n",
    "                    #check, whether all Maze Corners are saved to bc.mc.results\n",
    "                    main.get_clean_df_gui(main)\n",
    "                else: \n",
    "                    self.maze_corner_idx += 1\n",
    "                    self.actualize()\n",
    "            else:\n",
    "                display(\"Please save the settings before continuing!\")\n",
    "\n",
    "        def on_load_previous_button_click(self, b):\n",
    "            if self.maze_corner_idx <= 0:\n",
    "                display(\"Index out of range! Index has been set to 0.\")\n",
    "                self.maze_corner_idx = 0\n",
    "            else:\n",
    "                if self.results_saved:\n",
    "                    self.maze_corner_idx -= 1\n",
    "                    self.actualize()\n",
    "                else:\n",
    "                    display(\"Please save the settings before continuing!\")\n",
    "\n",
    "        def actualize(self):\n",
    "            self.results_saved = False\n",
    "\n",
    "        def on_save_button_click(self, b):\n",
    "            main.l_maze_corners[self.maze_corner_idx].results[\"offset_x\"] = self.interactive_plot.children[0].value\n",
    "            main.l_maze_corners[self.maze_corner_idx].results[\"offset_y\"] = self.interactive_plot.children[1].value\n",
    "            main.l_maze_corners[self.maze_corner_idx].results[\"length\"] = self.interactive_plot.children[2].value\n",
    "            main.l_maze_corners[self.maze_corner_idx].results[\"width\"] = self.interactive_plot.children[3].value\n",
    "            main.l_maze_corners[self.maze_corner_idx].results[\"theta\"] = math.radians(self.interactive_plot.children[4].value)\n",
    "            self.results_saved = True\n",
    "            # Save the results:??????????????????????????????????????????????????????????\n",
    "            #with open('reference_coordinates.p', 'wb') as fp:\n",
    "            #    pickle.dump(d_results, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "        def create_gui(self):\n",
    "            width, height = main.l_maze_corners[self.maze_corner_idx].frame.shape[0], main.l_maze_corners[self.maze_corner_idx].frame.shape[1]#replace slider with int, since slider are very slow\n",
    "            slider_x = widgets.IntSlider(value=300, min=0, max=width, step=1, description='x offset', continuous_update=False)\n",
    "            slider_y = widgets.IntSlider(value=5, min=0, max=height, step=1, description='y offset', continuous_update=False)\n",
    "            slider_length = widgets.IntSlider(value=height/2, min=0, max=height*1.5, step=1, continuous_update=False)\n",
    "            slider_width = widgets.IntSlider(value=width/20, min=0, max=width/7, step=1, continuous_update=False)\n",
    "            slider_degrees = widgets.FloatSlider(value=0, min=0, max=90, step=0.1, continuous_update=False)\n",
    "\n",
    "            self.interactive_plot = interactive(main.l_maze_corners[self.maze_corner_idx].f, x=slider_x, y=slider_y, length=slider_length, width=slider_width, degrees=slider_degrees)\n",
    "\n",
    "            self.interactive_plot.children[-1].layout.height = '600px'\n",
    "\n",
    "            load_next_button = widgets.Button(description=\"Load next file\", style = {'description_width': 'auto'})\n",
    "            save_button = widgets.Button(description=\"Save settings\", style = {'description_width': 'auto'})\n",
    "            load_previous_button = widgets.Button(description=\"Load previous file\", style = {'description_width': 'auto'})\n",
    "\n",
    "            load_next_button.on_click(self.on_load_next_button_click)\n",
    "            load_previous_button.on_click(self.on_load_previous_button_click)\n",
    "            save_button.on_click(self.on_save_button_click)\n",
    "\n",
    "            col0 = VBox([load_next_button, save_button])\n",
    "            col1 = VBox([self.interactive_plot.children[0], self.interactive_plot.children[1]])\n",
    "            col2 = VBox([self.interactive_plot.children[2], self.interactive_plot.children[3]])\n",
    "            col3 = VBox([self.interactive_plot.children[4], load_previous_button])\n",
    "            row0 = HBox([col0, col1, col2, col3])\n",
    "            box = VBox([row0, self.interactive_plot.children[-1]])\n",
    "            \n",
    "            gui.main_tab.children += (box, ) \n",
    "            gui.tab_index += 1\n",
    "            gui.main_tab.set_title(gui.tab_index, \"Set Maze Corners\")\n",
    "            gui.main_tab.selected_index = gui.tab_index\n",
    "            \n",
    "\n",
    "    class clean_df_gui(bottom_cam, top_cam, side_cam):\n",
    "        def __init__(self, cam):\n",
    "            self.cam = cam\n",
    "            self.clean_df = False\n",
    "            clean_df_button = widgets.Button(description = \"Clean Dataframe for {}!\".format(self.cam), style = {'description_width': 'auto'}, layout=widgets.Layout(width=\"auto\"))\n",
    "            clean_df_button.on_click(self.get_processed_df)\n",
    "            self.likelihood_threshold_slider = widgets.FloatSlider(min=0, max=1, step=0.01, value=0.75, description = \"DLC likelihood threshold for {}:\".format(self.cam), style = {'description_width': 'auto'}, layout=widgets.Layout(width=\"auto\"))\n",
    "            self.framerate_slider = widgets.IntSlider(min=0, max=200, value=30, description = \"Framerate for {}:\".format(self.cam),  style = {'description_width': 'auto'}, layout=widgets.Layout(width=\"auto\"))\n",
    "            #framerate für videos individuell festlegen?\n",
    "            self.maze_length_slider = widgets.IntSlider(min=30, max=100, value=50, description = \"Mazelength (in cm):\",  style = {'description_width': 'auto'}, layout=widgets.Layout(width=\"auto\"))\n",
    "            \n",
    "            row0 = VBox([clean_df_button, self.framerate_slider, self.likelihood_threshold_slider, self.maze_length_slider])\n",
    "            box = VBox([row0])\n",
    "            \n",
    "            gui.main_tab.children += (box, ) \n",
    "            gui.tab_index += 1\n",
    "            gui.main_tab.set_title(gui.tab_index, \"Clean Dataframe\")\n",
    "            gui.main_tab.selected_index = gui.tab_index\n",
    "\n",
    "            \n",
    "        def get_processed_df(self, b):\n",
    "            if self.clean_df == False:\n",
    "                DLC_likelihood_threshold = self.likelihood_threshold_slider.value\n",
    "                main.framerate[self.cam] = self.framerate_slider.value\n",
    "                main.maze_length_in_cm = self.maze_length_slider.value\n",
    "                main.get_processed_dfs(main, DLC_likelihood_threshold, self.cam)\n",
    "                self.clean_df = True\n",
    "            else:\n",
    "                display(\"Dataframe already cleaned\")\n",
    "            \n",
    "    class select_functions(main):\n",
    "        def __init__(self):\n",
    "            select_functions = widgets.Label(value=\"Select functions in which you're interested in\", layout=widgets.Layout(width=\"auto\"), style = {'description_width': 'auto'})\n",
    "            self.anxiety_check = widgets.Checkbox(value=False, description='Anxiety', layout=widgets.Layout(width=\"auto\"))\n",
    "            self.parkinson_check = widgets.Checkbox(value=False, description='Parkinson', layout=widgets.Layout(width=\"auto\"))\n",
    "            self.catwalk_check = widgets.Checkbox(value=False, description='Catwalk', layout=widgets.Layout(width=\"auto\"))\n",
    "            \n",
    "            self.l_checkboxes = [self.anxiety_check, self.parkinson_check, self.catwalk_check]\n",
    "\n",
    "            confirm_selection_button = widgets.Button(description = \"Confirm Selection\", layout=widgets.Layout(width=\"auto\"))\n",
    "            confirm_selection_button.on_click(self.confirm_selection)\n",
    "\n",
    "            col0 = VBox([select_functions, self.anxiety_check, self.parkinson_check, self.catwalk_check])\n",
    "            col1 = VBox([confirm_selection_button])\n",
    "            box = HBox([col0, col1])\n",
    "            gui.main_tab.children += (box, ) \n",
    "            gui.tab_index += 1\n",
    "            gui.main_tab.set_title(gui.tab_index, \"Select Functions\")\n",
    "            gui.main_tab.selected_index = gui.tab_index\n",
    "\n",
    "        def confirm_selection(self, b):\n",
    "            l_selected_functions_values = [checkbox.value for checkbox in self.l_checkboxes]\n",
    "            l_selected_functions_keys = [checkbox.description for checkbox in self.l_checkboxes]\n",
    "            dict_selected_functions = {key:value for key,value in zip(l_selected_functions_keys,l_selected_functions_values)}\n",
    "            main.execute_functions(main, dict_selected_functions)\n",
    "            \n",
    "    class stats_gui(main):\n",
    "        output_path = \"\"\n",
    "        \n",
    "        def __init__(self, dict_selected_functions):\n",
    "            self.dict_selected_functions = dict_selected_functions\n",
    "            self.select_stats_dropdown = widgets.RadioButtons(options=[\"basic\", \"all\", \"select\"], value=\"basic\", description = \"Choose, which statistics you want to plot\", layout=widgets.Layout(width=\"auto\"), style = {'description_width': 'auto'})\n",
    "            \n",
    "            confirm_button = widgets.Button(description = \"Confirm\", layout=widgets.Layout(width=\"auto\"))\n",
    "            confirm_button.on_click(self.confirm)\n",
    "            \n",
    "            enter_path = widgets.Button(description=\"Select output folder\", layout=widgets.Layout(width=\"auto\"))\n",
    "            enter_path.on_click(self.select_output_path)\n",
    "            \n",
    "            select_ind_var_label = widgets.Label(value=\"Select independent variable\", layout=widgets.Layout(width=\"auto\"))\n",
    "            self.select_ind_variable = widgets.Dropdown(options = [\"group_ID\", \"trialnumber\", \"paradigm\"], layout=widgets.Layout(width=\"auto\"))\n",
    "            select_hue_label = widgets.Label(value=\"Select hue\", layout=widgets.Layout(width=\"auto\"))\n",
    "            self.select_hue = widgets.Dropdown(options = [\"subject_ID\", \"paradigm\", \"group_ID\"], layout=widgets.Layout(width=\"auto\"))\n",
    "            \n",
    "            col0 = VBox([self.select_stats_dropdown, confirm_button])\n",
    "            col1 = VBox([select_ind_var_label, self.select_ind_variable])\n",
    "            col2 = VBox([select_hue_label, self.select_hue])\n",
    "            col3 = VBox ([enter_path])\n",
    "            row0 = HBox([col0, col1, col2, col3])\n",
    "            box = VBox([row0])\n",
    "            gui.main_tab.children += (box, ) \n",
    "            gui.tab_index += 1\n",
    "            gui.main_tab.set_title(gui.tab_index, \"Select Statistics\")\n",
    "            gui.main_tab.selected_index = gui.tab_index\n",
    "            \n",
    "        def select_output_path(self, b):\n",
    "            root = Tk()\n",
    "            root.withdraw()\n",
    "            root.call('wm', 'attributes', '.', '-topmost', True)\n",
    "            self.output_path = filedialog.askdirectory() + \"/\"\n",
    "            display(self.output_path)        \n",
    "            \n",
    "        def confirm(self, b):\n",
    "            if self.select_stats_dropdown.value == \"select\":\n",
    "                self.select_data_col()\n",
    "            else:\n",
    "                if self.select_stats_dropdown.value == \"basic\":\n",
    "                    self.l_selected_data_col = []\n",
    "                    if self.dict_selected_functions[\"Anxiety\"]:\n",
    "                        self.l_selected_data_col.extend(['count_freezing_bouts', 'percentage_of_time_spent_freezing', 'mean_freezing_bouts_y_position'])\n",
    "                    if self.dict_selected_functions[\"Parkinson\"]:\n",
    "                        self.l_selected_data_col.extend(['mean_gait_disruption_bouts_y_position_all'])\n",
    "                    if self.dict_selected_functions[\"Catwalk\"]:\n",
    "                        self.l_selected_data_col.extend(['mean_distance_secondtoe_hindpawright', 'mean_distance_secondtoe_hindpawleft', 'mean_area_hindpawright', 'mean_area_hindpawleft'])\n",
    "                elif self.select_stats_dropdown.value == \"all\":\n",
    "                    self.l_selected_data_col = [key for key in main.d_data.keys() if key not in set(['subject_ID', 'group_ID', 'paradigm', 'trialnumber'])]\n",
    "                l_selected_data_col_dict = []\n",
    "                for data_col in self.l_selected_data_col:\n",
    "                    dict_stats = {}\n",
    "                    dict_stats[\"data_col\"] = data_col\n",
    "                    dict_stats[\"independent_variable\"] =  self.select_ind_variable.value\n",
    "                    dict_stats[\"hue\"] =  self.select_hue.value\n",
    "                    l_selected_data_col_dict.append(dict_stats)\n",
    "                main.calculate_stats(main, self.output_path, l_selected_data_col_dict)\n",
    "                \n",
    "        def select_data_col(self):\n",
    "            confirm_button = widgets.Button(description = \"Confirm\", layout=widgets.Layout(width=\"auto\"))\n",
    "            confirm_button.on_click(self.confirm_selected_data_col)\n",
    "            select_data_key_label = widgets.Label(value=\"Select Data Column\", layout=widgets.Layout(width=\"auto\"))\n",
    "            select_ind_var_label = widgets.Label(value=\"Select independent variable\", layout=widgets.Layout(width=\"auto\"))\n",
    "            select_hue_label = widgets.Label(value=\"Select hue\", layout=widgets.Layout(width=\"auto\"))\n",
    "            \n",
    "            l_grid_children = [select_data_key_label, select_ind_var_label, select_hue_label]\n",
    "            for key in main.d_data.keys(): \n",
    "                if key not in set(['subject_ID', 'group_ID', 'paradigm', 'trialnumber']):\n",
    "                    l_grid_children.append(widgets.Checkbox(value=False, description=key, layout=widgets.Layout(width=\"auto\")))\n",
    "                    l_grid_children.append(widgets.Dropdown(options = [\"group_ID\", \"trialnumber\", \"paradigm\"], value='group_ID', layout=widgets.Layout(width=\"auto\")))\n",
    "                    l_grid_children.append(widgets.Dropdown(options = [\"subject_ID\", \"paradigm\", \"group_ID\"], value='subject_ID', layout=widgets.Layout(width=\"auto\")))\n",
    "            \n",
    "            enter_path = widgets.Button(description=\"Select output folder\", layout=widgets.Layout(width=\"auto\"))\n",
    "            enter_path.on_click(self.select_output_path)\n",
    "\n",
    "            col3 = VBox([enter_path, confirm_button]) \n",
    " \n",
    "            self.grid = widgets.GridBox(l_grid_children, layout=widgets.Layout(grid_template_columns=\"repeat(3, auto)\"))\n",
    "\n",
    "            box = HBox([self.grid, col3])\n",
    "            gui.main_tab.children[gui.tab_index].children += (box,)\n",
    "            gui.main_tab.children[gui.tab_index].children[0].children = (gui.main_tab.children[gui.tab_index].children[0].children[0], )\n",
    "            \n",
    "\n",
    "        def confirm_selected_data_col(self, b):\n",
    "            l_selected_data_col_dict = []\n",
    "            for n in range(len(self.grid.children)):\n",
    "                if n>2 & n%3 == 0:\n",
    "                    if self.grid.children[n].value == True:\n",
    "                        dict_stats = {}\n",
    "                        dict_stats[\"data_col\"] = self.grid.children[n].description\n",
    "                        dict_stats[\"independent_variable\"] =  self.grid.children[n+1].value\n",
    "                        dict_stats[\"hue\"] =  self.grid.children[n+2].value\n",
    "                        l_selected_data_col_dict.append(dict_stats)\n",
    "            main.calculate_stats(main, self.output_path, l_selected_data_col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3ddf38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stats(main):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def position_stats(self, data_col, independent_variable, hue, output_path):\n",
    "        #if output_path != \"\"\n",
    "        l_columns = ['group_ID', 'subject_ID', 'paradigm']\n",
    "\n",
    "        dataframe = main.dataframe.loc[:, [data_col] + l_columns]\n",
    "        dataframe.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        plt.figure(figsize=(7,9), facecolor='white')\n",
    "        \n",
    "        sns.violinplot(data=dataframe, y=\"paradigm\", x=data_col, fliersize=0, orient='h', hue=independent_variable)\n",
    "        sns.stripplot(data=dataframe, y=\"paradigm\", x=data_col, orient='h', color='k', hue=independent_variable, dodge=True, alpha=0.3)\n",
    "        plt.vlines(x=35, ymin=0.5, ymax=3.5, color='magenta', linestyle='dashed')\n",
    "\n",
    "        if output_path != \"\":\n",
    "            figname = 'differences between {} for {}.png'.format(data_col, independent_variable)\n",
    "            plt.savefig(output_path + figname, dpi=300)\n",
    "            csv_name = figname.replace('png', 'csv')\n",
    "            dataframe.to_csv(output_path + csv_name)\n",
    "    \n",
    "        plt.xlim(0, 75)\n",
    "        plt.legend(loc='center right')\n",
    "        plt.title(data_col + \" per \" + independent_variable)\n",
    "        plt.show()\n",
    "        #plt.close()\n",
    "        \n",
    "    def total_count_stats(self, data_col, independent_variable, hue, output_path):\n",
    "        #if output_path != \"\"\n",
    "        l_columns = ['group_ID', 'subject_ID', 'paradigm']\n",
    "        \n",
    "        dataframe = main.dataframe.loc[:, [data_col] + l_columns].copy()\n",
    "        dataframe.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        plt.figure(figsize=(7,4), facecolor='white')\n",
    "        \n",
    "        sns.boxplot(data=dataframe, y=\"paradigm\", x=data_col, hue=independent_variable, fliersize=0)\n",
    "        sns.stripplot(data=dataframe, y=\"paradigm\", x=data_col, hue=independent_variable, dodge=True, color='k')\n",
    "        \n",
    "        if output_path != \"\":\n",
    "            figname = 'differences between {} for {}.png'.format(data_col, independent_variable)\n",
    "            plt.savefig(output_path + figname, dpi=300)\n",
    "            csv_name = figname.replace('png', 'csv')\n",
    "            dataframe.to_csv(output_path + csv_name)\n",
    "\n",
    "        plt.ylim(0)\n",
    "        plt.xlim(-0.5,5.5)\n",
    "        #plt.legend('')\n",
    "        plt.title(data_col + \" per \" + independent_variable)\n",
    "        plt.show()\n",
    "        #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1e25349",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1f967e8068407ba05ff128949e030a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HBox(children=(VBox(children=(Button(description='Select folder', layout=Layout(width='auto'), s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.main at 0x1e7a85109d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'C:/Users/kobel/Documents/Medizin/Doktorarbeit/Coding/Dummy Data/'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maze Corners for all videos set.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "class plotting(main):\n",
    "\n",
    "\n",
    "\n",
    "    ###################################################################\n",
    "    #Overview:\n",
    "\n",
    "        # 1 Compute statistics\n",
    "        # 2 Annotate stats within the plots\n",
    "        # 3 Functions that are triggered by clicking the widget buttons\n",
    "        # 4 Create all widget elements\n",
    "        # 5 Specify widget layout and launch it\n",
    "        # 6 Process statistical results for download\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "\n",
    "    ###################################################################\n",
    "    # 1 Functions to compute the different statistics\n",
    "    # 1.1 Comparison of independent samples\n",
    "    def independent_samples():\n",
    "        global data_col, group_col, d_main, l_groups, performed_test\n",
    "        data_col = df.columns[0]\n",
    "        group_col = df.columns[1]\n",
    "\n",
    "        d_main = {}\n",
    "        l_groups = list(df[group_col].unique())\n",
    "        for group_id in l_groups:\n",
    "            d_main[group_id] = {'data': df.loc[df[group_col] == group_id, data_col].values,\n",
    "                                'normality_full': pg.normality(df.loc[df[group_col] == group_id, data_col].values),\n",
    "                                'normality_bool': pg.normality(df.loc[df[group_col] == group_id, data_col].values)['normal'][0]}\n",
    "\n",
    "        n_groups = len(l_groups)\n",
    "\n",
    "        d_main['summary'] = {'normality': all([d_main[elem]['normality_bool'] for elem in l_groups]),\n",
    "                             'homoscedasticity': pg.homoscedasticity([d_main[elem]['data'] for elem in l_groups])['equal_var'][0]}\n",
    "\n",
    "        parametric = all([d_main['summary']['normality'], d_main['summary']['homoscedasticity']])\n",
    "\n",
    "        if len(l_groups) > 2:\n",
    "            if parametric:\n",
    "                d_main['summary']['group_level_statistic'] = pg.anova(data=df, dv=data_col, between=group_col)\n",
    "                performed_test = 'One-way ANOVA'\n",
    "            else:\n",
    "                d_main['summary']['group_level_statistic'] = pg.kruskal(data=df, dv=data_col, between=group_col)\n",
    "                performed_test = 'Kruskal-Wallis-ANOVA'\n",
    "\n",
    "        if len(l_groups) > 1:\n",
    "            d_main['summary']['pairwise_comparisons'] = pg.pairwise_ttests(data=df, dv=data_col, between=group_col, parametric=parametric, padjust='holm')\n",
    "\n",
    "        else:\n",
    "            print('Error: The group_id column has to contain at least two different group_ids for this selection.\\\n",
    "            \\nDid you mean to perform a one-sample test?')   \n",
    "\n",
    "\n",
    "    # 1.2 Mixed-model ANOVA (contributed by Konstantin Kobel):\n",
    "    def mixed_model_ANOVA():\n",
    "        global d_main, data_col, group_col, subject_col, session_col, l_groups, l_sessions, performed_test\n",
    "        data_col = df.columns[0]\n",
    "        group_col = df.columns[1]\n",
    "        subject_col = df.columns[2]\n",
    "        session_col = df.columns[3]\n",
    "\n",
    "        d_main = {}\n",
    "        l_groups = list(df[group_col].unique())\n",
    "        l_sessions = list(df[session_col].unique())\n",
    "\n",
    "        for group_id in l_groups:\n",
    "            for session_id in l_sessions:       \n",
    "                d_main[group_id, session_id] = {'data': df.loc[(df[group_col] == group_id) & (df[session_col] == session_id), data_col].values,\n",
    "                                                'mean': df.loc[(df[group_col] == group_id) & (df[session_col] == session_id), data_col].mean(),\n",
    "                                                'normality_full': pg.normality(df.loc[(df[group_col] == group_id) \n",
    "                                                                                      & (df[session_col] == session_id), data_col].values),\n",
    "                                                'normality_bool': pg.normality(df.loc[(df[group_col] == group_id) \n",
    "                                                                                      & (df[session_col] == session_id), data_col].values)['normal'][0]}\n",
    "\n",
    "        n_groups = len(l_groups)*len(l_sessions)\n",
    "        d_main['summary'] = {}\n",
    "\n",
    "        d_main['summary'] = {'normality': all([d_main[key]['normality_bool'] for key in d_main.keys() if key != 'summary']),\n",
    "                             'homoscedasticity': pg.homoscedasticity([d_main[key]['data'] for key in d_main.keys() if key != 'summary'])['equal_var'][0]}    \n",
    "\n",
    "        parametric = all([d_main['summary']['normality'], d_main['summary']['homoscedasticity']])\n",
    "\n",
    "        d_main['summary']['group_level_statistic'] = pg.mixed_anova(data=df, dv=data_col, within=session_col, subject=subject_col, between=group_col)\n",
    "        performed_test = 'Mixed-model ANOVA'\n",
    "        # If we found some non-parametric alternative this could be implemented here\n",
    "        if parametric == False:\n",
    "            print (\"Please be aware that the data require non-parametric testing.\\n\\\n",
    "            However, this is not implemented yet and a parametric test is computed instead.\")\n",
    "\n",
    "        d_main['summary']['pairwise_comparisons'] = pg.pairwise_ttests(data=df, dv=data_col, \n",
    "                                                                       within=session_col, subject=subject_col, \n",
    "                                                                       between=group_col, padjust='holm')\n",
    "\n",
    "    ###################################################################    \n",
    "\n",
    "\n",
    "    ###################################################################\n",
    "    # 2 Functions to annotate the results of the statistical tests in the respective plots:\n",
    "    # 2.1 Get and update all customization values that were set by the user:\n",
    "    def get_customization_values():\n",
    "        global distance_stars_to_brackets, distance_brackets_to_data, fontsize_stars_bold\n",
    "        global linewidth_annotations, fontsize_stars, annotation_brackets_factor\n",
    "        global l_xlabel_order, l_hue_order\n",
    "\n",
    "        distance_stars_to_brackets = set_distance_stars_to_brackets.value\n",
    "        distance_brackets_to_data = set_distance_brackets_to_data.value\n",
    "        fontsize_stars = set_fontsize_stars.value\n",
    "        linewidth_annotations = set_linewidth_annotations.value\n",
    "\n",
    "        if set_stars_fontweight_bold.value == True:\n",
    "            fontsize_stars_bold = 'bold'\n",
    "        else:\n",
    "            fontsize_stars_bold = 'normal'\n",
    "\n",
    "        if select_bracket_no_bracket.value == 'Brackets':\n",
    "            annotation_brackets_factor = 1\n",
    "        else:\n",
    "            annotation_brackets_factor = 0\n",
    "\n",
    "        l_xlabel_order = []\n",
    "        l_xlabel_string = set_xlabel_order.value\n",
    "\n",
    "        while ', ' in l_xlabel_string:\n",
    "            l_xlabel_order.append(l_xlabel_string[:l_xlabel_string.index(', ')])\n",
    "            l_xlabel_string = l_xlabel_string[l_xlabel_string.index(', ')+2:]\n",
    "\n",
    "        l_xlabel_order.append(l_xlabel_string)\n",
    "\n",
    "        l_hue_order = []\n",
    "        l_hue_string = set_hue_order.value\n",
    "\n",
    "        while ', ' in l_hue_string:\n",
    "            l_hue_order.append(l_hue_string[:l_hue_string.index(', ')])\n",
    "            l_hue_string = l_hue_string[l_hue_string.index(', ')+2:]\n",
    "\n",
    "        l_hue_order.append(l_hue_string)\n",
    "\n",
    "\n",
    "    # 2.2 Get l_stats_to_annotate:\n",
    "    # 2.2.1 For independent samples:\n",
    "    def get_l_stats_to_annotate_independent_samples():\n",
    "        l_stats_to_annotate = []\n",
    "        if set_annotate_all.value==True:\n",
    "            for i in range(len(l_checkboxes)):\n",
    "                l_checkboxes[i].value = True\n",
    "        for i in range(len(l_checkboxes)):\n",
    "            if l_checkboxes[i].value:\n",
    "                checkbox_description = l_checkboxes[i].description\n",
    "                group1 = checkbox_description[:checkbox_description.index(' ')]\n",
    "                group2 = checkbox_description[checkbox_description.index(' vs. ') + 5 :]\n",
    "                l_stats_to_annotate.append((group1, group2))\n",
    "        return l_stats_to_annotate\n",
    "\n",
    "\n",
    "    # 2.2.2 For Mixed-Model-ANOVA:\n",
    "    def get_l_stats_to_annotate_mma():\n",
    "        l_stats_to_annotate = []\n",
    "        if set_annotate_all.value==True:\n",
    "            for i in range(len(l_checkboxes)):\n",
    "                l_checkboxes[i][1].value = True\n",
    "        for i in range(len(l_checkboxes)):\n",
    "            if l_checkboxes[i][1].value:\n",
    "                checkbox_description = l_checkboxes[i][1].description\n",
    "                group1 = checkbox_description[:checkbox_description.index(' ')]\n",
    "                group2 = checkbox_description[checkbox_description.index(' vs. ') + 5 :]\n",
    "                session_id = l_checkboxes[i][0]\n",
    "                l_stats_to_annotate.append((group1, group2, session_id))\n",
    "        return l_stats_to_annotate\n",
    "\n",
    "\n",
    "    # 2.3 Get the 'stars' string for the respective pairwise comparison:\n",
    "    def get_stars_str(df_tmp, group1, group2):\n",
    "        if df_tmp.loc[(df_tmp['A'] == group1) & (df_tmp['B'] == group2)].shape[0] > 0:\n",
    "            if 'p-corr' in df_tmp.loc[(df_tmp['A'] == group1) & (df_tmp['B'] == group2)].columns:\n",
    "                pval = df_tmp.loc[(df_tmp['A'] == group1) & (df_tmp['B'] == group2), 'p-corr'].iloc[0]\n",
    "            else:\n",
    "                pval = df_tmp.loc[(df_tmp['A'] == group1) & (df_tmp['B'] == group2), 'p-unc'].iloc[0]\n",
    "\n",
    "        elif df_tmp.loc[(df_tmp['B'] == group1) & (df_tmp['A'] == group2)].shape[0] > 0:\n",
    "            if 'p-corr' in df_tmp.loc[(df_tmp['B'] == group1) & (df_tmp['A'] == group2)].columns:\n",
    "                pval = df_tmp.loc[(df_tmp['B'] == group1) & (df_tmp['A'] == group2), 'p-corr'].iloc[0]\n",
    "            else:\n",
    "                pval = df_tmp.loc[(df_tmp['B'] == group1) & (df_tmp['A'] == group2), 'p-unc'].iloc[0]\n",
    "        else:\n",
    "            print('There was an error with annotating the stats!')\n",
    "        if pval <= 0.001:\n",
    "            stars = '***'\n",
    "        elif pval <= 0.01:\n",
    "            stars = '**'\n",
    "        elif pval <= 0.05:\n",
    "            stars = '*'\n",
    "        else: \n",
    "            stars = 'n.s.'\n",
    "        return stars\n",
    "\n",
    "\n",
    "    # 2.4 Annotate the stats in the respective plots\n",
    "    # 2.4.1 Annotate stats in independent sample plots:\n",
    "    def annotate_stats_independent_samples(l_stats_to_annotate):\n",
    "        if len(l_stats_to_annotate) > 0:\n",
    "            max_total = df[data_col].max()\n",
    "            y_shift_annotation_line = max_total * distance_brackets_to_data\n",
    "            brackets_height = y_shift_annotation_line*0.5*annotation_brackets_factor\n",
    "            y_shift_annotation_text = brackets_height + y_shift_annotation_line*0.5*distance_stars_to_brackets\n",
    "\n",
    "            # Set initial y\n",
    "            y = max_total + y_shift_annotation_line\n",
    "\n",
    "            # Add check whether group level ANOVA / Kruska-Wallis-ANOVA is significant\n",
    "            df_temp = d_main['summary']['pairwise_comparisons'].copy()\n",
    "\n",
    "            for group1, group2 in l_stats_to_annotate:\n",
    "\n",
    "                x1 = l_xlabel_order.index(group1)\n",
    "                x2 = l_xlabel_order.index(group2)\n",
    "\n",
    "                stars = get_stars_str(df_temp, group1, group2)\n",
    "\n",
    "                plt.plot([x1, x1, x2, x2], [y, y+brackets_height, y+brackets_height, y], c='k', lw=linewidth_annotations)    \n",
    "                plt.text((x1+x2)*.5, y+y_shift_annotation_text, stars, ha='center', va='bottom', color='k', \n",
    "                         fontsize=fontsize_stars, fontweight=fontsize_stars_bold)\n",
    "\n",
    "                # With set_distance_stars_to_brackets being limited to 5, stars will always be closer than next annotation line\n",
    "                y = y+3*y_shift_annotation_line\n",
    "\n",
    "\n",
    "    # 2.4.2 Annotate stats in Mixed-model ANOVA plots:\n",
    "    # 2.4.2.1 Annotate stats in Mixed-model ANOVA point plot:\n",
    "    def annotate_stats_mma_pointplot(l_stats_to_annotate):\n",
    "        if len(l_stats_to_annotate) > 0:\n",
    "            l_to_annotate_ordered = []\n",
    "            for session_id in l_sessions:\n",
    "                l_temp = [elem for elem in l_stats_to_annotate if elem[2]==session_id]\n",
    "                for elem in l_temp:\n",
    "                    abs_mean_difference = abs(df.loc[(df[group_col]==elem[0]) & (df[session_col]==elem[2]), data_col].mean()-\n",
    "                                              df.loc[(df[group_col]==elem[1]) & (df[session_col]==elem[2]), data_col].mean())\n",
    "                    l_temp[l_temp.index(elem)] = elem+(abs_mean_difference,)\n",
    "                l_temp.sort(key=sort_by_third)\n",
    "                l_to_annotate_ordered = l_to_annotate_ordered+l_temp\n",
    "\n",
    "            df_temp = d_main['summary']['pairwise_comparisons'].copy()\n",
    "\n",
    "            for elem in l_to_annotate_ordered:\n",
    "                group1, group2, session_id, abs_mean_difference = elem\n",
    "\n",
    "                if l_to_annotate_ordered.index(elem) == 0:\n",
    "                    n_previous_annotations_in_this_session_id = 0\n",
    "                elif session_id == prev_session:\n",
    "                    n_previous_annotations_in_this_session_id = n_previous_annotations_in_this_session_id + 1\n",
    "                else:\n",
    "                    n_previous_annotations_in_this_session_id = 0\n",
    "\n",
    "                x_shift_annotation_line = distance_brackets_to_data + distance_brackets_to_data * n_previous_annotations_in_this_session_id * 1.5\n",
    "                brackets_height = distance_brackets_to_data*0.5*annotation_brackets_factor\n",
    "                x_shift_annotation_text = brackets_height + distance_brackets_to_data*0.5*distance_stars_to_brackets            \n",
    "\n",
    "                x = l_xlabel_order.index(session_id) + x_shift_annotation_line\n",
    "                y1=df.loc[(df[group_col] == group1) & (df[session_col] == session_id), data_col].mean()\n",
    "                y2=df.loc[(df[group_col] == group2) & (df[session_col] == session_id), data_col].mean()            \n",
    "\n",
    "                stars = get_stars_str(df_temp.loc[df_temp[session_col] == session_id], group1, group2)\n",
    "\n",
    "                plt.plot([x, x+brackets_height, x+brackets_height, x], [y1, y1, y2, y2], color='k', lw=linewidth_annotations)\n",
    "                plt.text(x+x_shift_annotation_text, (y1+y2)/2, stars, rotation=-90, ha='center', va='center', \n",
    "                         fontsize=fontsize_stars, fontweight=fontsize_stars_bold)             \n",
    "\n",
    "                prev_session = session_id\n",
    "\n",
    "\n",
    "    # Helper function to make sorting based on 3rd element in tuple possible\n",
    "    def sort_by_third(e):\n",
    "        return e[3]\n",
    "\n",
    "\n",
    "    # 2.4.2.2 Annotate stats in Mixed-model ANOVA violin plot:\n",
    "    def annotate_stats_mma_violinplot(l_stats_to_annotate):\n",
    "        if len(l_stats_to_annotate) > 0:\n",
    "            l_to_annotate_ordered = []\n",
    "            for session_id in l_sessions:\n",
    "                l_temp = [elem for elem in l_stats_to_annotate if elem[2]==session_id]\n",
    "                for elem in l_temp:\n",
    "                    abs_mean_difference = abs(df.loc[(df[group_col]==elem[0]) & (df[session_col]==elem[2]), data_col].mean()-\n",
    "                                              df.loc[(df[group_col]==elem[1]) & (df[session_col]==elem[2]), data_col].mean())\n",
    "                    l_temp[l_temp.index(elem)] = elem+(abs_mean_difference,)\n",
    "                l_temp.sort(key=sort_by_third)\n",
    "                l_to_annotate_ordered = l_to_annotate_ordered+l_temp\n",
    "\n",
    "            df_temp = d_main['summary']['pairwise_comparisons'].copy()\n",
    "\n",
    "            max_total = df[data_col].max()\n",
    "            y_shift_annotation_line = max_total * distance_brackets_to_data\n",
    "            brackets_height = y_shift_annotation_line*0.5*annotation_brackets_factor\n",
    "            y_shift_annotation_text = brackets_height + y_shift_annotation_line*0.5*distance_stars_to_brackets\n",
    "\n",
    "            for elem in l_to_annotate_ordered:\n",
    "                group1, group2, session_id, abs_mean_difference = elem\n",
    "\n",
    "                if l_to_annotate_ordered.index(elem) == 0:\n",
    "                    n_previous_annotations_in_this_session_id = 0\n",
    "                elif session_id == prev_session:\n",
    "                    n_previous_annotations_in_this_session_id = n_previous_annotations_in_this_session_id + 1\n",
    "                else:\n",
    "                    n_previous_annotations_in_this_session_id = 0\n",
    "\n",
    "                y = max_total + y_shift_annotation_line + y_shift_annotation_line*n_previous_annotations_in_this_session_id*3\n",
    "\n",
    "                width = 0.8\n",
    "                x_base = l_xlabel_order.index(session_id) - width/2 + width/(2*len(l_hue_order))\n",
    "                x1 = x_base + width/len(l_hue_order)*l_hue_order.index(group1)\n",
    "                x2 = x_base + width/len(l_hue_order)*l_hue_order.index(group2)\n",
    "\n",
    "                stars = get_stars_str(df_temp.loc[df_temp[session_col] == session_id], group1, group2)\n",
    "\n",
    "                plt.plot([x1, x1, x2, x2], [y, y+brackets_height, y+brackets_height, y], color='k', lw=linewidth_annotations)\n",
    "                plt.text((x1+x2)/2, y+y_shift_annotation_text, stars, ha='center', va='bottom', \n",
    "                         fontsize=fontsize_stars, fontweight=fontsize_stars_bold)\n",
    "\n",
    "                prev_session = session_id\n",
    "\n",
    "\n",
    "    ###################################################################    \n",
    "\n",
    "\n",
    "    ###################################################################\n",
    "    # 3 Functions that are triggered by clicking on the widget buttons:\n",
    "    # 3.1 Stats button:        \n",
    "    def on_stats_button_clicked(b):\n",
    "        global df, save_plot, l_checkboxes\n",
    "        if list(uploader.value.keys())[0].endswith('.csv'): \n",
    "            with open(\"input.csv\", \"w+b\") as i:\n",
    "                i.write(uploader.value[list(uploader.value.keys())[0]]['content'])\n",
    "            df = pd.read_csv('input.csv', index_col=0)\n",
    "\n",
    "        elif list(uploader.value.keys())[0].endswith('.xlsx'):\n",
    "            with open(\"input.xlsx\", \"w+b\") as i:\n",
    "                i.write(uploader.value[list(uploader.value.keys())[0]]['content'])\n",
    "            df = pd.read_excel('input.xlsx', index_col=0)\n",
    "\n",
    "        save_plot = False\n",
    "\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "\n",
    "            uploader.layout.visibility = 'hidden'\n",
    "            plotting_button.layout.visibility = 'visible'\n",
    "            select_plot.layout.visibility = 'visible'\n",
    "            expand_me_accordion.layout.visibility = 'visible'\n",
    "            select_downloads.layout.visibility = 'visible'\n",
    "            download_button.layout.visibility = 'visible'\n",
    "\n",
    "            if select_test.value == 0: # comparison of independent samples\n",
    "                select_plot.options = [('stripplot', 0), ('boxplot', 1), ('boxplot with scatterplot overlay', 2), ('violinplot', 3)]\n",
    "            elif select_test.value == 2: # mixed-model ANOVA\n",
    "                select_plot.options = [('pointplot', 0), ('boxplot', 1), ('boxplot with scatterplot overlay', 2), ('violinplot', 3)]\n",
    "            else:\n",
    "                print('Function not implemented. Please go and annoy Dennis to finally do it')\n",
    "\n",
    "            if select_test.value==0:\n",
    "                independent_samples()\n",
    "                checkboxes_to_add, l_checkboxes = create_checkboxes_pairwise_comparisons()\n",
    "            elif select_test.value==2:\n",
    "                mixed_model_ANOVA()\n",
    "                checkboxes_to_add, l_checkboxes = create_checkboxes_pairwise_comparisons_mma()\n",
    "\n",
    "            if len(select_annotations_vbox.children) == 0:\n",
    "                    select_annotations_vbox.children = select_annotations_vbox.children + checkboxes_to_add\n",
    "\n",
    "            create_group_order_text()\n",
    "            create_ylims()\n",
    "\n",
    "            create_group_color_pickers()\n",
    "\n",
    "\n",
    "\n",
    "            display(d_main['summary']['pairwise_comparisons'])   \n",
    "\n",
    "\n",
    "    # 3.2 Plotting button\n",
    "    def on_plotting_button_clicked(b):\n",
    "        global l_xlabel_order \n",
    "        # Update all variables according to the customization input of the user\n",
    "        get_customization_values()\n",
    "\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "\n",
    "            plotting_button.description = 'Refresh the plot'\n",
    "\n",
    "            if select_palette_or_individual_color.value == 0:\n",
    "                color_palette = select_color_palettes.value\n",
    "            else:\n",
    "                color_palette = {}\n",
    "                for group_id in l_groups:\n",
    "                    color_palette[group_id] = group_colors_vbox.children[l_groups.index(group_id)].value\n",
    "\n",
    "            fig = plt.figure(figsize=(set_fig_width.value/2.54 , set_fig_height.value/2.54), facecolor='white')\n",
    "            ax = fig.add_subplot()\n",
    "\n",
    "            for axis in ['top', 'right']:\n",
    "                ax.spines[axis].set_visible(False)\n",
    "\n",
    "            for axis in ['bottom','left']:\n",
    "                ax.spines[axis].set_linewidth(set_axes_linewidth.value)\n",
    "                ax.spines[axis].set_color(set_axes_color.value)      \n",
    "\n",
    "            plt.tick_params(labelsize=set_axes_tick_size.value, colors=set_axes_color.value)\n",
    "\n",
    "            if select_test.value == 0: # independent_samples()\n",
    "                if select_plot.value == 0:\n",
    "                    sns.stripplot(data=df, x=group_col, y=data_col, order=l_xlabel_order, palette=color_palette, size=set_marker_size.value)\n",
    "                elif select_plot.value == 1:\n",
    "                    sns.boxplot(data=df, x=group_col, y=data_col, order=l_xlabel_order, palette=color_palette)\n",
    "                elif select_plot.value == 2:\n",
    "                    sns.boxplot(data=df, x=group_col, y=data_col, order=l_xlabel_order, palette=color_palette, showfliers=False)\n",
    "                    sns.stripplot(data=df, x=group_col, y=data_col, color='k', order=l_xlabel_order, size=set_marker_size.value)\n",
    "                elif select_plot.value == 3:\n",
    "                    sns.violinplot(data=df, x=group_col, y=data_col, order=l_xlabel_order, palette=color_palette, cut=0)\n",
    "                    sns.stripplot(data=df, x=group_col, y=data_col, color='k', order=l_xlabel_order, size=set_marker_size.value)                \n",
    "                else:\n",
    "                    print(\"Function not implemented. Please go and annoy Dennis to finally do it\")\n",
    "\n",
    "            elif select_test.value == 2: # mixed_model_ANOVA()\n",
    "                if select_plot.value == 0:\n",
    "                    sns.pointplot(data=df, x=session_col, y=data_col, order=l_xlabel_order, hue=group_col, hue_order=l_hue_order,\n",
    "                                  palette=color_palette, dodge=True, ci='sd', err_style='bars', capsize=0)  \n",
    "                elif select_plot.value == 1:\n",
    "                    sns.boxplot(data=df, x=session_col, y=data_col, order=l_xlabel_order, hue=group_col, hue_order=l_hue_order,\n",
    "                                palette=color_palette)\n",
    "                elif select_plot.value == 2:\n",
    "                    sns.boxplot(data=df, x=session_col, y=data_col, order=l_xlabel_order, hue=group_col, hue_order=l_hue_order,\n",
    "                                palette=color_palette, showfliers=False)\n",
    "                    sns.stripplot(data=df, x=session_col, y=data_col, order=l_xlabel_order, hue=group_col, hue_order=l_hue_order,\n",
    "                                  dodge=True, color='k', size=set_marker_size.value)\n",
    "                elif select_plot.value == 3:\n",
    "                    sns.violinplot(data=df, x=session_col, y=data_col, order=l_xlabel_order, hue=group_col, hue_order=l_hue_order,\n",
    "                                   width=0.8, cut=0, palette=color_palette)\n",
    "                    sns.stripplot(data=df, x=session_col, y=data_col, order=l_xlabel_order, hue=group_col, hue_order=l_hue_order,\n",
    "                                  dodge=True, color='k', size=set_marker_size.value)\n",
    "                else:\n",
    "                    print(\"Function not implemented. Please go and annoy Dennis to finally do it\")\n",
    "\n",
    "                if set_show_legend.value == True:\n",
    "                    if select_plot.value == 0:\n",
    "                        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), frameon=False)\n",
    "\n",
    "                    elif select_plot.value in [1, 2, 3]:\n",
    "                        handles, labels = ax.get_legend_handles_labels()\n",
    "                        new_handles = handles[:len(l_hue_order)]\n",
    "                        new_labels = labels[:len(l_hue_order)]\n",
    "                        ax.legend(new_handles, new_labels, loc='center left', bbox_to_anchor=(1, 0.5), frameon=False)\n",
    "                else:\n",
    "                    ax.get_legend().remove()\n",
    "\n",
    "            else:\n",
    "                print(\"Function not implemented. Please go and annoy Dennis to finally do it\")\n",
    "\n",
    "            if select_test.value == 0: # independent_samples()\n",
    "                l_stats_to_annotate = get_l_stats_to_annotate_independent_samples()\n",
    "                annotate_stats_independent_samples(l_stats_to_annotate)\n",
    "\n",
    "            elif select_test.value == 2: # mixed_model_ANOVA()#\n",
    "                l_stats_to_annotate = get_l_stats_to_annotate_mma()\n",
    "                if select_plot.value == 0:\n",
    "                    annotate_stats_mma_pointplot(l_stats_to_annotate)\n",
    "                elif select_plot.value in [1, 2, 3]:\n",
    "                    annotate_stats_mma_violinplot(l_stats_to_annotate)\n",
    "                else:\n",
    "                    print(\"Function not implemented. Please go and annoy Dennis to finally do it\")\n",
    "\n",
    "            plt.ylabel(set_yaxis_label_text.value, fontsize=set_yaxis_label_fontsize.value, color=set_yaxis_label_color.value)\n",
    "            plt.xlabel(set_xaxis_label_text.value, fontsize=set_xaxis_label_fontsize.value, color=set_xaxis_label_color.value)        \n",
    "\n",
    "            if set_yaxis_scaling_mode.value == 1:\n",
    "                plt.ylim(set_yaxis_lower_lim.value, set_yaxis_upper_lim.value)\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if save_plot == True:\n",
    "                plt.savefig('customized_plot.svg', dpi=300)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    # 3.3 Download button:        \n",
    "    def on_download_button_clicked(b):\n",
    "        global save_plot\n",
    "        if select_downloads.value == 0 or select_downloads.value == 2:\n",
    "            if select_test.value == 0:\n",
    "                df_individual_group_stats = get_individual_group_stats_for_download(False)\n",
    "                df_group_level_overview = get_group_level_stats_for_download()\n",
    "                df_pairwise_comparisons = d_main['summary']['pairwise_comparisons'].copy()\n",
    "\n",
    "            elif select_test.value == 2:\n",
    "                df_individual_group_stats = get_individual_group_stats_for_download(True)\n",
    "                df_group_level_overview = get_group_level_stats_for_download()\n",
    "                df_pairwise_comparisons = d_main['summary']['pairwise_comparisons'].copy()\n",
    "\n",
    "            with pd.ExcelWriter('statistic_results.xlsx') as writer:  \n",
    "                df_individual_group_stats.to_excel(writer, sheet_name='Individual group statistics')\n",
    "                df_group_level_overview.to_excel(writer, sheet_name='Whole-group statistics')\n",
    "                df_pairwise_comparisons.to_excel(writer, sheet_name='Pairwise comparisons')                \n",
    "\n",
    "        if select_downloads.value == 1 or select_downloads.value == 2:\n",
    "            save_plot = True\n",
    "            plotting_button.click()\n",
    "            save_plot = False\n",
    "\n",
    "\n",
    "    ###################################################################    \n",
    "\n",
    "\n",
    "    ###################################################################\n",
    "    # 4 Functions that create the individual widget elements:\n",
    "    # 4.1 Buttons:\n",
    "    def create_buttons():\n",
    "        global uploader, stats_button, plotting_button, download_button\n",
    "        uploader = widgets.FileUpload(accept=('.xlsx,.csv'), multiple=False)\n",
    "        stats_button = widgets.Button(description=\"Calculate stats\", icon='rocket')\n",
    "        plotting_button = widgets.Button(description='Plot the data', layout={'visibility': 'hidden'})\n",
    "        download_button = widgets.Button(description='Download', icon='file-download', layout={'visibility': 'hidden'})\n",
    "\n",
    "    # 4.2 Dropdown menus:\n",
    "    def create_dropdowns():\n",
    "        global select_test, select_plot, select_downloads\n",
    "        select_test = widgets.Dropdown(options=[('pairwise comparison of two or more independent samples', 0), ('Mixed_model_ANOVA', 2)], \n",
    "                                       value=0, description='Please select which test you want to perform:',\n",
    "                                       layout={'width': '700px'}, style={'description_width': 'initial'})\n",
    "\n",
    "        select_plot = widgets.Dropdown(options=[('something initial', 0)], value=0,\n",
    "                                       description='Please select which type of plot you want to create:',\n",
    "                                       layout={'width': '700px', 'visibility': 'hidden'}, style={'description_width': 'initial'})\n",
    "\n",
    "        select_downloads = widgets.Dropdown(options=[('statistical results only', 0), ('plot only', 1), ('both', 2)], value=1,\n",
    "                                       description='Please select what you would like to write to disk:',\n",
    "                                       layout={'width': '700px', 'visibility': 'hidden'}, style={'description_width': 'initial'})\n",
    "\n",
    "    # 4.3 Create all default widgets that allow customization of the stats annotations\n",
    "    #     and that don´t require any information about the data (e.g. how many groups)\n",
    "    def create_default_stats_annotation_widgets():\n",
    "        global set_distance_stars_to_brackets, set_distance_brackets_to_data, set_fontsize_stars\n",
    "        global set_linewidth_annotations, set_stars_fontweight_bold, set_annotate_all, select_bracket_no_bracket    \n",
    "\n",
    "        # How far will the annotation lines be shifted from the data? Calculates as: \n",
    "        # y_shift_annotation_line = max(data) * set_distance_brackets_to_data.value\n",
    "        set_distance_brackets_to_data = widgets.BoundedFloatText(description='Distance of the annotation bars to the graph',\n",
    "                                                                 style={'description_width': 'initial'}, value=0.1, min=0, max=1, \n",
    "                                                                 step=0.005, layout={'width':'initial'})\n",
    "\n",
    "        # Determines annotation_brackets_factor: 0 for 'No brackets', 1 for 'brackets'\n",
    "        # brackets_height = y_shift_annotation_line*0.5*annotation_brackets_factor\n",
    "        select_bracket_no_bracket = widgets.RadioButtons(options=['Brackets', 'No brackets'], \n",
    "                                                         value=('Brackets'), style={'description_width': 'initial'}, \n",
    "                                                         layout={'width': '300px', 'height': '50px'}, description='Annotation bar style:')\n",
    "\n",
    "        # How far will the annotation stars be shifted from the annotation lines? Calculates as:\n",
    "        # y_shift_annotation_text = y_shift_annotation_line + brackets_height + y_shift_annotation_line*0.5*set_distance_stars_to_brackets.value\n",
    "        set_distance_stars_to_brackets = widgets.BoundedFloatText(description='Distance of the stars to the annotation bars', \n",
    "                                                                  value=0.5, style={'description_width': 'initial'}, min=0, max=3, \n",
    "                                                                  step=0.05, layout={'width':'initial'})\n",
    "\n",
    "        set_fontsize_stars = widgets.BoundedFloatText(description='Fontsize of the stars', value=10, min=1, max=50, \n",
    "                                               style={'description_width': 'initial'}, layout={'width':'initial'})\n",
    "\n",
    "        set_linewidth_annotations = widgets.BoundedFloatText(description='Linewidth of the annotation bars', \n",
    "                                                        value=1.5, min=0, max=10, step=0.1, layout={'width':'initial'}, \n",
    "                                                        style={'description_width': 'initial'})\n",
    "\n",
    "        set_stars_fontweight_bold = widgets.Checkbox(description='Stars bold', value=False)\n",
    "\n",
    "        customize_stats_annotation_vbox = VBox([HBox([set_stars_fontweight_bold, select_bracket_no_bracket]),\n",
    "                                                set_distance_stars_to_brackets, set_distance_brackets_to_data, \n",
    "                                                set_fontsize_stars, set_linewidth_annotations]) \n",
    "\n",
    "        set_annotate_all = widgets.Checkbox(value=False, description='Annotate all', indent=False)\n",
    "\n",
    "        return customize_stats_annotation_vbox\n",
    "\n",
    "\n",
    "    # 4.4 Create elements that allow the customization of the plot\n",
    "    # 4.4.1 Create and arrange the main accordion that has to be expanded by the user to access customization elements.\n",
    "    #       Triggers several functions that in turn create and/or arrange the respective elements.\n",
    "    def create_accordion_to_customize_the_plot():\n",
    "        global expand_me_accordion, customization_accordion, select_annotations_vbox, customize_annotations_accordion\n",
    "\n",
    "        # Still missing: \n",
    "            # Optional annotation of within and between statistics for mma\n",
    "        customize_stats_annotation_vbox = create_default_stats_annotation_widgets()\n",
    "\n",
    "        # Create empty VBox that will be filled with checkboxes to select individual pairwise \n",
    "        # comparisons that shall be annotated, as soon as the data is specified (stats_button.click())\n",
    "        select_annotations_vbox = VBox([])\n",
    "\n",
    "        select_annotations_accordion = widgets.Accordion(children=[select_annotations_vbox])\n",
    "        select_annotations_accordion.set_title(0, 'Select individual comparisons for annotation')\n",
    "\n",
    "        customize_annotations_accordion = widgets.Accordion(children=[VBox([select_annotations_accordion, set_annotate_all]), \n",
    "                                                                      customize_stats_annotation_vbox],\n",
    "                                                           selected_index=None)\n",
    "\n",
    "        customize_annotations_accordion.set_title(0, 'Select which stats shall be annotated')\n",
    "        customize_annotations_accordion.set_title(1, 'Customize annotation features')\n",
    "\n",
    "        # Second accordion will contain widgets to customize the axes\n",
    "        customize_yaxis_vbox = create_vbox_y_axis()\n",
    "        customize_xaxis_vbox = create_vbox_x_axis()\n",
    "        customize_both_axes_hbox = create_hbox_both_axes()\n",
    "\n",
    "        customize_axes_accordion = widgets.Accordion(children=[customize_yaxis_vbox, customize_xaxis_vbox, customize_both_axes_hbox])\n",
    "        customize_axes_accordion.set_title(0, 'y-axis') \n",
    "        customize_axes_accordion.set_title(1, 'x-axis')\n",
    "        customize_axes_accordion.set_title(2, 'common features')\n",
    "\n",
    "        # Third accordion will contain widgets to customize the style of the plot (colorpalette, markersizes)\n",
    "            # Still missing:\n",
    "                # Plot size (2 sliders, x & y) to change fig_size [make sure violinplot annotation is still working for mma()]\n",
    "                    # e.g.: y_size=widgets.FloatSlider(description='Change the size of your plot.', value=1, min=0, max=10)\n",
    "                # Make sure set_marker_size only shows up if possible to change\n",
    "                # Plot title (+ size & color)\n",
    "                # Option to remove upper and right spines\n",
    "                # Set dpi\n",
    "                # Select (.png, .tif, .pdf)\n",
    "        customize_plot_features_hbox = create_customize_plot_features_hbox()\n",
    "\n",
    "        # Create the accordion that actually contains all widget-containing accordions and will become the only child of the main accordion\n",
    "        customization_accordion = widgets.Accordion(children=[customize_annotations_accordion, \n",
    "                                                              customize_axes_accordion, \n",
    "                                                              customize_plot_features_hbox], selected_index=None)\n",
    "\n",
    "        # Give the individual accordions titles that are displayed before dropdown is clicked\n",
    "        customization_accordion.set_title(0, 'Customize how statistics are annotated in the plot')\n",
    "        customization_accordion.set_title(1, 'Customize axes')\n",
    "        customization_accordion.set_title(2, 'Customize other features of the plot')\n",
    "\n",
    "        # Create the main accordion that contains all widgets to customize the plot and use selected_index=None to avoid dropdown by default\n",
    "        expand_me_accordion = widgets.Accordion(children=[customization_accordion], selected_index=None, continous_update=False, layout={'visibility': 'hidden'})\n",
    "        expand_me_accordion.set_title(0, 'Expand me to customize your plot!')\n",
    "\n",
    "\n",
    "    # 4.4.2 Customization axes:\n",
    "    # 4.4.2.1 Create an HBox that allows customization of the y-axis\n",
    "    def create_vbox_y_axis():\n",
    "        global set_yaxis_label_text, set_yaxis_label_fontsize, set_yaxis_label_color, set_yaxis_scaling_mode, set_yaxis_lower_lim, set_yaxis_upper_lim\n",
    "\n",
    "        set_yaxis_label_text = widgets.Text(value='data', placeholder='data', description='y-axis title:', layout={'width': 'auto'})\n",
    "        set_yaxis_label_fontsize = widgets.IntSlider(value=12, min=8, max=40, step=1, description='fontsize:')\n",
    "        set_yaxis_label_color = widgets.ColorPicker(concise=False, description='font color', value='#000000')\n",
    "        yaxis_hbox1 = HBox([set_yaxis_label_text, set_yaxis_label_fontsize, set_yaxis_label_color])\n",
    "\n",
    "        set_yaxis_scaling_mode = widgets.RadioButtons(description = 'Please select whether you want to use automatic or manual scaling of the yaxis:', \n",
    "                                                                  options=[('Use automatic scaling', 0), ('Use manual scaling', 1)],\n",
    "                                                                  value=0, layout={'width': '700px', 'height': '75px'}, style={'description_width': 'initial'})\n",
    "\n",
    "        set_yaxis_lower_lim = widgets.FloatText(value=0.0, description='lower limit:', style={'description_width': 'initial'})\n",
    "        set_yaxis_upper_lim = widgets.FloatText(value=0.0, description='upper limit:', style={'description_width': 'initial'})\n",
    "        yaxis_hbox2 = HBox([set_yaxis_lower_lim, set_yaxis_upper_lim])\n",
    "\n",
    "        return VBox([yaxis_hbox1, set_yaxis_scaling_mode, yaxis_hbox2])\n",
    "\n",
    "\n",
    "    # 4.4.2.2 Create an HBox that allows customization of the x-axis\n",
    "    def create_vbox_x_axis():\n",
    "        global set_xaxis_label_text, set_xaxis_label_fontsize, set_xaxis_label_color, set_xlabel_order, set_hue_order\n",
    "        set_xaxis_label_text = widgets.Text(value='group_IDs', placeholder='group_IDs', description='x-axis title:', layout={'width': 'auto'})\n",
    "        set_xaxis_label_fontsize = widgets.IntSlider(value=12, min=8, max=40, step=1, description='fontsize:')\n",
    "        set_xaxis_label_color = widgets.ColorPicker(concise=False, description='font color', value='#000000')\n",
    "        xaxis_hbox = HBox([set_xaxis_label_text, set_xaxis_label_fontsize, set_xaxis_label_color])\n",
    "\n",
    "        set_xlabel_order = widgets.Text(value='x label order', \n",
    "                                        placeholder='Specify the desired order of the x-axis labels with individual labels separated by a comma',\n",
    "                                        description='x-axis label order (separated by comma):', \n",
    "                                        layout={'width': '800px', 'visibility': 'hidden'},\n",
    "                                        style={'description_width': 'initial'})\n",
    "\n",
    "        set_hue_order = widgets.Text(value='hue order',\n",
    "                                     placeholder='Specify the desired group order with individual groups separated by a comma',\n",
    "                                     description='group order (separated by comma):',\n",
    "                                     layout={'width': '800px', 'visibility': 'hidden'},\n",
    "                                     style={'description_width': 'initial'})\n",
    "\n",
    "\n",
    "\n",
    "        return VBox([xaxis_hbox, set_xlabel_order, set_hue_order])\n",
    "\n",
    "\n",
    "    # 4.4.2.3 Create an HBox that allows customization of general axis features\n",
    "    def create_hbox_both_axes():\n",
    "        global set_axes_linewidth, set_axes_color, set_axes_tick_size\n",
    "        set_axes_linewidth = widgets.BoundedFloatText(value=1, min=0, max=40, description='Axes linewidth', \n",
    "                                               style={'description_width': 'initial'}, layout={'width': 'auto'})\n",
    "        set_axes_color = widgets.ColorPicker(concise=False, description='Axes and tick label color', \n",
    "                                             value='#000000', style={'description_width': 'initial'}, layout={'width': 'auto'})\n",
    "        set_axes_tick_size = widgets.BoundedFloatText(value=10, min=1, max=40, description='Tick label size', \n",
    "                                                style={'description_width': 'initial'}, layout={'width': 'auto'})\n",
    "        return HBox([set_axes_linewidth, set_axes_color, set_axes_tick_size])\n",
    "\n",
    "\n",
    "    # 4.4.3 Customize general features of the plot (like colors, size, ...)\n",
    "    def create_customize_plot_features_hbox():\n",
    "        global select_color_palettes, set_marker_size, select_palette_or_individual_color, group_colors_vbox\n",
    "        global plot_style_features_hbox, set_fig_width, set_fig_height, set_show_legend\n",
    "        select_palette_or_individual_color = widgets.RadioButtons(description = 'Please select a color code option and chose from the respective options below:', \n",
    "                                                                  options=[('Use a pre-defined palette', 0), ('Define colors individually', 1)],\n",
    "                                                                  value=0, layout={'width': '700px', 'height': '75px'}, style={'description_width': 'initial'})\n",
    "\n",
    "        select_color_palettes = widgets.Dropdown(options=['colorblind', 'Spectral', 'viridis', 'rocket', 'cubehelix'],\n",
    "                                 value='colorblind',\n",
    "                                 description='Select a color palette', \n",
    "                                 layout={'width': '350'},\n",
    "                                 style={'description_width': 'initial'})\n",
    "\n",
    "        set_show_legend = widgets.Checkbox(value=True, description='Show legend (if applicable):', style={'description_width': 'initial'})\n",
    "        set_marker_size = widgets.FloatText(value=5,description='marker size (if applicable):', style={'description_width': 'initial'})\n",
    "\n",
    "        optional_features_hbox = HBox([set_show_legend, set_marker_size])\n",
    "\n",
    "        # Empty VBox which will be filled as soon as groups are determined (stats_button.click())\n",
    "        group_colors_vbox = VBox([])\n",
    "\n",
    "        set_fig_width = widgets.FloatSlider(value=28, min=3, max=30, description='Figure width:', style={'description_width': 'inital'})\n",
    "        set_fig_height = widgets.FloatSlider(value=16, min=3, max=30, description='Figure height:', style={'description_width': 'inital'})\n",
    "        fig_size_hbox = HBox([set_fig_width, set_fig_height])\n",
    "\n",
    "        plot_style_features_vbox = VBox([select_palette_or_individual_color, HBox([select_color_palettes, group_colors_vbox]), fig_size_hbox, optional_features_hbox])\n",
    "        return plot_style_features_vbox\n",
    "\n",
    "\n",
    "    # 4.5 Create elements that are dependent on group information:\n",
    "    # 4.5.1 Create checkboxes to select individual comparisons that shall be annotated\n",
    "    # 4.5.1.1 Base-function: create and arrange checkboxes of all possible pairwise comparisons\n",
    "    def create_checkboxes_pairwise_comparisons():\n",
    "        # Create a checkbox for each pairwise comparison\n",
    "        l_checkboxes_temp = [widgets.Checkbox(value=False,description='{} vs. {}'.format(group1, group2)) \n",
    "                             for group1, group2 in list(itertools.combinations(l_groups, 2))]\n",
    "        # Arrange checkboxes in a HBoxes with up to 3 checkboxes per HBox\n",
    "        l_HBoxes = []\n",
    "        elem = 0\n",
    "        for i in range(int(len(l_checkboxes_temp)/3)):\n",
    "            l_HBoxes.append(HBox(l_checkboxes_temp[elem:elem+3]))\n",
    "            elem = elem + 3\n",
    "\n",
    "        if len(l_checkboxes_temp) % 3 != 0:\n",
    "            l_HBoxes.append(HBox(l_checkboxes_temp[elem:]))\n",
    "\n",
    "        # Arrange HBoxes in a VBox and select all as tuple to later place in empty placeholder (select_annotations_vbox)\n",
    "        checkboxes_to_add_temp = VBox(l_HBoxes).children[:]\n",
    "\n",
    "        return checkboxes_to_add_temp, l_checkboxes_temp \n",
    "\n",
    "\n",
    "    # 4.5.1.2 Create checkboxes taking session_id into account (for mixed-model ANOVA):\n",
    "    def create_checkboxes_pairwise_comparisons_mma():\n",
    "        annotate_session_stats_accordion = widgets.Accordion(children=[], selected_index=None)\n",
    "        l_all_checkboxes = []\n",
    "\n",
    "        for session_id in l_sessions:\n",
    "            checkboxes_to_add_temp, l_checkboxes_temp = create_checkboxes_pairwise_comparisons()\n",
    "            # Little complicated, but neccessary since the output of create_checkboxes_pairwise_comparisons() is a tuple\n",
    "            checkboxes_to_add_temp_vbox = VBox([])\n",
    "            checkboxes_to_add_temp_vbox.children = checkboxes_to_add_temp_vbox.children + checkboxes_to_add_temp\n",
    "            annotate_session_stats_accordion.children = annotate_session_stats_accordion.children + (checkboxes_to_add_temp_vbox, )\n",
    "            l_all_checkboxes = l_all_checkboxes + [(session_id, elem) for elem in l_checkboxes_temp]\n",
    "\n",
    "        for i in range(len(list(annotate_session_stats_accordion.children))):\n",
    "            annotate_session_stats_accordion.set_title(i, l_sessions[i])\n",
    "\n",
    "        return VBox([annotate_session_stats_accordion]).children[:], l_all_checkboxes\n",
    "\n",
    "\n",
    "    # 4.5.2 Create color pickers that allow the user to specify a color for each group\n",
    "    def create_group_color_pickers():\n",
    "        for group_id in l_groups:\n",
    "            set_group_color = widgets.ColorPicker(concise=False, description = group_id, style={'description_width': 'initial'})\n",
    "            group_colors_vbox.children = group_colors_vbox.children + (set_group_color, )\n",
    "\n",
    "\n",
    "    # 4.5.3 Specify the group order string:\n",
    "    def create_group_order_text():\n",
    "        if select_test.value == 0:\n",
    "            for group_id in l_groups:\n",
    "                if l_groups.index(group_id) == 0:\n",
    "                    l_xlabel_string = group_id\n",
    "                else:\n",
    "                    l_xlabel_string = l_xlabel_string + ', {}'.format(group_id)\n",
    "            set_xlabel_order.value = l_xlabel_string\n",
    "            set_xlabel_order.layout.visibility = 'visible'\n",
    "\n",
    "        elif select_test.value == 2:\n",
    "            for session_id in l_sessions:\n",
    "                if l_sessions.index(session_id) == 0:\n",
    "                    l_xlabel_string = session_id\n",
    "                else:\n",
    "                    l_xlabel_string = l_xlabel_string + ', {}'.format(session_id)\n",
    "            set_xlabel_order.value = l_xlabel_string\n",
    "            set_xlabel_order.layout.visibility = 'visible'\n",
    "\n",
    "            for group_id in l_groups:\n",
    "                if l_groups.index(group_id) == 0:\n",
    "                    l_hue_string = group_id\n",
    "                else:\n",
    "                    l_hue_string = l_hue_string + ', {}'.format(group_id)\n",
    "            set_hue_order.value = l_hue_string\n",
    "            set_hue_order.layout.visibility = 'visible'        \n",
    "\n",
    "    def create_ylims():\n",
    "        if df[data_col].min() < 0:\n",
    "            set_yaxis_lower_lim.value = round(df[data_col].min() + df[data_col].min()*0.1, 2)\n",
    "        else:\n",
    "            set_yaxis_lower_lim.value = round(df[data_col].min() - df[data_col].min()*0.1, 2)\n",
    "\n",
    "        if df[data_col].max() < 0:\n",
    "            set_yaxis_upper_lim.value = round(df[data_col].max() - df[data_col].max()*0.1, 2)\n",
    "        else:\n",
    "            set_yaxis_upper_lim.value = round(df[data_col].max() + df[data_col].max()*0.1, 2)\n",
    "\n",
    "    ###################################################################    \n",
    "\n",
    "\n",
    "    ###################################################################\n",
    "    # 5 Specify the layout of the widget and define the launch function\n",
    "    # 5.1 Top level widget layout\n",
    "    def top_level_layout():\n",
    "        global stats_widget\n",
    "\n",
    "        create_accordion_to_customize_the_plot()\n",
    "        create_dropdowns()\n",
    "        create_buttons()\n",
    "\n",
    "        # Bind the on_button_clicked functions to the respective buttons:\n",
    "        stats_button.on_click(on_stats_button_clicked)\n",
    "        plotting_button.on_click(on_plotting_button_clicked) \n",
    "        download_button.on_click(on_download_button_clicked)\n",
    "\n",
    "        # Layout of the remaining elements\n",
    "        first_row = HBox([uploader])\n",
    "        second_row = HBox([select_test, stats_button])\n",
    "        third_row = HBox([select_plot, plotting_button])\n",
    "        third_row_extension = HBox([expand_me_accordion])\n",
    "        fourth_row = HBox([select_downloads, download_button])\n",
    "\n",
    "        stats_widget = VBox([first_row, second_row, third_row, third_row_extension, fourth_row])\n",
    "\n",
    "\n",
    "    # 5.2 Launch function\n",
    "    def launch():\n",
    "        global output\n",
    "        # Configure the layout:\n",
    "        top_level_layout()\n",
    "        # Define the output\n",
    "        output = widgets.Output()\n",
    "        # Display the widget:\n",
    "        display(stats_widget, output)\n",
    "\n",
    "    ###################################################################    \n",
    "\n",
    "\n",
    "    ###################################################################\n",
    "    # 6 Functions to process the statistical data for download:\n",
    "    # 6.1 Calculate individual group statistics:\n",
    "    def calculate_individual_group_stats(d, key):\n",
    "        group_data = d_main[key]['data']\n",
    "        d['means'].append(np.mean(group_data))\n",
    "        d['medians'].append(np.median(group_data))\n",
    "        d['stddevs'].append(np.std(group_data))\n",
    "        d['stderrs'].append(np.std(group_data) / math.sqrt(group_data.shape[0]))\n",
    "        d['tests'].append('Shapiro-Wilk')\n",
    "        d['test_stats'].append(d_main[key]['normality_full'].iloc[0,0])\n",
    "        d['pvals'].append(d_main[key]['normality_full'].iloc[0,1])\n",
    "        d['bools'].append(d_main[key]['normality_full'].iloc[0,2])\n",
    "        return d\n",
    "\n",
    "\n",
    "    # 6.2 Create the DataFrame:\n",
    "    def get_individual_group_stats_for_download(include_sessions):\n",
    "        d_individual_group_stats = {'means': [],\n",
    "                                    'medians': [],\n",
    "                                    'stddevs': [],\n",
    "                                    'stderrs': [],\n",
    "                                    'tests': [],\n",
    "                                    'test_stats': [], \n",
    "                                    'pvals': [], \n",
    "                                    'bools': []}\n",
    "\n",
    "        l_for_index = []\n",
    "\n",
    "        if include_sessions == False:\n",
    "            # for independent samples:\n",
    "            for group_id in l_groups:\n",
    "                d_individual_group_stats = calculate_individual_group_stats(d_individual_group_stats, group_id)\n",
    "                l_for_index.append(group_id)\n",
    "            l_index = l_for_index\n",
    "        else:\n",
    "            # for mma:\n",
    "            for group_id in l_groups:\n",
    "                for session_id in l_sessions:\n",
    "                    d_individual_group_stats = calculate_individual_group_stats(d_individual_group_stats, (group_id, session_id))\n",
    "                    l_for_index.append((group_id, session_id))\n",
    "                l_index = pd.MultiIndex.from_tuples(l_for_index)\n",
    "\n",
    "        df_individual_group_stats = pd.DataFrame(data=d_individual_group_stats)\n",
    "\n",
    "        multi_index_columns = pd.MultiIndex.from_tuples([('Group statistics', 'Mean'), ('Group statistics', 'Median'), ('Group statistics', 'Standard deviation'), ('Group statistics', 'Standard error'),\n",
    "                                                 ('Test for normal distribution', 'Test'), ('Test for normal distribution', 'Test statistic'), ('Test for normal distribution', 'p-value'),\n",
    "                                                 ('Test for normal distribution', 'Normally distributed?')])\n",
    "\n",
    "        df_individual_group_stats.columns = multi_index_columns\n",
    "        df_individual_group_stats.index = l_index\n",
    "\n",
    "        return df_individual_group_stats\n",
    "\n",
    "\n",
    "    # 6.3 Group-level statistics:\n",
    "    def get_group_level_stats_for_download():\n",
    "        df_group_level_overview = pg.homoscedasticity([d_main[key]['data'] for key in d_main.keys() if key != 'summary'])\n",
    "        df_group_level_overview.index = [0]\n",
    "        df_group_level_overview.columns = pd.MultiIndex.from_tuples([('Levene', 'W statistic'), ('Levene', 'p value'), ('Levene', 'Equal variances?')])\n",
    "\n",
    "        df_group_level_overview[('', 'all normally distributed?')] = False\n",
    "        df_group_level_overview[('', 'critera for parametric test fulfilled?')] = False\n",
    "        df_group_level_overview[('', 'performed test')] = performed_test\n",
    "        df_group_level_overview[' '] = ''\n",
    "\n",
    "        df_group_statistics = d_main['summary']['group_level_statistic'].copy()\n",
    "\n",
    "        df_group_statistics.index = list(range(df_group_statistics.shape[0]))\n",
    "        df_group_statistics.columns = pd.MultiIndex.from_tuples([(performed_test, elem) for elem in df_group_statistics.columns])\n",
    "\n",
    "        df_group_level_overview = pd.concat([df_group_level_overview, df_group_statistics], axis=1)\n",
    "\n",
    "        return df_group_level_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b62177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
