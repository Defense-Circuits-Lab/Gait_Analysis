{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36ae279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies if not done already\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox, HBox, interactive\n",
    "import math\n",
    "import matplotlib.image as img\n",
    "import cv2\n",
    "from IPython.display import clear_output, display\n",
    "from tkinter import Tk, filedialog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6effd3ea",
   "metadata": {},
   "source": [
    "This notebook consists of the following classes:\n",
    "\n",
    "    class maze corner\n",
    "    class basics\n",
    "    class bottom_cam\n",
    "    class gui\n",
    "        class processing_gui\n",
    "        class bc_gui\n",
    "        class maze_corner_gui\n",
    "\n",
    "    class side_cams\n",
    "    class bottom_cams\n",
    "    class defish\n",
    "    class session\n",
    "    class main\n",
    "\n",
    "All of the classes have an __init__ function, that requires at least the path of the target folder as argument. \n",
    "\n",
    "Name all of your .csv/.mp4 files strictly like this: \n",
    "                       210_F1-83_220518_OTT_bc\n",
    "                       Line_ID_Date_Paradigm_Camera                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c74159",
   "metadata": {},
   "outputs": [],
   "source": [
    "class main:\n",
    "    path = \"\" \n",
    "\n",
    "    def __init__(self):\n",
    "        gui.main_gui()\n",
    "        \n",
    "    def all_information_given(self):\n",
    "        self.l_sessions = [session(self.path, session_ID, self.bottom_cam_used, self.top_cam_used, self.side_cam_used) for session_ID in [elem[0:-7] for elem in os.listdir(self.path) if elem.endswith('.csv')]]\n",
    "        #in bc_gui (aufgerufen in session.bc) wird zum ersten mal cam definiert\n",
    "        \n",
    "    def get_maze_corners(self, cam):\n",
    "        if cam == \"bottom_cam\": #instead several if statements: list comprehention odeer loop over new l_cams?\n",
    "            self.l_maze_corners = [session.bc.mc for session in self.l_sessions]\n",
    "        elif cam == \"top_cam\":\n",
    "            pass\n",
    "        gui.maze_corner_gui(cam)\n",
    "                   \n",
    "    def get_processed_dfs(self, DLC_likelihood_threshold, framerate, cam):\n",
    "        if cam == \"bottom_cam\":\n",
    "            for session in self.l_sessions:\n",
    "                bottom_cam.get_processed_df(session.bc, DLC_likelihood_threshold, framerate)\n",
    "        elif cam ==\"top_cam\":\n",
    "            pass\n",
    "        elif cam == \"side_cam\":\n",
    "            pass        \n",
    "        gui.select_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c17da831",
   "metadata": {},
   "outputs": [],
   "source": [
    "class session(main):\n",
    "    def __init__(self, path, session_ID, bottom_cam_used, top_cam_used, side_cam_used):\n",
    "        self.path = path\n",
    "        self.bottom_cam_used = bottom_cam_used\n",
    "        self.top_cam_used = top_cam_used\n",
    "        self.side_cam_used = side_cam_used\n",
    "        self.session_ID = session_ID\n",
    "        #####[slicing range] muss angepasst werden an ending (bottom, top, side)\n",
    "        bc_csv = self.session_ID in set([elem[0:-7] for elem in os.listdir(path) if elem.endswith('_bottom.csv')])\n",
    "        bc_mp4 = self.session_ID in set([elem[0:-7] for elem in os.listdir(path) if elem.endswith('_bottom.mp4')]) \n",
    "        tc_csv = self.session_ID in set([elem[0:-7] for elem in os.listdir(path) if elem.endswith('_top.csv')])\n",
    "        tc_mp4 = self.session_ID in set([elem[0:-7] for elem in os.listdir(path) if elem.endswith('_top.mp4')])\n",
    "        sc_csv = self.session_ID in set([elem[0:-7] for elem in os.listdir(path) if elem.endswith('_side.csv')])\n",
    "        sc_mp4 = self.session_ID in set([elem[0:-7] for elem in os.listdir(path) if elem.endswith('_side.mp4')])\n",
    "        \n",
    "        if all([self.bottom_cam_used, self.top_cam_used, self.side_cam_used, bc_csv, bc_mp4, tc_csv, tc_mp4, sc_csv, sc_mp4]) or all([self.top_cam_used, self.side_cam_used, self.bottom_cam_used == False, tc_csv, tc_mp4, sc_csv, sc_mp4]) or all([self.bottom_cam_used , self.top_cam_used, self.side_cam_used == False, bc_csv , bc_mp4 , tc_csv , tc_mp4]) or all([self.bottom_cam_used , self.side_cam_used, self.top_cam_used==False, bc_csv , bc_mp4 , sc_csv , sc_mp4]) or all([self.bottom_cam_used, self.top_cam_used ==False, self.side_cam_used==False, bc_csv , bc_mp4]) or all([self.top_cam_used, self.bottom_cam_used==False, self.side_cam_used==False, tc_csv , tc_mp4]) or all([self.side_cam_used, self.bottom_cam_used==False, self.top_cam_used==False, sc_csv , sc_mp4]):\n",
    "            if bottom_cam_used:\n",
    "                bc_video_filename = session_ID + \"_bottom.mp4\"\n",
    "                bc_csv_filename = session_ID + \"_bottom.csv\"\n",
    "                bc_df = pd.read_csv(self.path + bc_csv_filename, skiprows=1, index_col=0, header=[0, 1])\n",
    "                self.bc = bottom_cam(self.path, self.session_ID, bc_df)\n",
    "                self.bc_gui = gui.bc_gui(self.path, self.session_ID)#change to main! and input list\n",
    "            \n",
    "            if top_cam_used:\n",
    "                tc_video_filename = session_ID + \"_top.mp4\"\n",
    "                tc_csv_filename = session_ID + \"_top.csv\"\n",
    "                tc_df = pd.read_csv(self.path + tc_csv_filename, skiprows=1, index_col=0, header=[0, 1])\n",
    "                #create top_cam object\n",
    "                \n",
    "            if side_cam_used:\n",
    "                sc_video_filename = session_ID + \"_side.mp4\"\n",
    "                sc_csv_filename = session_ID + \"_side.csv\"\n",
    "                sc_df = pd.read_csv(self.path + sc_csv_filename, skiprows=1, index_col=0, header=[0, 1])\n",
    "                #create side_cam object\n",
    "                \n",
    "        else:\n",
    "            missing_files_statement = \"\\nPlease name your files like as the following: 210_F1-83_220518_OTT_bottom.mp4 \\nLine_ID_Date_Paradigm_Camera_ending\"\n",
    "            if bottom_cam_used:\n",
    "                if bc_csv == False:\n",
    "                    print(\"Missing _bottom.csv file for session {} in {}!\".format(self.session_ID, self.path), missing_files_statement)\n",
    "                elif bc_mp4==False:\n",
    "                    print(\"Missing _bottom.mp4 file for session {} in {}!\".format(self.session_ID, self.path), missing_files_statement)\n",
    "            if top_cam_used:\n",
    "                if tc_csv ==False:\n",
    "                    print(\"Missing _top.csv file for session {} in {}!\".format(self.session_ID, self.path), missing_files_statement)\n",
    "                elif tc_mp4 == False:\n",
    "                    print(\"Missing top.mp4 file for session {} in {}!\".format(self.session_ID, self.path), missing_files_statement)\n",
    "            if side_cam_used:\n",
    "                if sc_csv == False:\n",
    "                    print(\"Missing _side.csv file for session {} in {}!\".format(self.session_ID, self.path), missing_files_statement)\n",
    "                if sc_mp4 == False:\n",
    "                    print(\"Missing side.mp4 file for session {} in {}!\".format(self.session_ID, self.path),missing_files_statement)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \"\"\"def get_session_averages(df):#?????\n",
    "        freezing_bout_count = df[('Freezing_bout', 'count')].unique().shape[0] - 1\n",
    "\n",
    "        if frezing_bout_count > 0:\n",
    "            df[('whole_session', 'percentage_time_spent_freezing')] = (df.loc[df[('Freezing_bout', '')] == True].shape[0] / df.shape[0]) * 100\n",
    "            df[('whole_session', 'median_freezing_bout_duration')] = np.nanmedian(df[('Freezing_bout', 'duration')].unique())\n",
    "            df[('whole_session', 'median_x_norm_cm_all_freezing_bouts')] = np.nanmedian(df[('Freezing_bout', 'mean_x_norm_cm')].unique())\n",
    "            df[('whole_session', 'median_y_norm_cm_all_freezing_bouts')] = np.nanmedian(df[('Freezing_bout', 'mean_y_norm_cm')].unique())\n",
    "        else:\n",
    "            df[('whole_session', 'percentage_time_spent_freezing')] = 0\n",
    "            df[('whole_session', 'median_freezing_bout_duration')] = np.NaN\n",
    "            df[('whole_session', 'median_x_norm_cm_all_freezing_bouts')] = np.NaN\n",
    "            df[('whole_session', 'median_y_norm_cm_all_freezing_bouts')] = np.NaN       \n",
    "\n",
    "        gait_disruption_bout_count = df[('GaitDisruption_bout', 'count')].unique().shape[0] - 1\n",
    "\n",
    "        if gait_disruption_bout_count > 0:\n",
    "            df[('whole_session', 'percentage_time_spent_gait_disrupted')] = (df.loc[df[('GaitDisruption_bout', '')] == True].shape[0] / df.shape[0]) * 100\n",
    "            df[('whole_session', 'median_gait_disruption_bout_duration')] = np.nanmedian(df[('GaitDisruption_bout', 'duration')].unique())\n",
    "            df[('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')] = np.nanmedian(df[('GaitDisruption_bout', 'mean_x_norm_cm')].unique())\n",
    "            df[('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts')] = np.nanmedian(df[('GaitDisruption_bout', 'mean_y_norm_cm')].unique())\n",
    "        else:\n",
    "            df[('whole_session', 'percentage_time_spent_gait_disrupted')] = 0\n",
    "            df[('whole_session', 'median_gait_disruption_bout_duration')] = np.NaN\n",
    "            df[('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')] = np.NaN\n",
    "            df[('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts')] = np.NaN\n",
    "\n",
    "        return df\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "620c7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottom_cam(session):\n",
    "    def __init__(self, path, session_ID, df):\n",
    "        self.path = path\n",
    "        self.session_ID = session_ID\n",
    "        self.df = df\n",
    "        self.mc = maze_corners(self.path, session_ID + \"_bc.mp4\")\n",
    "\n",
    "    def get_processed_df(self, DLC_likelihood_threshold, framerate):\n",
    "        self.l_processed_df = clean_df(self.path, self.df, self.mc, DLC_likelihood_threshold, framerate).df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d7d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class top_cam:\n",
    "    def __init__(self, path):\n",
    "        self.tc_properties = gui.maze_corner_gui(self.path)\n",
    "        \n",
    "    #def get_center_of_gravity(): nicht nötig wenn CoG in DLC gesetzt wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "168e62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class side_cam:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        #stitch()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5456523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class clean_df(session): #get_time, identify duplicates, exclude_frames, rotate, translate, normalize\n",
    "    def __init__(self, path, df, results, threshold, framerate):\n",
    "        self.path = path\n",
    "        self.threshold = threshold\n",
    "        self.framerate = framerate\n",
    "        self.results = results.results\n",
    "        self.l_bodyparts = [elem[0] for elem in df.columns[::3]]\n",
    "        df = self.get_time(df)\n",
    "        df = self.identify_duplicates(df)\n",
    "        df[('all', 'exclude')] = False\n",
    "        df = self.exclude_frames(df)\n",
    "        df = self.normalize_coordinates(df)\n",
    "        self.df = df\n",
    "        \n",
    "    def get_time(self, df):\n",
    "\n",
    "        df['time'] = np.NaN\n",
    "        df['time'] = df['EarRight'].index/self.framerate\n",
    "\n",
    "        return df\n",
    "        # in future version: check for NaN\n",
    "        \n",
    "    def identify_duplicates(self, df):\n",
    "        l_indices = list(df.index)\n",
    "        l_unique_indices = list(set(l_indices))\n",
    "\n",
    "        if len(l_indices) != len(l_unique_indices):\n",
    "            l_duplicates = []\n",
    "            for index in l_unique_indices:\n",
    "                if l_indices.count(index) > 1:\n",
    "                    l_duplicates.append(index)\n",
    "            df.loc[l_duplicates, ('all', 'exclude')] = True\n",
    "\n",
    "        return df\n",
    "\n",
    "    def exclude_frames(self, df):\n",
    "        \"\"\"excludes frames where the likelihood of correct tracking is lower than the threshold\"\"\"\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            df.loc[:, (bodypart, 'exclude')] = False\n",
    "            df.loc[df[bodypart]['likelihood'] < self.threshold, (bodypart, 'exclude')] = True\n",
    "            df.loc[df[('all', 'exclude')] == True, (bodypart, 'exclude')] = True\n",
    "        return df\n",
    "    \n",
    "    def rotate(self, xy, theta):\n",
    "        cos_theta, sin_theta = math.cos(theta), math.sin(theta)\n",
    "\n",
    "        return (\n",
    "            xy[0] * cos_theta - xy[1] * sin_theta,\n",
    "            xy[0] * sin_theta + xy[1] * cos_theta\n",
    "        )\n",
    "\n",
    "    def translate(self, xy, offset):\n",
    "        return xy[0] + offset[0], xy[1] + offset[1]\n",
    "\n",
    "\n",
    "    def normalize_coordinates(self, df):##### changed it!!! \n",
    "        # Extract all reference information - ???\n",
    "\n",
    "        length = self.results['length']\n",
    "        width = self.results['width']\n",
    "        offset_to_standard = (-self.results['offset_x'], -self.results['offset_y'])\n",
    "        offset_from_standard = (self.results['offset_x'], self.results['offset_y'])\n",
    "        theta_to_standard = -self.results['theta']\n",
    "\n",
    "\n",
    "        maze_length_in_cm = 50\n",
    "        length_in_px = length\n",
    "        cm_per_px = maze_length_in_cm/length_in_px\n",
    "\n",
    "        for bodypart in self.l_bodyparts: #removed + ['CenterOfGravity'] since we will label it in DLC\n",
    "            df[(bodypart, 'x_norm')] = self.translate(self.rotate((df[(bodypart,'x')], df[(bodypart,'y')]), theta_to_standard), offset_to_standard)[0]\n",
    "            df[(bodypart, 'y_norm')] = self.translate(self.rotate((df[(bodypart,'x')], df[(bodypart,'y')]), theta_to_standard), offset_to_standard)[1]\n",
    "            df[(bodypart, 'x_norm_cm')] = 3 - (df[(bodypart, 'x_norm')] * cm_per_px)\n",
    "            df[(bodypart, 'y_norm_cm')] = 50 - (df[(bodypart, 'y_norm')] * cm_per_px)\n",
    "\n",
    "        return df    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24088076",
   "metadata": {},
   "source": [
    "class df_functions(bottom_cam, top_cam, side_cam):\n",
    "    def __init__(df, l_bodyparts, cam):\n",
    "        self.l_bodyparts = l_bodyparts\n",
    "        self.cam = cam\n",
    "    \n",
    "    def get_speed_and_rolling_speed(df):\n",
    "        for bodypart in l_bodyparts:\n",
    "            # Create columns\n",
    "            df[(bodypart, 'speed_px_per_s')] = np.NaN\n",
    "            df[(bodypart, 'rolling_speed_px_per_s')] = np.NaN\n",
    "\n",
    "            # Calculate speed\n",
    "            # Calculates speed from time passed & distance moved in reference to previous frame (ignoring all frames that are marked as to be excluded)\n",
    "            # Limiation: since we have to exclude some frames, these calculations are not made frame by frame (yet for most)\n",
    "            df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'speed_px_per_s')] = (((df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'x')].diff()**2                                                                                                        + df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'y')].diff()**2)**(1/2)) \n",
    "                                                                                                                             / df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), 'time'].diff())\n",
    "            df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'rolling_speed_px_per_s')] = df.loc[df[('all', 'exclude')] == False, (bodypart, 'speed_px_per_s')].rolling(5, min_periods=3, center=True).mean()\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def get_direction(df): #used Snout instead of EarLeft & EarRight (less secure parameter?, but better suitable for BottomCam?)\n",
    "            #could also synchronize with top Cam data and use direction from there\n",
    "        df[('moving_towards_maze_end', '')] = False\n",
    "        df.loc[(df[('Snout', 'y_norm')] < df[('CenterOfGravity', 'y_norm')]), ('moving_towards_maze_end', '')] = True\n",
    "        return df\n",
    "    \n",
    "    def get_immobility(df):\n",
    "        \"\"\"determine for individual bodyparts and whole head if they are immobile, add the information into the 'immobility' coulmn as boolean value\n",
    "        input: d_extracted_files[mouse_ID]['exponential']['processed_DataFrame']\n",
    "        output: d_extracted_files[mouse_ID]['exponential']['processed_DataFrame'][bodypart]['immobility']\"\"\"\n",
    "\n",
    "        for bodypart in l_bodyparts:\n",
    "            # create 'immobility' column and set base value to false\n",
    "            df.loc[ :, (bodypart, 'immobility')] = False\n",
    "            df.loc[df[(bodypart,'rolling_speed_px_per_s')] < immobility_threshold, (bodypart, 'immobility')] = True\n",
    "        return df\n",
    "        print('get_immobility is completed')\n",
    "        \n",
    "        def get_gait_disruption_bouts(df):\n",
    "            df[('GaitDisruption_bout', '')] = False\n",
    "            df[('GaitDisruption_bout', 'count')] = np.NaN\n",
    "            df[('GaitDisruption_bout', 'duration')] = np.NaN\n",
    "            df[('GaitDisruption_bout', 'mean_x_norm_cm')] = np.NaN\n",
    "            df[('GaitDisruption_bout', 'mean_y_norm_cm')] = np.NaN\n",
    "            df[('GaitDisruption_bout', 'direction_bool')] = ''\n",
    "            df[('GaitDisruption_bout', 'direction_mean')] = np.NaN\n",
    "\n",
    "\n",
    "            l_timesteps = []\n",
    "            for i in range(self.framerate):\n",
    "                l_timesteps.append(i/self.framerate)\n",
    "\n",
    "            time_gait_disruption = self.find_nearest(np.asarray(l_timesteps), TARGET_TIME_GAIT_DISRUPTION)\n",
    "            frames_difference = l_timesteps.index(time_gait_disruption)\n",
    "\n",
    "            gait_disruption_threshold_reached = df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].iloc[np.where(np.round(df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].diff(frames_difference).values, 7) == round(time_gait_disruption, 7))[0]].values\n",
    "\n",
    "            # could still throw an error if only a single frame, because of slicing to find first and last index of each interval?    \n",
    "            if gait_disruption_threshold_reached.shape[0] > 0:\n",
    "                indices = np.asarray(df.loc[df['time'].isin(gait_disruption_threshold_reached)].index)\n",
    "                lower_end = (indices+1)[:-1]\n",
    "                upper_end = indices[1:]\n",
    "                mask = lower_end < upper_end\n",
    "                mask_last = np.concatenate([mask, np.array([True])])\n",
    "                mask_first = np.concatenate([np.array([True]), mask])\n",
    "\n",
    "                last_value_of_intervals = indices[mask_last]\n",
    "                first_value_of_intervals = indices[mask_first]\n",
    "                # Since this is only the first value that matches the criterion, we have to substract the corresponding frames \n",
    "                # where the criterion was already fulfilled, to get the actual first index of the interval:\n",
    "                first_value_of_intervals = first_value_of_intervals-l_timesteps.index(self.find_nearest(np.asarray(l_timesteps), TARGET_TIME_GAIT_DISRUPTION))\n",
    "\n",
    "                interval_ranges = np.column_stack([first_value_of_intervals,last_value_of_intervals])\n",
    "\n",
    "                frames_prior_to_interval_start = l_timesteps.index(self.find_nearest(np.asarray(l_timesteps), TIME_OF_GAIT_BEFORE_DISRUPT))\n",
    "                bout_count = 0\n",
    "\n",
    "                if interval_ranges.shape[0] > 0:\n",
    "                    for first_idx, last_idx in interval_ranges:\n",
    "                        start_idx_gait_check = first_idx - frames_prior_to_interval_start\n",
    "                        if df.loc[start_idx_gait_check:first_idx-1, 'all_freezing_bodyparts_immobile'].any() == False:\n",
    "                            bout_count = bout_count + 1\n",
    "                            bout_duration = (df.loc[last_idx, 'time'] - df.loc[first_idx, 'time'])[0]\n",
    "                            mean_pos_x_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'x_norm_cm')].mean()\n",
    "                            mean_pos_y_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'y_norm_cm')].mean()\n",
    "                            direction_bool = df.loc[first_idx:last_idx, ('moving_towards_maze_end', '')].all()\n",
    "                            direction_mean = df.loc[first_idx:last_idx, ('moving_towards_maze_end', '')].mean()\n",
    "\n",
    "                            df.loc[first_idx:last_idx, ('GaitDisruption_bout', '')] = True\n",
    "                            df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'count')] = bout_count\n",
    "                            df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'duration')] = bout_duration\n",
    "                            df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'mean_x_norm_cm')] = mean_pos_x_norm_cm\n",
    "                            df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'mean_y_norm_cm')] = mean_pos_y_norm_cm\n",
    "                            df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'direction_bool')] = direction_bool\n",
    "                            df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'direction_mean')] = direction_mean\n",
    "\n",
    "            return df\n",
    "        \n",
    "    def find_nearest(array, value):\n",
    "        array = np.asarray(array)\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "        return array[idx]\n",
    "\n",
    "    def get_freezing_bouts(df):\n",
    "        df[('Freezing_bout', '')] = False\n",
    "        df[('Freezing_bout', 'count')] = np.NaN\n",
    "        df[('Freezing_bout', 'duration')] = np.NaN\n",
    "        df[('Freezing_bout', 'mean_x_norm_cm')] = np.NaN\n",
    "        df[('Freezing_bout', 'mean_y_norm_cm')] = np.NaN\n",
    "\n",
    "        df['all_freezing_bodyparts_immobile'] = df[[('EarRight', 'immobility'), ('EarLeft', 'immobility'), ('CenterOfGravity', 'immobility')]].all(axis=1)\n",
    "\n",
    "        times_where_freezing_threshold_was_reached = df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].iloc[np.where(df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].diff(self.framerate).values == 1)[0]].values\n",
    "\n",
    "        # could still throw an error if only a single frame, because of slicing to find first and last index of each interval?\n",
    "        if times_where_freezing_threshold_was_reached.shape[0] > 0:\n",
    "            indices = np.asarray(df.loc[df['time'].isin(times_where_freezing_threshold_was_reached)].index)\n",
    "            lower_end = (indices+1)[:-1]\n",
    "            upper_end = indices[1:]\n",
    "            mask = lower_end < upper_end\n",
    "            mask_last = np.concatenate([mask, np.array([True])])\n",
    "            mask_first = np.concatenate([np.array([True]), mask])\n",
    "\n",
    "            last_value_of_intervals = indices[mask_last]\n",
    "            first_value_of_intervals = indices[mask_first]\n",
    "            # Since this is only the first value that matches the criterion, we have to substract the corresponding frames \n",
    "            # where the criterion was already fulfilled, to get the actual first index of the interval:\n",
    "            first_value_of_intervals = first_value_of_intervals-self.framerate\n",
    "\n",
    "            interval_ranges = np.column_stack([first_value_of_intervals,last_value_of_intervals])\n",
    "\n",
    "            bout_count = 0\n",
    "\n",
    "            if interval_ranges.shape[0] > 0:\n",
    "                for first_idx, last_idx in interval_ranges:\n",
    "                        bout_count = bout_count + 1\n",
    "                        bout_duration = (df.loc[last_idx, 'time'] - df.loc[first_idx, 'time'])[0]\n",
    "                        mean_pos_x_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'x_norm_cm')].mean()\n",
    "                        mean_pos_y_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'y_norm_cm')].mean()\n",
    "\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', '')] = True\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'count')] = bout_count\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'duration')] = bout_duration\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'mean_x_norm_cm')] = mean_pos_x_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'mean_y_norm_cm')] = mean_pos_y_norm_cm\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6e4ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maze_corners(bottom_cam, top_cam):    \n",
    "    def __init__(self, path, filename):\n",
    "        self.filename = filename\n",
    "        self.filepath = path + filename\n",
    "        self.cap = cv2.VideoCapture(self.filepath)\n",
    "        self.ret, self.frame = self.cap.read()\n",
    "        self.results = {}\n",
    "    \n",
    "    def rotate(self, xy, theta):\n",
    "        cos_theta, sin_theta = math.cos(theta), math.sin(theta)\n",
    "\n",
    "        return (\n",
    "            xy[0] * cos_theta - xy[1] * sin_theta,\n",
    "            xy[0] * sin_theta + xy[1] * cos_theta\n",
    "        )\n",
    "\n",
    "    def translate(self, xy, offset):\n",
    "        return xy[0] + offset[0], xy[1] + offset[1]\n",
    "\n",
    "    def f(self, x, y, length, width, degrees):\n",
    "        offset = (x, y)\n",
    "        corners = [(0, 0), (width, 0), (width, length), (0, length)]\n",
    "        rotated_and_shifted_corners = [self.translate(self.rotate(xy, math.radians(degrees)), offset) for xy in corners]\n",
    "\n",
    "        end_right_corner = list(rotated_and_shifted_corners[0]) + ['red']\n",
    "        end_left_corner = list(rotated_and_shifted_corners[1]) + ['orange']\n",
    "        start_left_corner = list(rotated_and_shifted_corners[2]) + ['cyan']\n",
    "        start_right_corner = list(rotated_and_shifted_corners[3]) + ['green']\n",
    "\n",
    "        fig = plt.figure(figsize=(18, 10))\n",
    "        gs = fig.add_gridspec(2, 4)\n",
    "\n",
    "        fig.add_subplot(gs[0:2, 0:2])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.ylim(0,self.frame.shape[0])\n",
    "        plt.xlim(0,self.frame.shape[1])\n",
    "\n",
    "        if len(self.results.keys()) > 0:\n",
    "            saved_current = 'saved'\n",
    "        else:\n",
    "            saved_current = 'missing'\n",
    "\n",
    "        plt.title('current file: {} (analysis {})'.format(self.filename, saved_current))\n",
    "\n",
    "        l_corners = [start_right_corner, start_left_corner, end_right_corner, end_left_corner]\n",
    "\n",
    "        for corner in l_corners:\n",
    "            plt.scatter(corner[0], corner[1], c=corner[2], s=100)\n",
    "\n",
    "        fig.add_subplot(gs[0, 2])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[0][0], l_corners[0][1], c=l_corners[0][2], s=100)\n",
    "        plt.xlim(l_corners[0][0]-25, l_corners[0][0]+25)\n",
    "        plt.ylim(l_corners[0][1]-25, l_corners[0][1]+25)\n",
    "        plt.title('start right corner')\n",
    "\n",
    "        fig.add_subplot(gs[0, 3])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[1][0], l_corners[1][1], c=l_corners[1][2], s=100)\n",
    "        plt.xlim(l_corners[1][0]-25, l_corners[1][0]+25)\n",
    "        plt.ylim(l_corners[1][1]-25, l_corners[1][1]+25)\n",
    "        plt.title('start left corner')\n",
    "\n",
    "        fig.add_subplot(gs[1, 2])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[2][0], l_corners[2][1], c=l_corners[2][2], s=100)\n",
    "        plt.xlim(l_corners[2][0]-25, l_corners[2][0]+25)\n",
    "        plt.ylim(l_corners[2][1]-25, l_corners[2][1]+25)\n",
    "        plt.title('end right corner')\n",
    "\n",
    "        fig.add_subplot(gs[1, 3])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[3][0], l_corners[3][1], c=l_corners[3][2], s=100)\n",
    "        plt.xlim(l_corners[3][0]-25, l_corners[3][0]+25)\n",
    "        plt.ylim(l_corners[3][1]-25, l_corners[3][1]+25)\n",
    "        plt.title('end left corner')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b694fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gui():\n",
    "    class main_gui(main):\n",
    "        def __init__(self):             \n",
    "            self.path = \"\"\n",
    "            folder_select = widgets.Button(description=\"Select folder\")\n",
    "            folder_select.on_click(self.select_folder)\n",
    "            \n",
    "            select_recording_modalities = widgets.Label(value=\"Select recording modalities\")\n",
    "            self.bottom_cam_check = widgets.Checkbox(\n",
    "                        value=False,\n",
    "                        description='Bottom Cam',\n",
    "                        disabled=False,\n",
    "                        indent=False)\n",
    "            self.top_cam_check = widgets.Checkbox(\n",
    "                        value=False,\n",
    "                        description='Top Cam',\n",
    "                        disabled=False,\n",
    "                        indent=False)\n",
    "            self.side_cam_check = widgets.Checkbox(\n",
    "                        value=False,\n",
    "                        description='Side Cam',\n",
    "                        disabled=False,\n",
    "                        indent=False)\n",
    "            \n",
    "            confirm_button = widgets.Button(description = \"Confirm Settings\")\n",
    "            confirm_button.on_click(self.confirm_settings)\n",
    "            \n",
    "            col0 = VBox([folder_select])\n",
    "            col1 = VBox([select_recording_modalities, self.bottom_cam_check, self.top_cam_check, self.side_cam_check])\n",
    "            col2 = VBox([confirm_button])\n",
    "            box = HBox([col0, col1, col2])\n",
    "            display(box)\n",
    "\n",
    "        def select_folder(self, b):\n",
    "            root = Tk()\n",
    "            root.withdraw()\n",
    "            root.call('wm', 'attributes', '.', '-topmost', True)\n",
    "            self.path = filedialog.askdirectory() + \"//\"\n",
    "            display(self.path)        \n",
    "            \n",
    "        def confirm_settings(self, b):\n",
    "            if self.path == \"\":\n",
    "                display(\"Set the path before continuing!\")\n",
    "            else:\n",
    "                main.bottom_cam_used = self.bottom_cam_check.value\n",
    "                main.top_cam_used = self.top_cam_check.value\n",
    "                main.side_cam_used = self.side_cam_check.value\n",
    "                main.path = self.path\n",
    "                main.all_information_given(main)\n",
    "        \n",
    "    class bc_gui(main):\n",
    "        def __init__(self):\n",
    "            #defish\n",
    "            self.cam = \"bottom_cam\"\n",
    "\n",
    "            #defish_button = widgets.Button(description=\"Removing Fisheye Effect\")\n",
    "            self.maze_corners_set = False\n",
    "            maze_corners_button = widgets.Button(description = \"Set maze corners\")\n",
    "            \n",
    "            #defish_button.on_click(self.get_defished_videos)\n",
    "            maze_corners_button.on_click(self.get_cam_properties)\n",
    "            \n",
    "            row0 = HBox([maze_corners_button])\n",
    "            box = VBox([row0])\n",
    "            \n",
    "            display(box)\n",
    "            \n",
    "        #def get_defished_videos(self):\n",
    "            \n",
    "        def get_cam_properties(self, b):\n",
    "            if self.maze_corners_set == False:\n",
    "                main.get_maze_corners(main, self.cam)\n",
    "                self.maze_corners_set = True\n",
    "    \n",
    "    class maze_corner_gui(main):\n",
    "        def __init__(self):\n",
    "            self.maze_corner_idx = 0\n",
    "            self.actualize()\n",
    "            self.create_gui()\n",
    "\n",
    "        def on_load_next_button_click(self, b):\n",
    "            if self.maze_corner_idx >= (len(main.l_maze_corners)-1):\n",
    "                print(\"Maze Corners for all videos set.\")\n",
    "                #check, whether all Maze Corners are saved to bc.mc.results\n",
    "                \n",
    "            else: \n",
    "                self.maze_corner_idx += 1\n",
    "                self.actualize()\n",
    "\n",
    "        def on_load_previous_button_click(self, b):\n",
    "            if self.maze_corner_idx <= 0:\n",
    "                print(\"Index out of range! Index has been set to 0.\")\n",
    "                self.maze_corner_idx = 0\n",
    "            else:\n",
    "                self.maze_corner_idx -= 1\n",
    "                self.actualize()\n",
    "\n",
    "        def actualize(self):\n",
    "            self.filename = main.l_maze_corners[self.maze_corner_idx].filename\n",
    "            self.filepath = main.l_maze_corners[self.maze_corner_idx].filepath\n",
    "            self.cap = cv2.VideoCapture(self.filepath)\n",
    "            self.ret, self.frame = self.cap.read()\n",
    "\n",
    "        def on_save_button_click(self, b):\n",
    "            main.l_maze_corners[self.maze_corner_idx].results[\"offset_x\"] = self.interactive_plot.children[0].value\n",
    "            main.l_maze_corners[self.maze_corner_idx].results[\"offset_y\"] = self.interactive_plot.children[1].value\n",
    "            main.l_maze_corners[self.maze_corner_idx].results[\"length\"] = self.interactive_plot.children[2].value\n",
    "            main.l_maze_corners[self.maze_corner_idx].results[\"width\"] = self.interactive_plot.children[3].value\n",
    "            main.l_maze_corners[self.maze_corner_idx].results[\"theta\"] = math.radians(self.interactive_plot.children[4].value)\n",
    "            # Save the results:??????????????????????????????????????????????????????????\n",
    "            #with open('reference_coordinates.p', 'wb') as fp:\n",
    "            #    pickle.dump(d_results, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "        def create_gui(self):\n",
    "            width, height = self.frame.shape[0], self.frame.shape[1]\n",
    "            slider_x = widgets.IntSlider(value=300, min=0, max=width, step=1, description='x offset')\n",
    "            slider_y = widgets.IntSlider(value=5, min=0, max=height, step=1, description='y offset')\n",
    "            slider_length = widgets.IntSlider(value=300, min=0, max=height, step=1)\n",
    "            slider_width = widgets.IntSlider(value=20, min=0, max=width, step=1)\n",
    "            slider_degrees = widgets.FloatSlider(value=0, min=0, max=90, step=0.1)\n",
    "\n",
    "            self.interactive_plot = interactive(main.l_maze_corners[self.maze_corner_idx].f, x=slider_x, y=slider_y, length=slider_length, width=slider_width, degrees=slider_degrees)\n",
    "\n",
    "            self.interactive_plot.children[-1].layout.height = '600px'\n",
    "\n",
    "            load_next_button = widgets.Button(description=\"Load next file\")\n",
    "            save_button = widgets.Button(description=\"Save settings\")\n",
    "            load_previous_button = widgets.Button(description=\"Load previous file\")\n",
    "\n",
    "            load_next_button.on_click(self.on_load_next_button_click)\n",
    "            load_previous_button.on_click(self.on_load_previous_button_click)\n",
    "            save_button.on_click(self.on_save_button_click)\n",
    "\n",
    "            col0 = VBox([load_next_button, save_button])\n",
    "            col1 = VBox([self.interactive_plot.children[0], self.interactive_plot.children[1]])\n",
    "            col2 = VBox([self.interactive_plot.children[2], self.interactive_plot.children[3]])\n",
    "            col3 = VBox([self.interactive_plot.children[4], load_previous_button])\n",
    "            box = HBox([col0, col1, col2, col3])\n",
    "            \n",
    "            display(box, self.interactive_plot.children[-1])\n",
    "            \n",
    "\n",
    "        def proceed_with_clean_df(self) \n",
    "            self.clean_df = False\n",
    "            clean_df_button = widgets.Button(description = \"Clean Dataframe for {}\".format(self.cam))\n",
    "            clean_df_button.on_click(self.get_processed_df)\n",
    "            self.likelihood_threshold_slider = widgets.FloatSlider(min=0, max=1, steps=0.01, value=0.75, description = \"Set the DLC likelihood threshold for {}!\".format(self.cam))\n",
    "            self.framerate_slider = widgets.IntSlider(min=0, max=200, value=30, description = \"Set the Framerate for {}!\".format(self.cam))\n",
    "            \n",
    "            row0 = HBox([clean_df_button, self.framerate_slider, self.likelihood_threshold_slider])\n",
    "            box = VBox([row0])\n",
    "            \n",
    "            display(box)\n",
    "\n",
    "            \n",
    "        def get_processed_df(self, b):\n",
    "            if self.clean_df == False:\n",
    "                DLC_likelihood_threshold = self.likelihood_threshold_slider.value\n",
    "                framerate = self.framerate_slider.value\n",
    "                main.clean_dataframe(main, DLC_likelihood_threshold, framerate)\n",
    "                self.clean_df = True\n",
    "            else:\n",
    "                print(\"Dataframe already cleaned\")\n",
    "            \n",
    "        class select_functions(main):\n",
    "            def __init__(self):\n",
    "                select_functions = widgets.Label(value=\"Select functions in which you're interested in\")\n",
    "                self.immobility_check = widgets.Checkbox(\n",
    "                            value=False,\n",
    "                            description='Immobility',\n",
    "                            disabled=False,\n",
    "                            indent=False)\n",
    "                self.gait_disruption_check = widgets.Checkbox(\n",
    "                            value=False,\n",
    "                            description='Gait Disruption',\n",
    "                            disabled=False,\n",
    "                            indent=False)\n",
    "                self.freezing_check = widgets.Checkbox(\n",
    "                            value=False,\n",
    "                            description='Freezing',\n",
    "                            disabled=False,\n",
    "                            indent=False)\n",
    "                self.Piro_Inken_check = widgets.Checkbox(\n",
    "                            value=False,\n",
    "                            description='Funktionen für Inken',\n",
    "                            disabled=False,\n",
    "                            indent=False)\n",
    "\n",
    "                confirm_selection_button = widgets.Button(description = \"Confirm Selection\")\n",
    "                confirm_button.on_click(self.confirm_selection)\n",
    "\n",
    "                col0 = VBox([select_functions, self.immobility_check, self.gait_disruption_check, self.freezing_check, self.Piro_Inken_check])\n",
    "                col1 = VBox([confirm_selection])\n",
    "                box = HBox([col0, col1])\n",
    "                display(box)\n",
    "            \n",
    "            def confirm_selection():\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1e25349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d873e1fb92a4ebfa633c606e7a7292e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Button(description='Select folder', style=ButtonStyle()),)), VBox(children=(Labe…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'F:/Konstantin/data/Coding/Dummy data//'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'F:/Konstantin/data/Coding/Dummy data//210_F1-66_220323_OTR_bot_bc.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36mgui.main_gui.confirm_settings\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     47\u001b[0m main\u001b[38;5;241m.\u001b[39mside_cam_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mside_cam_check\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m     48\u001b[0m main\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\n\u001b[1;32m---> 49\u001b[0m \u001b[43mmain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_information_given\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mmain.all_information_given\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_information_given\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_sessions \u001b[38;5;241m=\u001b[39m [session(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, session_ID, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbottom_cam_used, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_cam_used, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mside_cam_used) \u001b[38;5;28;01mfor\u001b[39;00m session_ID \u001b[38;5;129;01min\u001b[39;00m [elem[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath) \u001b[38;5;28;01mif\u001b[39;00m elem\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)]]\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_information_given\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_sessions \u001b[38;5;241m=\u001b[39m [\u001b[43msession\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbottom_cam_used\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_cam_used\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mside_cam_used\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m session_ID \u001b[38;5;129;01min\u001b[39;00m [elem[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath) \u001b[38;5;28;01mif\u001b[39;00m elem\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)]]\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36msession.__init__\u001b[1;34m(self, path, session_ID, bottom_cam_used, top_cam_used, side_cam_used)\u001b[0m\n\u001b[0;32m     17\u001b[0m bc_video_filename \u001b[38;5;241m=\u001b[39m session_ID \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_bc.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m bc_csv_filename \u001b[38;5;241m=\u001b[39m session_ID \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_bc.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 19\u001b[0m bc_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbc_csv_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbc \u001b[38;5;241m=\u001b[39m bottom_cam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_ID, bc_df)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbc_gui \u001b[38;5;241m=\u001b[39m gui\u001b[38;5;241m.\u001b[39mbc_gui(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_ID)\n",
      "File \u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'F:/Konstantin/data/Coding/Dummy data//210_F1-66_220323_OTR_bot_bc.csv'"
     ]
    }
   ],
   "source": [
    "a=main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b62177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77573202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3c42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f45ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class subjects:\n",
    "    \n",
    "    def __init__(self, subject_ID):\n",
    "        self.subject_ID = subject_ID\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e335f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7448ab97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ffa75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9346ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e0ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60971cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b15cc97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
