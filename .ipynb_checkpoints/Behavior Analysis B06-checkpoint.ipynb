{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36ae279",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox, HBox, interactive\n",
    "import math\n",
    "import matplotlib.image as img\n",
    "import cv2\n",
    "from IPython.display import clear_output, display\n",
    "from tkinter import Tk, filedialog\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6effd3ea",
   "metadata": {},
   "source": [
    "This notebook consists of the following classes:\n",
    "  \n",
    "    \n",
    "    class main\n",
    "    class subjects\n",
    "    class session\n",
    "    class side_cam\n",
    "    class bottom_cam\n",
    "    class top_cam\n",
    "    class maze corner\n",
    "    class clean_df\n",
    "    class Functions\n",
    "    class stats\n",
    "    class Bodypart\n",
    "    class Parameters\n",
    "    \n",
    "    class gui\n",
    "        class main_gui\n",
    "        class subject_gui\n",
    "        class bc_gui\n",
    "        class tc_gui\n",
    "        class sc_gui\n",
    "        class clean_df_gui\n",
    "        class select_functions\n",
    "        \n",
    "    class maze_corner_gui       \n",
    "    class stats_gui\n",
    "\n",
    "\n",
    "Name all of your .csv/.mp4/.avi files strictly like this: \n",
    "\n",
    "                        210_F1-83_220518_OTT_bottom\n",
    "                        211_F3-04_211123_OTR_top\n",
    "\n",
    "                        Line_ID_Date_Paradigm_Camera   \n",
    "                    \n",
    "Your framerate should not have decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c74159",
   "metadata": {},
   "outputs": [],
   "source": [
    "class main: \n",
    "    \"\"\"Main object contains overview over all files, subjects and common variable over a folder of files as specified by the path.\"\"\"\n",
    "\n",
    "    def __init__(self, path, dict_cams_used = {\"bottom_cam\": False, \"top_cam\": False, \"side_cam\": False}, gui_check = False):\n",
    "        #creates common variables\n",
    "        self.path = path\n",
    "        self.dict_cams_used = dict_cams_used\n",
    "        self.gui_check = gui_check        \n",
    "        \n",
    "        self.save_dict = {}\n",
    "        self.save_dict[\"path\"]=path\n",
    "        self.save_dict[\"dict_cams_used\"]=dict_cams_used\n",
    "\n",
    "        \n",
    "    def all_information_given(self):\n",
    "        #creates objects for all of the files in the chosen folder\n",
    "        self.l_session_IDs = np.unique(np.array([file for file in set ([elem[0:-11] for elem in os.listdir(self.path) if elem.endswith('bottom.csv')]+[elem[0:-8] for elem in os.listdir(self.path) if elem.endswith('top.csv')]+[elem[0:-9] for elem in os.listdir(self.path) if elem.endswith('side.csv')])])).tolist()\n",
    "        self.l_sessions = [session(session_ID, self.save_dict) for session_ID in self.l_session_IDs]\n",
    "        self.save_dict[\"sessions\"]={session.session_ID:session for session in self.l_sessions}\n",
    "        self.l_subject_IDs = np.unique(np.array([session.subject_ID for session in self.l_sessions])).tolist()\n",
    "        self.l_subjects = [subject(subject_ID, self.save_dict) for subject_ID in self.l_subject_IDs]\n",
    "        self.save_dict[\"subjects\"]={subject.subject_ID:subject for subject in self.l_subjects}\n",
    "        self.all_files_there = all([session.all_files_there for session in self.l_sessions])\n",
    "        self.save_dict[\"all_files_there\"] = self.all_files_there\n",
    "            \n",
    "    def subjects_to_groups(self, subject_group_dict, l_groups = []):\n",
    "        #provides each subject a subject_ID as in subject_group_dict\n",
    "        if self.all_files_there:\n",
    "            for subject in self.l_subjects:\n",
    "                subject.group_ID = subject_group_dict[subject.subject_ID]\n",
    "\n",
    "    def get_maze_corners(self):\n",
    "        #if top or bottom cam are used, this function creates the maze_corner annotation\n",
    "        self.l_maze_corners_bc = []\n",
    "        self.l_maze_corners_tc = []\n",
    "        if self.dict_cams_used[\"bottom_cam\"] & self.all_files_there:\n",
    "            self.l_maze_corners_bc = [session.bc.mc for session in self.l_sessions]\n",
    "        if self.dict_cams_used[\"top_cam\"] & self.all_files_there:\n",
    "            self.l_maze_corners_tc = [session.tc.mc for session in self.l_sessions]\n",
    "        \n",
    "        if self.dict_cams_used[\"bottom_cam\"] or self.dict_cams_used[\"top_cam\"]:\n",
    "            self.l_maze_corners = self.l_maze_corners_bc + self.l_maze_corners_tc\n",
    "            self.save_dict[\"l_maze_corners\"] = self.l_maze_corners\n",
    "            if gui.displayed == False:\n",
    "                display(gui.main_tab)\n",
    "                gui.displayed = True\n",
    "            maze_corner_gui(self.save_dict, self.gui_check)\n",
    "        else:\n",
    "            self.get_processed_dfs()\n",
    "                   \n",
    "    def get_processed_dfs(self, DLC_likelihood_threshold = 0.80, maze_length_in_cm = 50):\n",
    "        #processes the dataframes\n",
    "        for session in self.l_sessions:\n",
    "            self.save_dict[\"sessions\"][session.session_ID].dict_bodyparts = {}\n",
    "            if self.dict_cams_used[\"bottom_cam\"]:\n",
    "                session.bc.cleaned_df = clean_df(session.bc, self.save_dict, threshold = DLC_likelihood_threshold, maze_length_in_cm = maze_length_in_cm)\n",
    "                self.save_dict[\"sessions\"][session.session_ID].dict_bodyparts[\"bottom_cam\"] = session.bc.cleaned_df.dict_objects\n",
    "            if self.dict_cams_used[\"top_cam\"]:\n",
    "                session.tc.cleaned_df = clean_df(session.tc, self.save_dict, threshold = DLC_likelihood_threshold,maze_length_in_cm = maze_length_in_cm)\n",
    "                self.save_dict[\"sessions\"][session.session_ID].dict_bodyparts[\"top_cam\"] = session.tc.cleaned_df.dict_objects\n",
    "            if self.dict_cams_used[\"side_cam\"]:\n",
    "                #clean_df\n",
    "                pass\n",
    "        \n",
    "    def execute_functions(self, dict_selected_functions = {\"Anxiety\": False, \"Parkinson\": False}):\n",
    "        #calculates the target variables as chosen in dict_selected_functions\n",
    "        self.get_col_in_master_df_and_main_dataframe(dict_selected_functions)\n",
    "        for subject in self.l_subjects:\n",
    "            for session in subject.l_sessions:\n",
    "                session.master_df = Functions(subject, session, dict_selected_functions, self.save_dict).master_df\n",
    "                self.append_session_to_d_data(subject, session, dict_selected_functions)\n",
    "        if gui.displayed == False:\n",
    "            display(gui.main_tab)\n",
    "            gui.displayed = True\n",
    "        self.save_dict[\"d_data\"] = self.d_data\n",
    "        self.save_dict[\"dataframe\"]= self.dataframe\n",
    "        if self.gui_check:\n",
    "            stats_gui(dict_selected_functions, self.save_dict)\n",
    "        \n",
    "    def get_col_in_master_df_and_main_dataframe(self, dict_selected_functions):\n",
    "        #creates the master and main dataframe\n",
    "        self.d_data = {'subject_ID': [], 'group_ID': [], 'paradigm': [], 'trialnumber': [], }\n",
    "        self.col_in_master_df = [('subject_ID', ('subject_ID', '')),\n",
    "                    ('group_ID', ('group_ID', '')),\n",
    "                    ('paradigm', ('paradigm', '')),\n",
    "                    ('trialnumber', ('trialnumber', '')),\n",
    "                    ('time', ('time', '')),\n",
    "                    ('exclude', ('all', 'exclude')), \n",
    "                    ('CenterOfGravity_x_norm_cm', ('CenterOfGravity', 'x_norm_cm')),\n",
    "                    ('CenterOfGravity_y_norm_cm', ('CenterOfGravity', 'y_norm_cm')),                    \n",
    "                    ('CenterOfGravity_rolling_speed_px_per_s', ('CenterOfGravity', 'rolling_speed_px_per_s'))]\n",
    "        if dict_selected_functions[\"Anxiety\"]:              \n",
    "            d_data_anx = { 'count_freezing_bouts': [],\n",
    "                       'mean_freezing_bout_duration': [],\n",
    "                       'percentage_of_time_spent_freezing': [],\n",
    "                       'mean_freezing_bouts_y_position': [],\n",
    "                       'median_freezing_bouts_y_position': [],\n",
    "                       'wall_endzone_mean_freezing_bouts_y_position': [], \n",
    "                       'wall_endzone_median_freezing_bouts_y_position': [], \n",
    "                       'wall_endzone_stddev_freezing_bouts_y_position': [], \n",
    "                       'wall_endzone_count_freezing_bouts': [],}\n",
    "            self.d_data = self.d_data | d_data_anx\n",
    "            self.col_in_master_df.extend([('freezing', ('Freezing_bout', '')),\n",
    "                    ('freezing_bout_count', ('Freezing_bout', 'count')),\n",
    "                    ('freezing_bout_duration', ('Freezing_bout', 'duration')),\n",
    "                    ('freezing_bout_mean_x_norm_cm', ('Freezing_bout', 'mean_x_norm_cm')),\n",
    "                    ('freezing_bout_mean_y_norm_cm', ('Freezing_bout', 'mean_y_norm_cm')),\n",
    "                    ('Percentage_time_spent_freezing_session', ('whole_session', 'percentage_time_spent_freezing')),\n",
    "                    ('Median_freezing_bout_duration_session', ('whole_session', 'median_freezing_bout_duration')),\n",
    "                    ('Median_x_norm_cm_all_freezing_bouts_session', ('whole_session', 'median_x_norm_cm_all_freezing_bouts')),\n",
    "                    ('Median_y_norm_cm_all_freezing_bouts_session', ('whole_session', 'median_y_norm_cm_all_freezing_bouts'))])\n",
    "                      \n",
    "        if dict_selected_functions[\"Parkinson\"]:\n",
    "            d_data_pd =  {'count_gait_disruption_bouts_all': [],\n",
    "                       #'count_gait_disruption_bouts_in': [],\n",
    "                       #'count_gait_disruption_bouts_out': [],\n",
    "                       'mean_gait_disruption_bout_duration_all': [], \n",
    "                       #'mean_gait_disruption_bout_duration_in': [], \n",
    "                       #'mean_gait_disruption_bout_duration_out': [],\n",
    "                       'percentage_of_time_spent_gait_disrupted_all': [],\n",
    "                       'mean_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'mean_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'mean_gait_disruption_bouts_y_position_out': [], \n",
    "                       'median_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'median_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'median_gait_disruption_bouts_y_position_out': [], \n",
    "                       'wall_endzone_mean_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'wall_endzone_mean_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'wall_endzone_mean_gait_disruption_bouts_y_position_out': [],\n",
    "                       'wall_endzone_median_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'wall_endzone_median_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'wall_endzone_median_gait_disruption_bouts_y_position_out': [],\n",
    "                       'wall_endzone_stddev_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'wall_endzone_stddev_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'wall_endzone_stddev_gait_disruption_bouts_y_position_out': [],\n",
    "                       'wall_endzone_count_gait_disruption_bouts_all': [],\n",
    "                       #'wall_endzone_count_gait_disruption_bouts_in': [],\n",
    "                       #'wall_endzone_count_gait_disruption_bouts_out': [], \n",
    "                         }\n",
    "            self.d_data = self.d_data | d_data_pd\n",
    "            self.col_in_master_df.extend([('gaitdisruption', ('GaitDisruption_bout', '')),\n",
    "                    ('gaitdisruption_bout_count', ('GaitDisruption_bout', 'count')),\n",
    "                    ('gaitdisruption_bout_duration', ('GaitDisruption_bout', 'duration')),\n",
    "                    ('gaitdisruption_bout_mean_x_norm_cm', ('GaitDisruption_bout', 'mean_x_norm_cm')),\n",
    "                    ('gaitdisruption_bout_mean_y_norm_cm', ('GaitDisruption_bout', 'mean_y_norm_cm')),\n",
    "                    ('gaitdisruption_bout_direction_bool', ('GaitDisruption_bout', 'direction_bool')),\n",
    "                    ('gaitdisruption_bout_direction_mean', ('GaitDisruption_bout', 'direction_mean')),\n",
    "                    ('Percentage_time_spent_gaitdisrupted_session', ('whole_session', 'percentage_time_spent_gait_disrupted')),\n",
    "                    ('Median_gaitdisruption_bout_duration_session', ('whole_session', 'median_gait_disruption_bout_duration')),\n",
    "                    ('Median_x_norm_cm_all_gaitdisruption_bouts_session', ('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')),\n",
    "                    ('Median_y_norm_cm_all_gaitdisruption_bouts_session', ('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts'))])\n",
    "        self.save_dict[\"col_in_master_df\"] = self.col_in_master_df\n",
    "            \n",
    "    def append_session_to_d_data(self, subject, session, dict_selected_functions):\n",
    "        #appends data of each session to a dict containing all sessions\n",
    "            wall_end_position = 35 #in cm\n",
    "            \n",
    "            self.d_data['subject_ID'].append(session.subject_ID)\n",
    "            self.d_data['group_ID'].append(subject.group_ID)\n",
    "            self.d_data['paradigm'].append(session.paradigm)\n",
    "            self.d_data['trialnumber'].append(subject.trialnumber)\n",
    "            \n",
    "            if dict_selected_functions[\"Anxiety\"]: \n",
    "                self.d_data['count_freezing_bouts'].append(self.get_total_bount_count(session.master_df['freezing_bout_count'].unique()))\n",
    "                self.d_data['mean_freezing_bout_duration'].append(session.master_df['freezing_bout_duration'].mean())\n",
    "                self.d_data['percentage_of_time_spent_freezing'].append(session.master_df['Percentage_time_spent_freezing_session'].unique()[0])\n",
    "                self.d_data['mean_freezing_bouts_y_position'].append(session.master_df['freezing_bout_mean_y_norm_cm'].mean())\n",
    "                self.d_data['median_freezing_bouts_y_position'].append(session.master_df['freezing_bout_mean_y_norm_cm'].median())\n",
    "                \n",
    "                mean_pos_freezing, median_pos_freezing, std_dev_freezing, bout_count_freezing = self.get_fuzziness(session.master_df, wall_end_position, 10)\n",
    "                \n",
    "                self.d_data['wall_endzone_mean_freezing_bouts_y_position'].append(mean_pos_freezing)\n",
    "                self.d_data['wall_endzone_median_freezing_bouts_y_position'].append(median_pos_freezing)\n",
    "                self.d_data['wall_endzone_stddev_freezing_bouts_y_position'].append(std_dev_freezing)\n",
    "                self.d_data['wall_endzone_count_freezing_bouts'].append(bout_count_freezing)\n",
    "            \n",
    "            if dict_selected_functions[\"Parkinson\"]: \n",
    "                self.d_data['count_gait_disruption_bouts_all'].append(self.get_total_bount_count(session.master_df['gaitdisruption_bout_count'].unique()))\n",
    "                #self.d_data['count_gait_disruption_bouts_in'].append(self.get_total_bount_count(df_temp_in['gaitdisruption_bout_count'].unique()))\n",
    "                #self.d_data['count_gait_disruption_bouts_out'].append(self.get_total_bount_count(df_temp_out['gaitdisruption_bout_count'].unique()))\n",
    "\n",
    "\n",
    "                self.d_data['mean_gait_disruption_bout_duration_all'].append(session.master_df['gaitdisruption_bout_duration'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bout_duration_in'].append(df_temp_in['gaitdisruption_bout_duration'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bout_duration_out'].append(df_temp_out['gaitdisruption_bout_duration'].mean())\n",
    "\n",
    "\n",
    "                self.d_data['percentage_of_time_spent_gait_disrupted_all'].append(session.master_df['Percentage_time_spent_gaitdisrupted_session'].unique()[0])\n",
    "\n",
    "\n",
    "                self.d_data['mean_gait_disruption_bouts_y_position_all'].append(session.master_df['gaitdisruption_bout_mean_y_norm_cm'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bouts_y_position_in'].append(df_temp_in['gaitdisruption_bout_mean_y_norm_cm'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bouts_y_position_out'].append(df_temp_out['gaitdisruption_bout_mean_y_norm_cm'].mean())\n",
    "\n",
    "\n",
    "                self.d_data['median_gait_disruption_bouts_y_position_all'].append(session.master_df['gaitdisruption_bout_mean_y_norm_cm'].median())\n",
    "                #self.d_data['median_gait_disruption_bouts_y_position_in'].append(df_temp_in['gaitdisruption_bout_mean_y_norm_cm'].median())\n",
    "                #self.d_data['median_gait_disruption_bouts_y_position_out'].append(df_temp_out['gaitdisruption_bout_mean_y_norm_cm'].median())\n",
    "\n",
    "\n",
    "                mean_pos_gait_all, median_pos_gait_all, std_dev_gait_all, bout_count_gait_all = self.get_fuzziness(session.master_df, wall_end_position, 10)\n",
    "                #mean_pos_gait_in, median_pos_gait_in, std_dev_gait_in, bout_count_gait_in = self.get_fuzziness(df_temp_in, wall_end_position, 10)\n",
    "                #mean_pos_gait_out, median_pos_gait_out, std_dev_gait_out, bout_count_gait_out = self.get_fuzziness(df_temp_out, wall_end_position, 10)\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_mean_gait_disruption_bouts_y_position_all'].append(mean_pos_gait_all)\n",
    "                #self.d_data['wall_endzone_mean_gait_disruption_bouts_y_position_in'].append(mean_pos_gait_in)\n",
    "                #self.d_data['wall_endzone_mean_gait_disruption_bouts_y_position_out'].append(mean_pos_gait_out)\n",
    "\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_median_gait_disruption_bouts_y_position_all'].append(median_pos_gait_all)\n",
    "                #self.d_data['wall_endzone_median_gait_disruption_bouts_y_position_in'].append(median_pos_gait_in)\n",
    "                #self.d_data['wall_endzone_median_gait_disruption_bouts_y_position_out'].append(median_pos_gait_out)\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_stddev_gait_disruption_bouts_y_position_all'].append(std_dev_gait_all)\n",
    "                #self.d_data['wall_endzone_stddev_gait_disruption_bouts_y_position_in'].append(std_dev_gait_in)\n",
    "                #self.d_data['wall_endzone_stddev_gait_disruption_bouts_y_position_out'].append(std_dev_gait_out)\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_count_gait_disruption_bouts_all'].append(bout_count_gait_all)\n",
    "                #self.d_data['wall_endzone_count_gait_disruption_bouts_in'].append(bout_count_gait_in)\n",
    "                #self.d_data['wall_endzone_count_gait_disruption_bouts_out'].append(bout_count_gait_out)\n",
    "            \n",
    "            self.dataframe = pd.DataFrame(data = self.d_data)   \n",
    "            \n",
    "    def get_total_bount_count(self, uniques):\n",
    "        uniques = uniques[~np.isnan(uniques)]\n",
    "        return uniques.shape[0]\n",
    "\n",
    "    #was ist half_window_size, ist es fix auf 10?\n",
    "    def get_fuzziness(self, df_tmp, wall_end_position, half_window_size):\n",
    "        mean_pos = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                              (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].mean()\n",
    "\n",
    "        median_pos = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                                (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].median()\n",
    "\n",
    "        std_dev = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                             (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].std()\n",
    "\n",
    "        bout_count = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                                (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].shape[0]\n",
    "\n",
    "        if bout_count < 3:\n",
    "            mean_pos = np.NaN\n",
    "            std_dev = np.NaN    \n",
    "    \n",
    "        return mean_pos, median_pos, std_dev, bout_count\n",
    "        \n",
    "    def calculate_stats(self, output_path = \"\", selected_data_col = \"all\", stats_dict = {\"hue\": \"subject_ID\", \"independent_variable\": \"group_ID\"}, dict_selected_functions = {\"Anxiety\": True, \"Parkinson\": True}):\n",
    "        #calls the stats class based upon input\n",
    "        if isinstance(selected_data_col, list):\n",
    "            for stats_dict in selected_data_col:\n",
    "                stats.total_count_stats(self, stats_dict[\"data_col\"], stats_dict[\"independent_variable\"], stats_dict[\"hue\"], output_path)\n",
    "                if \"y_position\" in dict_stats[\"data_col\"]:\n",
    "                    stats.position_stats(self, stats_dict[\"data_col\"], stats_dict[\"independent_variable\"], stats_dict[\"hue\"], output_path)\n",
    "        elif isinstance(selected_data_col, str):\n",
    "            l_selected_data_col = []\n",
    "            if selected_data_col == \"basic\":\n",
    "                if dict_selected_functions[\"Anxiety\"]:\n",
    "                    l_selected_data_col.extend(['count_freezing_bouts', 'percentage_of_time_spent_freezing', 'mean_freezing_bouts_y_position'])\n",
    "                if dict_selected_functions[\"Parkinson\"]:\n",
    "                    l_selected_data_col.extend(['mean_gait_disruption_bouts_y_position_all'])\n",
    "            elif selected_data_col == \"all\":\n",
    "                l_selected_data_col = [key for key in self.save_dict[\"d_data\"].keys() if key not in set(['subject_ID', 'group_ID', 'paradigm', 'trialnumber'])]\n",
    "            for data_col in l_selected_data_col:\n",
    "                stats_dict[\"data_col\"] = data_col\n",
    "                stats.total_count_stats(self, stats_dict[\"data_col\"], stats_dict[\"independent_variable\"], stats_dict[\"hue\"], output_path)\n",
    "                if \"y_position\" in stats_dict[\"data_col\"]:\n",
    "                    stats.position_stats(self, stats_dict[\"data_col\"], stats_dict[\"independent_variable\"], stats_dict[\"hue\"], output_path)\n",
    "\n",
    "    def save(self, filename = 'data'):\n",
    "        with open('{}{}.pickle'.format(self.save_dict[\"path\"], filename), 'wb') as f:\n",
    "            pickle.dump(self.save_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5350d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class subject(main):\n",
    "    \"\"\"creates an object representing an individual subject\"\"\"\n",
    "    def __init__(self, subject_ID, save_dict):\n",
    "        self.subject_ID = subject_ID\n",
    "        self.l_sessions = [save_dict[\"sessions\"][session] for session in save_dict[\"sessions\"].keys() if save_dict[\"sessions\"][session].subject_ID == self.subject_ID]\n",
    "        #if len(self.l_sessions) > 1:\n",
    "            #self.l_paradigms = [session.paradigm for session in self.l_sessions]\n",
    "        self.dict_date_paradigm = {session.date:session.paradigm for session in self.l_sessions}\n",
    "        self.trialnumber = 1 #muss noch implementiert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c17da831",
   "metadata": {},
   "outputs": [],
   "source": [
    "class session(subject):\n",
    "    \"\"\"creates an object representing an individual session and checks, whether all the files are there\"\"\"\n",
    "    def __init__(self, session_ID, save_dict):\n",
    "        self.session_ID = session_ID\n",
    "        if 'OTE' in self.session_ID:\n",
    "            self.paradigm = 'exponential'\n",
    "        elif 'OTT'  in self.session_ID:\n",
    "            self.paradigm  = 'triangle'\n",
    "        elif 'OTR'  in self.session_ID:\n",
    "            self.paradigm = 'rectangle'\n",
    "        self.subject_ID_date = self.session_ID[0:-4] \n",
    "        #falls andere Paradigmen eingebaut werden, die nicht drei spaces in der Benennung haben, muss das geändert werden\n",
    "        #generisch: self.session_ID[self.session_ID.index('')+1:self.session_ID.index('')]\n",
    "        self.date = datetime.strptime(self.subject_ID_date[-6:], '%y%m%d')\n",
    "        self.subject_ID = self.subject_ID_date[0:-7]\n",
    "        bc_csv = self.session_ID in set([elem[0:-11] for elem in os.listdir(save_dict[\"path\"]) if elem.endswith('_bottom.csv')])\n",
    "        bc_vid = self.session_ID in set([elem[0:-11] for elem in os.listdir(save_dict[\"path\"]) if elem.endswith('_bottom.mp4') or elem.endswith('_bottom.avi')]) \n",
    "        tc_csv = self.session_ID in set([elem[0:-8] for elem in os.listdir(save_dict[\"path\"]) if elem.endswith('_top.csv')])\n",
    "        tc_vid = self.session_ID in set([elem[0:-8] for elem in os.listdir(save_dict[\"path\"]) if elem.endswith('_top.mp4') or elem.endswith('_top.avi')])\n",
    "        sc_csv = self.session_ID in set([elem[0:-9] for elem in os.listdir(save_dict[\"path\"]) if elem.endswith('_side.csv')])\n",
    "        sc_vid = self.session_ID in set([elem[0:-9] for elem in os.listdir(save_dict[\"path\"]) if elem.endswith('_side.mp4') or elem.endswith('_side.avi')])\n",
    "        \n",
    "        self.all_files_there = True\n",
    "        missing_files_statement = \"\\nPlease name your files as the following: 210_F1-83_220518_OTT_bottom.mp4 \\nLine_ID_Date_Paradigm_Camera_ending\"\n",
    "        if save_dict[\"dict_cams_used\"][\"bottom_cam\"]:\n",
    "            if bc_csv == False:\n",
    "                print(\"Missing _bottom.csv file for session {} in {}!\".format(self.session_ID, save_dict[\"path\"]), missing_files_statement)\n",
    "                self.all_files_there = False\n",
    "            elif bc_vid == False:\n",
    "                print(\"Missing _bottom.mp4 file for session {} in {}!\".format(self.session_ID, save_dict[\"path\"]), missing_files_statement)\n",
    "                self.all_files_there = False\n",
    "            else:\n",
    "                path_avi = save_dict[\"path\"] + self.session_ID + \"_bottom.AVI\"\n",
    "                path_mp4 = save_dict[\"path\"] + self.session_ID + \"_bottom.mp4\"\n",
    "                if os.path.exists(path_avi):\n",
    "                    video_path = path_avi\n",
    "                elif os.path.exists(path_mp4):\n",
    "                    video_path = path_mp4\n",
    "                bc_csv_filename = session_ID + \"_bottom.csv\"\n",
    "                bc_df = pd.read_csv(save_dict[\"path\"] + bc_csv_filename, skiprows=1, index_col=0, header=[0, 1])\n",
    "                self.bc = bottom_cam(save_dict, session_ID, bc_df, video_path)\n",
    "\n",
    "        if save_dict[\"dict_cams_used\"][\"top_cam\"]:\n",
    "            if tc_csv ==False:\n",
    "                print(\"Missing _top.csv file for session {} in {}!\".format(self.session_ID, save_dict[\"path\"]), missing_files_statement)\n",
    "                self.all_files_there = False\n",
    "            elif tc_vid == False:\n",
    "                print(\"Missing _top.mp4 file for session {} in {}!\".format(self.session_ID, save_dict[\"path\"]), missing_files_statement)\n",
    "                self.all_files_there = False\n",
    "            else:  \n",
    "                path_avi = save_dict[\"path\"] + self.session_ID + \"_top.AVI\"\n",
    "                path_mp4 = save_dict[\"path\"] + self.session_ID + \"_top.mp4\"\n",
    "                if os.path.exists(path_avi):\n",
    "                    video_path = path_avi\n",
    "                elif os.path.exists(path_mp4):\n",
    "                    video_path = path_mp4\n",
    "                tc_csv_filename = session_ID + \"_top.csv\"\n",
    "                tc_df = pd.read_csv(save_dict[\"path\"] + tc_csv_filename, skiprows=1, index_col=0, header=[0, 1])\n",
    "                self.tc = top_cam(save_dict, session_ID, tc_df, video_path)\n",
    "            \n",
    "        if save_dict[\"dict_cams_used\"][\"side_cam\"]:\n",
    "            if sc_csv == False:\n",
    "                print(\"Missing _side.csv file for session {} in {}!\".format(self.session_ID, save_dict[\"path\"]), missing_files_statement)\n",
    "                self.all_files_there = False\n",
    "            elif sc_vid == False:\n",
    "                print(\"Missing _side.mp4 file for session {} in {}!\".format(self.session_ID, save_dict[\"path\"]),missing_files_statement)\n",
    "                self.all_files_there = False\n",
    "            else:\n",
    "                path_avi = save_dict[\"path\"] + self.session_ID + \"_top.AVI\"\n",
    "                path_mp4 = save_dict[\"path\"] + self.session_ID + \"_top.mp4\"\n",
    "                if os.path.exists(path_avi):\n",
    "                    video_path = path_avi\n",
    "                elif os.path.exists(path_mp4):\n",
    "                    video_path = path_mp4\n",
    "                sc_csv_filename = session_ID + \"_side.csv\"\n",
    "                sc_df = pd.read_csv(save_dict[\"path\"] + sc_csv_filename, skiprows=1, index_col=0, header=[0, 1])\n",
    "                #create side_cam object\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "620c7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottom_cam(session):\n",
    "    \"\"\"creates an object containing the data for bottom cam recording modality\"\"\"\n",
    "    def __init__(self, save_dict, session_ID, bc_df, bc_video_path):\n",
    "        self.session_ID = session_ID\n",
    "        self.df = bc_df\n",
    "        self.video_path = bc_video_path\n",
    "        self.mc = maze_corners(self.video_path, self.session_ID)\n",
    "        video = imageio.get_reader(self.video_path,  'ffmpeg')\n",
    "        self.framerate = video.get_meta_data()[\"fps\"]\n",
    "        self.cam = \"bottom_cam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13d7d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class top_cam:\n",
    "    \"\"\"creates an object containing the data for top cam recording modality\"\"\"\n",
    "    def __init__(self, save_dict, session_ID, tc_df, tc_video_path):\n",
    "        self.session_ID = session_ID\n",
    "        self.df = tc_df\n",
    "        self.video_path = tc_video_path\n",
    "        self.mc = maze_corners(self.video_path, self.session_ID)\n",
    "        video = imageio.get_reader(self.video_path,  'ffmpeg')\n",
    "        self.framerate = video.get_meta_data()[\"fps\"]\n",
    "        self.cam = \"top_cam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168e62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class side_cam:\n",
    "    \"\"\"creates an object containing the data for side cam recording modality\"\"\"\n",
    "    def __init__(self, save_dict, session_ID):\n",
    "        self.cam = \"side_cam\"\n",
    "        pass\n",
    "        #stitch()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5456523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class clean_df(session):\n",
    "    \"\"\"creates an object that returns the cleaned dataframe after processing several functions\"\"\"\n",
    "    def __init__(self, session_cam_object, save_dict, threshold, maze_length_in_cm):        \n",
    "        self.threshold = threshold\n",
    "        self.framerate = session_cam_object.framerate\n",
    "        self.results = session_cam_object.mc.results #side cams geben noch keine results weil sie keine mc objects haben, brauchen aber noch welche\n",
    "        df = session_cam_object.df\n",
    "        self.session_ID = session_cam_object.session_ID\n",
    "        self.cam = session_cam_object.cam\n",
    "        self.l_bodyparts = [elem[0] for elem in df.columns[::3]]\n",
    "        \n",
    "        df = self.identify_duplicates(df)\n",
    "        df = self.exclude_frames(df)    \n",
    "        self.dict_objects = {}\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            x = df[bodypart][\"x\"]\n",
    "            y = df[bodypart][\"y\"]\n",
    "            exclude = df[bodypart][\"exclude\"]\n",
    "            self.dict_objects[bodypart] = Bodypart(session_ID = self.session_ID, cam = self.cam, x = x, y = y, exclude = exclude)\n",
    "        if \"CenterOfGravity\" not in set(self.l_bodyparts):\n",
    "            self.get_center_of_gravity()\n",
    "        if \"CenterOfGravity\" not in set(self.l_bodyparts):\n",
    "            print(\"error\")\n",
    "        for key in self.dict_objects.keys():\n",
    "            self.dict_objects[key].normalize_coordinates(results = self.results, maze_length_in_cm = maze_length_in_cm)\n",
    "        df = self.get_time(df)\n",
    "        self.dict_objects[\"parameters\"] = Parameters(session_ID = self.session_ID, cam = self.cam, time = df['time'])\n",
    "        \n",
    "    def get_time(self, df):\n",
    "        #appends the column time to the dataframe, calculated by index and framerate, therefore, the framerate should not have decimal places\n",
    "        df['time'] = np.NaN\n",
    "        df['time'] = df['EarRight'].index/self.framerate\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def identify_duplicates(self, df):\n",
    "        #checks for possible duplicates made by the DLC network and excludes them\n",
    "        l_indices = list(df.index)\n",
    "        l_unique_indices = list(set(l_indices))\n",
    "\n",
    "        if len(l_indices) != len(l_unique_indices):\n",
    "            l_duplicates = []\n",
    "            for index in l_unique_indices:\n",
    "                if l_indices.count(index) > 1:\n",
    "                    l_duplicates.append(index)\n",
    "            df.loc[l_duplicates, ('all', 'exclude')] = True\n",
    "        return df\n",
    "\n",
    "    def exclude_frames(self, df):\n",
    "        #excludes frames, where the likelihood is below a certain threshold\n",
    "        df[('all', 'exclude')] = False\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            df.loc[:, (bodypart, 'exclude')] = False\n",
    "            df.loc[df[bodypart]['likelihood'] < self.threshold, (bodypart, 'exclude')] = True\n",
    "            df.loc[df[('all', 'exclude')] == True, (bodypart, 'exclude')] = True\n",
    "        return df\n",
    "    \n",
    "    def get_center_of_gravity(self):\n",
    "        #calculates the center of gravity, if it is not labeled in DLC\n",
    "        x = (self.dict_objects[\"EarRight\"].x + self.dict_objects[\"EarLeft\"].x + self.dict_objects['TailBase'].x) / 3\n",
    "        y = (self.dict_objects['EarRight'].y + self.dict_objects['EarLeft'].y + self.dict_objects['TailBase'].y) / 3\n",
    "        exclude = self.dict_objects[\"EarRight\"].exclude.copy()\n",
    "        exclude[:] = False\n",
    "        ind = []\n",
    "        ind.append(self.dict_objects[\"EarRight\"].exclude.index[self.dict_objects[\"EarRight\"].exclude])\n",
    "        ind.append(self.dict_objects[\"EarLeft\"].exclude.index[self.dict_objects[\"EarLeft\"].exclude])\n",
    "        ind.append(self.dict_objects['TailBase'].exclude.index[self.dict_objects['TailBase'].exclude])\n",
    "        for n in ind:\n",
    "            exclude.iloc[n] = True\n",
    "        self.dict_objects[\"CenterOfGravity\"] = Bodypart(session_ID = self.session_ID, cam = self.cam, x = x, y = y, exclude = exclude)\n",
    "        self.l_bodyparts.append('CenterOfGravity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92ae4504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bodypart(clean_df):\n",
    "    def __init__(self, session_ID, cam, x, y, exclude):\n",
    "        self.session_ID = session_ID\n",
    "        self.cam = cam\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.exclude = exclude\n",
    "        \n",
    "    def rotate(self, xy, theta):\n",
    "        cos_theta, sin_theta = math.cos(theta), math.sin(theta)\n",
    "\n",
    "        return (xy[0] * cos_theta - xy[1] * sin_theta, xy[0] * sin_theta + xy[1] * cos_theta)\n",
    "\n",
    "    def translate(self, xy, offset):\n",
    "        \n",
    "        return xy[0] + offset[0], xy[1] + offset[1]\n",
    "\n",
    "\n",
    "    def normalize_coordinates(self, results, maze_length_in_cm):\n",
    "        #uses the functions rotate and translate to normalize the coordinates\n",
    "        length = results['length']\n",
    "        width = results['width']\n",
    "        offset_to_standard = (-results['offset_x'], -results['offset_y'])\n",
    "        offset_from_standard = (results['offset_x'], results['offset_y'])\n",
    "        theta_to_standard = -results['theta']\n",
    "\n",
    "        length_in_px = length\n",
    "        cm_per_px = maze_length_in_cm/length_in_px\n",
    "\n",
    "        self.x_norm = self.translate(self.rotate((self.x, self.y), theta_to_standard), offset_to_standard)[0]\n",
    "        self.y_norm = self.translate(self.rotate((self.x, self.y), theta_to_standard), offset_to_standard)[1]\n",
    "        self.x_norm_cm = self.x_norm * cm_per_px\n",
    "        self.y_norm_cm = self.y_norm * cm_per_px\n",
    "        \n",
    "        self.get_df()\n",
    "    \n",
    "    def get_df(self):\n",
    "        data={\"exclude\": self.exclude, \"x_norm_cm\": self.x_norm_cm, \"y_norm_cm\": self.y_norm_cm, \"x\": self.x, \"y\": self.y, \"x_norm\": self.x_norm, \"y_norm\": self.y_norm}\n",
    "        self.df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c41e092",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters(clean_df):\n",
    "    def __init__(self, session_ID, cam, time):\n",
    "        self.session_ID = session_ID\n",
    "        self.cam = cam\n",
    "        self.time = pd.DataFrame(data=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4374cea1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3985894690.py, line 72)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [11]\u001b[1;36m\u001b[0m\n\u001b[1;33m    +\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Functions(bottom_cam, top_cam, side_cam):\n",
    "    \"\"\"class that returns the dataframe appended with the chosen target variables after calling several functions and combines different recording modalities\"\"\"\n",
    "    immobility_threshold = 16\n",
    "\n",
    "    min_freezing_duration = 1\n",
    "\n",
    "    TIME_OF_GAIT_BEFORE_DISRUPT = 0.5\n",
    "    TARGET_TIME_GAIT_DISRUPTION = 0.2\n",
    "    \n",
    "    #self.save_dict[\"sessions\"][session_ID].dict_bodyparts[cam][bodypart]\n",
    "    \n",
    "    def __init__(self, subject, session, dict_selected_functions, save_dict):\n",
    "        #loops through the functions for each dataframe\n",
    "        self.session = session\n",
    "        self.session_ID = session.session_ID\n",
    "        self.subject = subject\n",
    "        self.subject_ID = subject.subject_ID\n",
    "        self.dict_selected_functions = dict_selected_functions\n",
    "        self.save_dict = save_dict\n",
    "        self.l_dfs = []\n",
    "        if save_dict[\"dict_cams_used\"][\"bottom_cam\"]:\n",
    "            dict_objects = session.bc.dict_objects\n",
    "            self.framerate = session.bc.framerate\n",
    "            \n",
    "            df = self.get_speed_and_rolling_speed(df)\n",
    "            df = self.get_immobility(df)\n",
    "            if dict_selected_functions[\"Anxiety\"]:\n",
    "                df = self.get_freezing_bouts(df)\n",
    "                df = self.get_freezing_avg(df)\n",
    "            if dict_selected_functions[\"Parkinson\"]:\n",
    "                df = self.get_direction_bc(df)\n",
    "                df = self.get_gait_disruption_bouts(df)\n",
    "                df = self.get_gait_disruption_avg(df)\n",
    "            self.l_dfs.append(df)\n",
    "            \n",
    "        if save_dict[\"dict_cams_used\"][\"top_cam\"]:\n",
    "            dict_objects = session.tc.dict_objects\n",
    "            self.framerate = session.tc.framerate\n",
    "            df = self.get_speed_and_rolling_speed(df)\n",
    "            df = self.get_immobility(df)\n",
    "            if dict_selected_functions[\"Anxiety\"]:\n",
    "                df = self.get_freezing_bouts(df)\n",
    "                df = self.get_freezing_avg(df)\n",
    "            if dict_selected_functions[\"Parkinson\"]:\n",
    "                df = self.get_direction_tc(df)\n",
    "                df = self.get_gait_disruption_bouts(df)\n",
    "                df = self.get_gait_disruption_avg(df)\n",
    "            self.l_dfs.append(df)\n",
    "            \n",
    "            \n",
    "        if save_dict[\"dict_cams_used\"][\"side_cam\"]:\n",
    "            self.l_bodyparts = save_dict[\"dict_bodyparts\"][\"side_cam\"]\n",
    "            self.framerate = session.sc.framerate\n",
    "            \n",
    "            self.l_dfs.append(df)\n",
    "        \n",
    "        self.combined_df = self.combine_cam_dfs()\n",
    "        self.combined_df = self.add_metadata(self.combined_df)\n",
    "        self.master_df = self.get_master_df()\n",
    "                \n",
    "    \n",
    "    def get_speed_and_rolling_speed(self, df):\n",
    "        #calculates speed for the bodyparts\n",
    "        for bodypart in dict_objects.keys():\n",
    "            if bodypart != \"time\":\n",
    "                bodypart.df.loc[ :, 'speed_px_per_s'] = np.NaN\n",
    "                bodypart.df.loc[ :, 'rolling_speed_px_per_s'] = np.NaN\n",
    "\n",
    "                # Limitation: since we have to exclude some frames, these calculations are not made frame by frame\n",
    "                bodypart.df.loc[bodypart.df[\"exclude\"] == False, 'speed_px_per_s'] = (((df.loc[(df[(bodypart, 'exclude')] == False), (bodypart, 'x')].diff()**2 + df.loc[(df[(bodypart, 'exclude')] == False), (bodypart, 'y')].diff()**2)**(1/2)) \n",
    "                                                                                                                             / df.loc[(df[(bodypart, 'exclude')] == False), 'time'].diff())\n",
    "            +\n",
    "                bodypart.df.loc[bodypart.df[\"exclude\"] == False, 'rolling_speed_px_per_s'] = df.loc[df[('all', 'exclude')] == False, (bodypart, 'speed_px_per_s')].rolling(5, min_periods=3, center=True).mean()\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def get_direction_bc(self, df): \n",
    "        #calculates the direction of the animal and appends the dataframe by a direction column\n",
    "        #used Snout instead of EarLeft & EarRight (less secure parameter?, but better suitable for BottomCam?)\n",
    "            #could also synchronize with top Cam data and use direction from there\n",
    "        df[('moving_towards_maze_end', '')] = False\n",
    "        df.loc[(df[('Snout', 'y_norm')] < df[('TailBase', 'y_norm')]), ('moving_towards_maze_end', '')] = True\n",
    "        #df.loc[(df[('Snout', 'y_norm')] < df[('CenterOfGravity', 'y_norm')]), ('moving_towards_maze_end', '')] = True\n",
    "        return df\n",
    "    \n",
    "    def get_direction_tc(self, df):\n",
    "        #calculates the direction of the animal and appends the dataframe by a direction column\n",
    "        df[('moving_towards_maze_end', '')] = False\n",
    "        df.loc[(df[('EarRight', 'y_norm')] < df[('CenterOfGravity', 'y_norm')]) & (df[('EarLeft', 'y_norm')] < df[('CenterOfGravity', 'y_norm')]), ('moving_towards_maze_end', '')] = True\n",
    "        return df\n",
    "    \n",
    "    def get_direction_sc(self, df):\n",
    "        pass\n",
    "    \n",
    "    def get_immobility(self, df):\n",
    "        #checks for immobility\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            df.loc[ :, (bodypart, 'immobility')] = False\n",
    "            df.loc[df[(bodypart,'rolling_speed_px_per_s')] < self.immobility_threshold, (bodypart, 'immobility')] = True\n",
    "        return df\n",
    "        \n",
    "    def get_gait_disruption_bouts(self, df):\n",
    "        #checks for gait disruption bouts\n",
    "        df[('GaitDisruption_bout', '')] = False\n",
    "        df[('GaitDisruption_bout', 'count')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'duration')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'mean_x_norm_cm')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'mean_y_norm_cm')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'direction_bool')] = ''\n",
    "        df[('GaitDisruption_bout', 'direction_mean')] = np.NaN\n",
    "\n",
    "        if self.dict_selected_functions[\"Anxiety\"] == False:\n",
    "            df['all_freezing_bodyparts_immobile'] = df[[('EarRight', 'immobility'), ('EarLeft', 'immobility'), ('CenterOfGravity', 'immobility')]].all(axis=1)\n",
    "        \n",
    "        l_timesteps = []\n",
    "        if self.framerate%1 != 0:\n",
    "            print(\"gait disruption bout calculations are invalid due to framerate with decimal places\")\n",
    "        for i in range(int(self.framerate)):\n",
    "            l_timesteps.append(i/self.framerate)\n",
    "\n",
    "        time_gait_disruption = self.find_nearest(np.asarray(l_timesteps), self.TARGET_TIME_GAIT_DISRUPTION)\n",
    "        frames_difference = l_timesteps.index(time_gait_disruption)\n",
    "\n",
    "        gait_disruption_threshold_reached = df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].iloc[np.where(np.round(df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].diff(frames_difference).values, 7) == round(time_gait_disruption, 7))[0]].values\n",
    "\n",
    "        # could still throw an error if only a single frame, because of slicing to find first and last index of each interval?    \n",
    "        if gait_disruption_threshold_reached.shape[0] > 0:\n",
    "            indices = np.asarray(df.loc[df['time'].isin(gait_disruption_threshold_reached)].index)\n",
    "            lower_end = (indices+1)[:-1]\n",
    "            upper_end = indices[1:]\n",
    "            mask = lower_end < upper_end\n",
    "            mask_last = np.concatenate([mask, np.array([True])])\n",
    "            mask_first = np.concatenate([np.array([True]), mask])\n",
    "\n",
    "            last_value_of_intervals = indices[mask_last]\n",
    "            first_value_of_intervals = indices[mask_first]\n",
    "            \n",
    "            first_value_of_intervals = first_value_of_intervals-l_timesteps.index(self.find_nearest(np.asarray(l_timesteps), self.TARGET_TIME_GAIT_DISRUPTION))\n",
    "\n",
    "            interval_ranges = np.column_stack([first_value_of_intervals,last_value_of_intervals])\n",
    "\n",
    "            frames_prior_to_interval_start = l_timesteps.index(self.find_nearest(np.asarray(l_timesteps), self.TIME_OF_GAIT_BEFORE_DISRUPT))\n",
    "            bout_count = 0\n",
    "\n",
    "            if interval_ranges.shape[0] > 0:\n",
    "                for first_idx, last_idx in interval_ranges:\n",
    "                    start_idx_gait_check = first_idx - frames_prior_to_interval_start\n",
    "                    if df.loc[start_idx_gait_check:first_idx-1, 'all_freezing_bodyparts_immobile'].any() == False:\n",
    "                        bout_count = bout_count + 1\n",
    "                        bout_duration = (df.loc[last_idx, 'time'] - df.loc[first_idx, 'time'])[0]\n",
    "                        mean_pos_x_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'x_norm_cm')].mean()\n",
    "                        mean_pos_y_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'y_norm_cm')].mean()\n",
    "                        direction_bool = df.loc[first_idx:last_idx, ('moving_towards_maze_end', '')].all()\n",
    "                        direction_mean = df.loc[first_idx:last_idx, ('moving_towards_maze_end', '')].mean()\n",
    "\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', '')] = True\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'count')] = bout_count\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'duration')] = bout_duration\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'mean_x_norm_cm')] = mean_pos_x_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'mean_y_norm_cm')] = mean_pos_y_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'direction_bool')] = direction_bool\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'direction_mean')] = direction_mean\n",
    "\n",
    "        return df\n",
    "        \n",
    "    def find_nearest(self, array, value):\n",
    "        array = np.asarray(array)\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "        return array[idx]\n",
    "\n",
    "    # für verschiedene Cams anpassen?\n",
    "    def get_freezing_bouts(self, df):\n",
    "        #checks for freezing bouts\n",
    "        df[('Freezing_bout', '')] = False\n",
    "        df[('Freezing_bout', 'count')] = np.NaN\n",
    "        df[('Freezing_bout', 'duration')] = np.NaN\n",
    "        df[('Freezing_bout', 'mean_x_norm_cm')] = np.NaN\n",
    "        df[('Freezing_bout', 'mean_y_norm_cm')] = np.NaN\n",
    "\n",
    "        df['all_freezing_bodyparts_immobile'] = df[[('EarRight', 'immobility'), ('EarLeft', 'immobility'), ('CenterOfGravity', 'immobility')]].all(axis=1)\n",
    "\n",
    "        times_where_freezing_threshold_was_reached = df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].iloc[np.where(df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].diff(self.framerate).values == 1)[0]].values\n",
    "\n",
    "        # could still throw an error if only a single frame, because of slicing to find first and last index of each interval?\n",
    "        if times_where_freezing_threshold_was_reached.shape[0] > 0:\n",
    "            indices = np.asarray(df.loc[df['time'].isin(times_where_freezing_threshold_was_reached)].index)\n",
    "            lower_end = (indices+1)[:-1]\n",
    "            upper_end = indices[1:]\n",
    "            mask = lower_end < upper_end\n",
    "            mask_last = np.concatenate([mask, np.array([True])])\n",
    "            mask_first = np.concatenate([np.array([True]), mask])\n",
    "\n",
    "            last_value_of_intervals = indices[mask_last]\n",
    "            first_value_of_intervals = indices[mask_first]\n",
    "\n",
    "            first_value_of_intervals = first_value_of_intervals-self.framerate\n",
    "\n",
    "            interval_ranges = np.column_stack([first_value_of_intervals,last_value_of_intervals])\n",
    "\n",
    "            bout_count = 0\n",
    "\n",
    "            if interval_ranges.shape[0] > 0:\n",
    "                for first_idx, last_idx in interval_ranges:\n",
    "                        bout_count = bout_count + 1\n",
    "                        bout_duration = (df.loc[last_idx, 'time'] - df.loc[first_idx, 'time'])[0]\n",
    "                        mean_pos_x_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'x_norm_cm')].mean()\n",
    "                        mean_pos_y_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'y_norm_cm')].mean()\n",
    "\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', '')] = True\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'count')] = bout_count\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'duration')] = bout_duration\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'mean_x_norm_cm')] = mean_pos_x_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'mean_y_norm_cm')] = mean_pos_y_norm_cm\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def get_freezing_avg(self, df):\n",
    "        #calculates the session average for freezing\n",
    "        freezing_bout_count = df[('Freezing_bout', 'count')].unique().shape[0] - 1\n",
    "\n",
    "        if freezing_bout_count > 0:\n",
    "            df[('whole_session', 'percentage_time_spent_freezing')] = (df.loc[df[('Freezing_bout', '')] == True].shape[0] / df.shape[0]) * 100\n",
    "            df[('whole_session', 'median_freezing_bout_duration')] = np.nanmedian(df[('Freezing_bout', 'duration')].unique())\n",
    "            df[('whole_session', 'median_x_norm_cm_all_freezing_bouts')] = np.nanmedian(df[('Freezing_bout', 'mean_x_norm_cm')].unique())\n",
    "            df[('whole_session', 'median_y_norm_cm_all_freezing_bouts')] = np.nanmedian(df[('Freezing_bout', 'mean_y_norm_cm')].unique())\n",
    "        else:\n",
    "            df[('whole_session', 'percentage_time_spent_freezing')] = 0\n",
    "            df[('whole_session', 'median_freezing_bout_duration')] = np.NaN\n",
    "            df[('whole_session', 'median_x_norm_cm_all_freezing_bouts')] = np.NaN\n",
    "            df[('whole_session', 'median_y_norm_cm_all_freezing_bouts')] = np.NaN       \n",
    "            \n",
    "        return df\n",
    "            \n",
    "    def get_gait_disruption_avg(self, df):\n",
    "        #calculates the session average for gait disruption\n",
    "        gait_disruption_bout_count = df[('GaitDisruption_bout', 'count')].unique().shape[0] - 1\n",
    "\n",
    "        if gait_disruption_bout_count > 0:\n",
    "            df[('whole_session', 'percentage_time_spent_gait_disrupted')] = (df.loc[df[('GaitDisruption_bout', '')] == True].shape[0] / df.shape[0]) * 100\n",
    "            df[('whole_session', 'median_gait_disruption_bout_duration')] = np.nanmedian(df[('GaitDisruption_bout', 'duration')].unique())\n",
    "            df[('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')] = np.nanmedian(df[('GaitDisruption_bout', 'mean_x_norm_cm')].unique())\n",
    "            df[('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts')] = np.nanmedian(df[('GaitDisruption_bout', 'mean_y_norm_cm')].unique())\n",
    "        else:\n",
    "            df[('whole_session', 'percentage_time_spent_gait_disrupted')] = 0\n",
    "            df[('whole_session', 'median_gait_disruption_bout_duration')] = np.NaN\n",
    "            df[('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')] = np.NaN\n",
    "            df[('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts')] = np.NaN\n",
    "\n",
    "        return df\n",
    "\n",
    "    def combine_cam_dfs(self):\n",
    "        #combines the data from different recording modalities. not yet implemented. requires class bodyparts\n",
    "        if len(self.l_dfs) == 1:\n",
    "            combined_df = self.l_dfs[0]\n",
    "            return combined_df\n",
    "        else:\n",
    "            #crazy function to combine input of all cams using self.l_dfs\n",
    "            #or the bodypart class\n",
    "            #return combined_df \n",
    "            pass\n",
    "        \n",
    "    def add_metadata(self, df):\n",
    "        #adds metadata to the dataframe\n",
    "        df['subject_ID'] = self.subject.subject_ID\n",
    "        df['group_ID'] = self.subject.group_ID\n",
    "        df['trialnumber'] = 1 #muss noch implementiert werden!\n",
    "        df['DateOfRecording'] = self.session.date\n",
    "        df['paradigm'] = self.session.paradigm\n",
    "        return df\n",
    "    \n",
    "    def get_master_df(self):\n",
    "        #combines all the information into a master_df as specified by col_in_precessed_df\n",
    "        d_for_master_df = {}\n",
    "\n",
    "        for key, col_in_processed_df in self.save_dict[\"col_in_master_df\"]:\n",
    "            d_for_master_df[key] = self.combined_df[col_in_processed_df].values\n",
    "\n",
    "        master_df = pd.DataFrame(data=d_for_master_df)\n",
    "        return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6e4ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maze_corners(bottom_cam, top_cam):   \n",
    "    \"\"\"creates an object representing the maze_corners\"\"\"\n",
    "    def __init__(self, filepath, session_ID):\n",
    "        self.filepath = filepath\n",
    "        cap = cv2.VideoCapture(self.filepath)\n",
    "        self.ret, self.frame = cap.read()\n",
    "        self.results = {}\n",
    "        cap.release()\n",
    "        self.session_ID = session_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b694fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gui():\n",
    "    \"\"\"represents the GUI\"\"\"\n",
    "    main_tab = widgets.Tab()   \n",
    "    tab_index = -1\n",
    "    displayed = False\n",
    "    \n",
    "    class main_gui(main):\n",
    "        \"\"\"creates a main object as specified by the path input and recording modalities\"\"\"\n",
    "        def __init__(self):\n",
    "            self.path = \"\"\n",
    "            folder_select = widgets.Button(description=\"Select folder\", layout=widgets.Layout(width=\"auto\"))\n",
    "            folder_select.on_click(self.select_folder)\n",
    "            \n",
    "            select_recording_modalities = widgets.Label(value=\"Select recording modalities\", layout=widgets.Layout(width=\"auto\"))\n",
    "            self.bottom_cam_check = widgets.Checkbox(value=False, description='Bottom Cam', layout=widgets.Layout(width=\"auto\"))\n",
    "            self.top_cam_check = widgets.Checkbox(value=False, description='Top Cam', layout=widgets.Layout(width=\"auto\"))\n",
    "            self.side_cam_check = widgets.Checkbox(value=False, description='Side Cam', disabled = True, layout=widgets.Layout(width=\"auto\"))\n",
    "            \n",
    "            confirm_button = widgets.Button(description = \"Confirm Settings\", layout=widgets.Layout(width=\"auto\"))\n",
    "            confirm_button.on_click(self.confirm_settings)\n",
    "            \n",
    "            col0 = VBox([folder_select])\n",
    "            col1 = VBox([select_recording_modalities, self.bottom_cam_check, self.top_cam_check, self.side_cam_check])\n",
    "            col2 = VBox([confirm_button])\n",
    "            box = HBox([col0, col1, col2])\n",
    "            gui.main_tab.children = [box]\n",
    "            gui.tab_index += 1\n",
    "            gui.main_tab.set_title(gui.tab_index, \"General Settings\")\n",
    "            display(gui.main_tab)\n",
    "            gui.displayed = True\n",
    "            gui.main_tab.selected_index = gui.tab_index\n",
    "\n",
    "        def select_folder(self, b):\n",
    "            root = Tk()\n",
    "            root.withdraw()\n",
    "            root.call('wm', 'attributes', '.', '-topmost', True)\n",
    "            self.path = filedialog.askdirectory() + \"/\"\n",
    "            display(self.path)        \n",
    "            \n",
    "        def confirm_settings(self, b):\n",
    "            if self.path == \"\":\n",
    "                display(\"Set the path before continuing!\")\n",
    "            else:\n",
    "                gui.a = main(path = self.path, dict_cams_used= {\"bottom_cam\": self.bottom_cam_check.value, \"top_cam\": self.top_cam_check.value, \"side_cam\": self.side_cam_check.value}, gui_check = True)\n",
    "                gui.a.all_information_given()\n",
    "                if gui.a.all_files_there == True:\n",
    "                    gui.subject_gui()\n",
    "                                    \n",
    "    class subject_gui(main):\n",
    "        \"\"\"allows to allocate subjects to groups\"\"\"\n",
    "        def __init__(self):\n",
    "            self.num_of_groups_dropdown = widgets.Dropdown(options=[1, 2, 3, 4, 5, 6, 7, 8], value=2, description='Choose, how many groups you have in your dataset', layout=widgets.Layout(width=\"auto\"), style={'description_width': 'auto'})\n",
    "            confirm_groups_button = widgets.Button(description='Confirm number of groups', layout=widgets.Layout(width=\"auto\"))\n",
    "            confirm_groups_button.on_click(self.name_groups)\n",
    "            row0 = HBox([self.num_of_groups_dropdown, confirm_groups_button])\n",
    "            box = VBox([row0])\n",
    "            gui.main_tab.children += (box, ) \n",
    "            gui.tab_index += 1\n",
    "            gui.main_tab.set_title(gui.tab_index, \"Subjects to groups\")\n",
    "            gui.main_tab.selected_index = gui.tab_index\n",
    "            \n",
    "        def name_groups(self, b):\n",
    "            self.num_of_groups = self.num_of_groups_dropdown.value\n",
    "            self.l_group_texts = [widgets.Text(value = 'group {}'.format(n), description='Name of group {}'.format(n), layout=widgets.Layout(width=\"auto\"), style = {'description_width': 'auto'}) for n in range (self.num_of_groups)]\n",
    "            name_subjects_button = widgets.Button(description = \"Confirm name of the groups\", layout=widgets.Layout(width=\"auto\"))\n",
    "            name_subjects_button.on_click(self.subjects_to_groups)\n",
    "            box = HBox([VBox(self.l_group_texts), name_subjects_button])\n",
    "            gui.main_tab.children[gui.tab_index].children += (box,)\n",
    "            \n",
    "        def subjects_to_groups(self, b):\n",
    "            l_subject_label = [widgets.Label(value=subject.subject_ID, layout=widgets.Layout(width=\"auto\")) for subject in gui.a.l_subjects]\n",
    "            \n",
    "            continue_button = widgets.Button(description = \"All subjects in the right group\", layout=widgets.Layout(width=\"auto\"))\n",
    "            continue_button.on_click(self.next_step)\n",
    "            \n",
    "            self.l_grid_children = []\n",
    "            for label in l_subject_label: \n",
    "                self.l_grid_children.append(label)\n",
    "                self.l_grid_children.append(widgets.ToggleButtons(options = [text.value for text in self.l_group_texts], layout=widgets.Layout(width=\"auto\")))\n",
    "            grid = widgets.GridBox(self.l_grid_children, layout=widgets.Layout(grid_template_columns=\"repeat(2, auto)\"))\n",
    "            box = HBox([grid, continue_button])\n",
    "            \n",
    "            gui.main_tab.children[gui.tab_index].children += (box,)\n",
    "            \n",
    "        def next_step(self, b):\n",
    "            l_groups = [self.l_group_texts[n].value for n in range(len(self.l_group_texts))]\n",
    "            gui.a.subjects_to_groups({self.l_grid_children[n].value:self.l_grid_children[n+1].value for n in range(len(self.l_grid_children)) if n%2==0}, l_groups)\n",
    "            gui.a.get_maze_corners()\n",
    "          \n",
    "    class bc_gui(main):\n",
    "        def __init__(self):\n",
    "            #defish\n",
    "            pass\n",
    "        \n",
    "    class tc_gui(main):\n",
    "        def __init__(self):\n",
    "            #?\n",
    "            pass\n",
    "        \n",
    "    class sc_gui(main):\n",
    "        def __init__(self):\n",
    "            # stitch\n",
    "            pass\n",
    "            \n",
    "    class select_functions(main):\n",
    "        \"\"\"allows to select the target variables, that will be analysed\"\"\"\n",
    "        def __init__(self):\n",
    "            select_functions = widgets.Label(value=\"Select functions in which you're interested in\", layout=widgets.Layout(width=\"auto\"), style = {'description_width': 'auto'})\n",
    "            self.anxiety_check = widgets.Checkbox(value=False, description='Anxiety', layout=widgets.Layout(width=\"auto\"))\n",
    "            self.parkinson_check = widgets.Checkbox(value=False, description='Parkinson', layout=widgets.Layout(width=\"auto\"))\n",
    "            \n",
    "            self.l_checkboxes = [self.anxiety_check, self.parkinson_check]\n",
    "\n",
    "            confirm_selection_button = widgets.Button(description = \"Confirm Selection\", layout=widgets.Layout(width=\"auto\"))\n",
    "            confirm_selection_button.on_click(self.confirm_selection)\n",
    "\n",
    "            col0 = VBox([select_functions, self.anxiety_check, self.parkinson_check])\n",
    "            col1 = VBox([confirm_selection_button])\n",
    "            box = HBox([col0, col1])\n",
    "            gui.main_tab.children += (box, ) \n",
    "            gui.tab_index += 1\n",
    "            gui.main_tab.set_title(gui.tab_index, \"Select Functions\")\n",
    "            gui.main_tab.selected_index = gui.tab_index\n",
    "\n",
    "        def confirm_selection(self, b):\n",
    "            l_selected_functions_values = [checkbox.value for checkbox in self.l_checkboxes]\n",
    "            l_selected_functions_keys = [checkbox.description for checkbox in self.l_checkboxes]\n",
    "            dict_selected_functions = {key:value for key,value in zip(l_selected_functions_keys,l_selected_functions_values)}\n",
    "            gui.a.execute_functions(dict_selected_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bc658d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maze_corner_gui(main):\n",
    "    \"\"\"creates the GUI for annotation maze corners, used in GUI as well as GUI-less usage\"\"\"\n",
    "    def __init__(self, save_dict, gui_check):\n",
    "        self.save_dict = save_dict\n",
    "        self.maze_corner_idx = 0\n",
    "        self.gui_check = gui_check\n",
    "        self.clean_df = False\n",
    "        self.create_gui()        \n",
    "        self.actualize()\n",
    "\n",
    "    def on_load_next_button_click(self, b):\n",
    "        if self.results_saved:\n",
    "            if self.maze_corner_idx >= (len(self.save_dict[\"l_maze_corners\"])-1):\n",
    "                if self.clean_df == False:\n",
    "                    print(\"Maze Corners for all videos set.\")\n",
    "                    if self.gui_check:\n",
    "                        gui.a.get_processed_dfs()\n",
    "                        self.clean_df = True\n",
    "                        print(\"Dataframes cleaned.\")\n",
    "                        gui.select_functions()\n",
    "            else: \n",
    "                self.maze_corner_idx += 1\n",
    "                self.actualize()\n",
    "        else:\n",
    "            display(\"Please save the settings before continuing!\")\n",
    "\n",
    "    def on_load_previous_button_click(self, b):\n",
    "        if self.maze_corner_idx <= 0:\n",
    "            display(\"Index out of range! Index has been set to 0.\")\n",
    "            self.maze_corner_idx = 0\n",
    "        else:\n",
    "            if self.results_saved:\n",
    "                self.maze_corner_idx -= 1\n",
    "                self.actualize()\n",
    "            else:\n",
    "                display(\"Please save the settings before continuing!\")\n",
    "                \n",
    "    def actualize(self):\n",
    "        self.results_saved = False\n",
    "        self.filepath = self.save_dict[\"l_maze_corners\"][self.maze_corner_idx].filepath\n",
    "        self.idx_slider.value = self.maze_corner_idx\n",
    "\n",
    "    def on_save_button_click(self, b):\n",
    "        self.save_dict[\"l_maze_corners\"][self.maze_corner_idx].results[\"offset_x\"] = self.interactive_plot.children[0].value\n",
    "        self.save_dict[\"l_maze_corners\"][self.maze_corner_idx].results[\"offset_y\"] = self.interactive_plot.children[1].value\n",
    "        self.save_dict[\"l_maze_corners\"][self.maze_corner_idx].results[\"length\"] = self.interactive_plot.children[2].value\n",
    "        self.save_dict[\"l_maze_corners\"][self.maze_corner_idx].results[\"width\"] = self.interactive_plot.children[3].value\n",
    "        self.save_dict[\"l_maze_corners\"][self.maze_corner_idx].results[\"theta\"] = math.radians(self.interactive_plot.children[4].value)\n",
    "        self.results_saved = True\n",
    "        \n",
    "    def create_gui(self):\n",
    "        height, width = self.save_dict[\"l_maze_corners\"][self.maze_corner_idx].frame.shape[0], self.save_dict[\"l_maze_corners\"][self.maze_corner_idx].frame.shape[1]\n",
    "        slider_x = widgets.IntSlider(value=300, min=0, max=width, step=1, description='x offset', continuous_update=False)\n",
    "        slider_y = widgets.IntSlider(value=5, min=0, max=height, step=1, description='y offset', continuous_update=False)\n",
    "        slider_length = widgets.IntSlider(value=height/2, min=0, max=width, step=1, continuous_update=False)\n",
    "        slider_width = widgets.IntSlider(value=width/20, min=0, max=height/7, step=1, continuous_update=False)\n",
    "        slider_degrees = widgets.FloatSlider(value=0, min=0, max=180, step=0.1, continuous_update=False)\n",
    "        self.idx_slider = widgets.IntSlider(value=0, min=0, max=len(self.save_dict[\"l_maze_corners\"]), step=1, continuous_update=False)\n",
    "        \n",
    "        self.interactive_plot = interactive(self.f, x=slider_x, y=slider_y, length=slider_length, width=slider_width, degrees=slider_degrees, idx = self.idx_slider)\n",
    "\n",
    "        self.interactive_plot.children[-1].layout.height = '600px'\n",
    "\n",
    "        load_next_button = widgets.Button(description=\"Load next file\", style = {'description_width': 'auto'})\n",
    "        save_button = widgets.Button(description=\"Save settings\", style = {'description_width': 'auto'})\n",
    "        load_previous_button = widgets.Button(description=\"Load previous file\", style = {'description_width': 'auto'})\n",
    "\n",
    "        load_next_button.on_click(self.on_load_next_button_click)\n",
    "        load_previous_button.on_click(self.on_load_previous_button_click)\n",
    "        save_button.on_click(self.on_save_button_click)\n",
    "\n",
    "        col0 = VBox([load_next_button, save_button])\n",
    "        col1 = VBox([self.interactive_plot.children[0], self.interactive_plot.children[1]])\n",
    "        col2 = VBox([self.interactive_plot.children[2], self.interactive_plot.children[3]])\n",
    "        col3 = VBox([self.interactive_plot.children[4], load_previous_button])\n",
    "        row0 = HBox([col0, col1, col2, col3])\n",
    "        box = VBox([row0, self.interactive_plot.children[-1]])\n",
    "\n",
    "        gui.main_tab.children += (box, ) \n",
    "        gui.tab_index += 1\n",
    "        gui.main_tab.set_title(gui.tab_index, \"Set Maze Corners\")\n",
    "        gui.main_tab.selected_index = gui.tab_index\n",
    "        \n",
    "    def rotate(self, xy, theta):\n",
    "        cos_theta, sin_theta = math.cos(theta), math.sin(theta)\n",
    "        return (xy[0] * cos_theta - xy[1] * sin_theta, xy[0] * sin_theta + xy[1] * cos_theta)\n",
    "\n",
    "    def translate(self, xy, offset):\n",
    "        return xy[0] + offset[0], xy[1] + offset[1]\n",
    "\n",
    "    def f(self, x, y, length, width, degrees, idx):\n",
    "\n",
    "        offset = (x, y)\n",
    "        corners = [(0, 0), (width, 0), (width, length), (0, length)]\n",
    "        rotated_and_shifted_corners = [self.translate(self.rotate(xy, math.radians(degrees)), offset) for xy in corners]\n",
    "\n",
    "        end_right_corner = list(rotated_and_shifted_corners[0]) + ['red']\n",
    "        end_left_corner = list(rotated_and_shifted_corners[1]) + ['orange']\n",
    "        start_left_corner = list(rotated_and_shifted_corners[2]) + ['cyan']\n",
    "        start_right_corner = list(rotated_and_shifted_corners[3]) + ['green']\n",
    "\n",
    "        fig = plt.figure(figsize=(18, 10))\n",
    "        gs = fig.add_gridspec(2, 4)\n",
    "\n",
    "        fig.add_subplot(gs[0:2, 0:2])\n",
    "        plt.imshow(self.save_dict[\"l_maze_corners\"][idx].frame)\n",
    "        plt.ylim(0,self.save_dict[\"l_maze_corners\"][idx].frame.shape[0])\n",
    "        plt.xlim(0,self.save_dict[\"l_maze_corners\"][idx].frame.shape[1])\n",
    "\n",
    "        if len(self.save_dict[\"l_maze_corners\"][idx].results.keys()) > 0:\n",
    "            saved_current = 'saved'\n",
    "        else:\n",
    "            saved_current = 'missing'\n",
    "\n",
    "        plt.title('current file: {} (analysis {})'.format(self.filepath, saved_current))\n",
    "\n",
    "        l_corners = [start_right_corner, start_left_corner, end_right_corner, end_left_corner]\n",
    "\n",
    "        for corner in l_corners:\n",
    "            plt.scatter(corner[0], corner[1], c=corner[2], s=100)\n",
    "\n",
    "        fig.add_subplot(gs[0, 2])\n",
    "        plt.imshow(self.save_dict[\"l_maze_corners\"][idx].frame)\n",
    "        plt.scatter(l_corners[0][0], l_corners[0][1], c=l_corners[0][2], s=100)\n",
    "        plt.xlim(l_corners[0][0]-25, l_corners[0][0]+25)\n",
    "        plt.ylim(l_corners[0][1]-25, l_corners[0][1]+25)\n",
    "        plt.title('start right corner')\n",
    "\n",
    "        fig.add_subplot(gs[0, 3])\n",
    "        plt.imshow(self.save_dict[\"l_maze_corners\"][idx].frame)\n",
    "        plt.scatter(l_corners[1][0], l_corners[1][1], c=l_corners[1][2], s=100)\n",
    "        plt.xlim(l_corners[1][0]-25, l_corners[1][0]+25)\n",
    "        plt.ylim(l_corners[1][1]-25, l_corners[1][1]+25)\n",
    "        plt.title('start left corner')\n",
    "\n",
    "        fig.add_subplot(gs[1, 2])\n",
    "        plt.imshow(self.save_dict[\"l_maze_corners\"][idx].frame)\n",
    "        plt.scatter(l_corners[2][0], l_corners[2][1], c=l_corners[2][2], s=100)\n",
    "        plt.xlim(l_corners[2][0]-25, l_corners[2][0]+25)\n",
    "        plt.ylim(l_corners[2][1]-25, l_corners[2][1]+25)\n",
    "        plt.title('end right corner')\n",
    "\n",
    "        fig.add_subplot(gs[1, 3])\n",
    "        plt.imshow(self.save_dict[\"l_maze_corners\"][idx].frame)\n",
    "        plt.scatter(l_corners[3][0], l_corners[3][1], c=l_corners[3][2], s=100)\n",
    "        plt.xlim(l_corners[3][0]-25, l_corners[3][0]+25)\n",
    "        plt.ylim(l_corners[3][1]-25, l_corners[3][1]+25)\n",
    "        plt.title('end left corner')\n",
    "\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8cd980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stats_gui(main):\n",
    "    \"\"\"allows to choose and individualize the stats\"\"\"\n",
    "    output_path = \"\"\n",
    "\n",
    "    def __init__(self, dict_selected_functions, save_dict):\n",
    "        self.save_dict = save_dict\n",
    "        self.dict_selected_functions = dict_selected_functions\n",
    "        self.select_stats_dropdown = widgets.RadioButtons(options=[\"basic\", \"all\", \"select\"], value=\"basic\", description = \"Choose, which statistics you want to plot\", layout=widgets.Layout(width=\"auto\"), style = {'description_width': 'auto'})\n",
    "\n",
    "        confirm_button = widgets.Button(description = \"Confirm\", layout=widgets.Layout(width=\"auto\"))\n",
    "        confirm_button.on_click(self.confirm)\n",
    "\n",
    "        enter_path = widgets.Button(description=\"Select output folder\", layout=widgets.Layout(width=\"auto\"))\n",
    "        enter_path.on_click(self.select_output_path)\n",
    "\n",
    "        select_ind_var_label = widgets.Label(value=\"Select independent variable\", layout=widgets.Layout(width=\"auto\"))\n",
    "        self.select_ind_variable = widgets.Dropdown(options = [\"group_ID\", \"trialnumber\", \"paradigm\"], layout=widgets.Layout(width=\"auto\"))\n",
    "        select_hue_label = widgets.Label(value=\"Select hue\", layout=widgets.Layout(width=\"auto\"))\n",
    "        self.select_hue = widgets.Dropdown(options = [\"subject_ID\", \"paradigm\", \"group_ID\"], layout=widgets.Layout(width=\"auto\"))\n",
    "\n",
    "        col0 = VBox([self.select_stats_dropdown, confirm_button])\n",
    "        col1 = VBox([select_ind_var_label, self.select_ind_variable])\n",
    "        col2 = VBox([select_hue_label, self.select_hue])\n",
    "        col3 = VBox ([enter_path])\n",
    "        row0 = HBox([col0, col1, col2, col3])\n",
    "        box = VBox([row0])\n",
    "        gui.main_tab.children += (box, ) \n",
    "        gui.tab_index += 1\n",
    "        gui.main_tab.set_title(gui.tab_index, \"Select Statistics\")\n",
    "        gui.main_tab.selected_index = gui.tab_index\n",
    "\n",
    "    def select_output_path(self, b):\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.call('wm', 'attributes', '.', '-topmost', True)\n",
    "        self.output_path = filedialog.askdirectory() + \"/\"\n",
    "        display(self.output_path)        \n",
    "\n",
    "    def confirm(self, b):\n",
    "        if self.select_stats_dropdown.value == \"select\":\n",
    "            self.select_data_col()\n",
    "        else:\n",
    "            if self.select_stats_dropdown.value == \"basic\":\n",
    "                l_selected_data_col_dict = \"basic\"\n",
    "            elif self.select_stats_dropdown.value == \"all\":\n",
    "                l_selected_data_col_dict = \"all\"\n",
    "            dict_stats = {}\n",
    "            dict_stats[\"independent_variable\"] =  self.select_ind_variable.value\n",
    "            dict_stats[\"hue\"] =  self.select_hue.value\n",
    "            gui.a.calculate_stats(self.output_path, l_selected_data_col_dict, dict_stats, dict_selected_functions = self.dict_selected_functions)\n",
    "\n",
    "    def select_data_col(self):\n",
    "        confirm_button = widgets.Button(description = \"Confirm\", layout=widgets.Layout(width=\"auto\"))\n",
    "        confirm_button.on_click(self.confirm_selected_data_col)\n",
    "        select_data_key_label = widgets.Label(value=\"Select Data Column\", layout=widgets.Layout(width=\"auto\"))\n",
    "        select_ind_var_label = widgets.Label(value=\"Select independent variable\", layout=widgets.Layout(width=\"auto\"))\n",
    "        select_hue_label = widgets.Label(value=\"Select hue\", layout=widgets.Layout(width=\"auto\"))\n",
    "\n",
    "        l_grid_children = [select_data_key_label, select_ind_var_label, select_hue_label]\n",
    "        for key in self.save_dict[\"d_data\"].keys(): \n",
    "            if key not in set(['subject_ID', 'group_ID', 'paradigm', 'trialnumber']):\n",
    "                l_grid_children.append(widgets.Checkbox(value=False, description=key, layout=widgets.Layout(width=\"auto\")))\n",
    "                l_grid_children.append(widgets.Dropdown(options = [\"group_ID\", \"trialnumber\", \"paradigm\"], value='group_ID', layout=widgets.Layout(width=\"auto\")))\n",
    "                l_grid_children.append(widgets.Dropdown(options = [\"subject_ID\", \"paradigm\", \"group_ID\"], value='subject_ID', layout=widgets.Layout(width=\"auto\")))\n",
    "\n",
    "        enter_path = widgets.Button(description=\"Select output folder\", layout=widgets.Layout(width=\"auto\"))\n",
    "        enter_path.on_click(self.select_output_path)\n",
    "\n",
    "        col3 = VBox([enter_path, confirm_button]) \n",
    "\n",
    "        self.grid = widgets.GridBox(l_grid_children, layout=widgets.Layout(grid_template_columns=\"repeat(3, auto)\"))\n",
    "\n",
    "        box = HBox([self.grid, col3])\n",
    "        gui.main_tab.children[gui.tab_index].children += (box,)\n",
    "        gui.main_tab.children[gui.tab_index].children[0].children = (gui.main_tab.children[gui.tab_index].children[0].children[0], )\n",
    "\n",
    "\n",
    "    def confirm_selected_data_col(self, b):\n",
    "        l_selected_data_col_dict = []\n",
    "        for n in range(len(self.grid.children)):\n",
    "            if n>2 & n%3 == 0:\n",
    "                if self.grid.children[n].value == True:\n",
    "                    dict_stats = {}\n",
    "                    dict_stats[\"data_col\"] = self.grid.children[n].description\n",
    "                    dict_stats[\"independent_variable\"] =  self.grid.children[n+1].value\n",
    "                    dict_stats[\"hue\"] =  self.grid.children[n+2].value\n",
    "                    l_selected_data_col_dict.append(dict_stats)\n",
    "        gui.a.calculate_stats(self.output_path, selected_data_col = l_selected_data_col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3ddf38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stats(main):\n",
    "    \"\"\"creates stats and output plots/.csv files as specified in the stats gui\"\"\"\n",
    "    def __init__(self, save_dict):\n",
    "        self.save_dict = save_dict\n",
    "    \n",
    "    def position_stats(self, data_col, independent_variable, hue, output_path):\n",
    "        l_columns = ['group_ID', 'subject_ID', 'paradigm']\n",
    "\n",
    "        dataframe = self.save_dict[\"dataframe\"].loc[:, [data_col] + l_columns]\n",
    "        dataframe.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        plt.figure(figsize=(7,9), facecolor='white')\n",
    "        \n",
    "        sns.violinplot(data=dataframe, y=\"paradigm\", x=data_col, fliersize=0, orient='h', hue=independent_variable)\n",
    "        sns.stripplot(data=dataframe, y=\"paradigm\", x=data_col, orient='h', color='k', hue=independent_variable, dodge=True, alpha=0.3)\n",
    "        plt.vlines(x=35, ymin=0.5, ymax=3.5, color='magenta', linestyle='dashed')\n",
    "\n",
    "        if output_path != \"\":\n",
    "            figname = 'differences between {} for {}.png'.format(data_col, independent_variable)\n",
    "            plt.savefig(output_path + figname, dpi=300)\n",
    "            csv_name = figname.replace('png', 'csv')\n",
    "            dataframe.to_csv(output_path + csv_name)\n",
    "    \n",
    "        plt.xlim(0, 75)\n",
    "        plt.legend(loc='center right')\n",
    "        plt.title(data_col + \" per \" + independent_variable)\n",
    "        plt.show()\n",
    "        #plt.close()\n",
    "        \n",
    "    def total_count_stats(self, data_col, independent_variable, hue, output_path):\n",
    "        l_columns = ['group_ID', 'subject_ID', 'paradigm']\n",
    "        \n",
    "        dataframe = self.save_dict[\"dataframe\"].loc[:, [data_col] + l_columns].copy()\n",
    "        dataframe.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        plt.figure(figsize=(7,4), facecolor='white')\n",
    "        \n",
    "        sns.boxplot(data=dataframe, y=\"paradigm\", x=data_col, hue=independent_variable, fliersize=0)\n",
    "        sns.stripplot(data=dataframe, y=\"paradigm\", x=data_col, hue=independent_variable, dodge=True, color='k')\n",
    "        \n",
    "        if output_path != \"\":\n",
    "            figname = 'differences between {} for {}.png'.format(data_col, independent_variable)\n",
    "            plt.savefig(output_path + figname, dpi=300)\n",
    "            csv_name = figname.replace('png', 'csv')\n",
    "            dataframe.to_csv(output_path + csv_name)\n",
    "\n",
    "        plt.ylim(0)\n",
    "        plt.xlim(-0.5,5.5)\n",
    "        #plt.legend('')\n",
    "        plt.title(data_col + \" per \" + independent_variable)\n",
    "        plt.show()\n",
    "        #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0da755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file = 'data.pickle', gui_check = False):\n",
    "    with open(file, 'rb') as f:\n",
    "        save_dict = pickle.load(f)\n",
    "         \n",
    "    main_obj = main(path = save_dict[\"path\"], dict_cams_used = save_dict[\"dict_cams_used\"], gui_check = gui_check)\n",
    "    \n",
    "    for key in save_dict: \n",
    "        setattr(main_obj, key, save_dict[key])\n",
    "    return main_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079d119a",
   "metadata": {},
   "source": [
    "GUI-less usage (as much as possible) of the Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8b62177",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = main(path = \"C:/Users/kobel/Documents/Medizin/Doktorarbeit/Coding/Dummy Data/\", dict_cams_used = {\"bottom_cam\": False, \"top_cam\": True, \"side_cam\": False}, gui_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8dae7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.all_information_given()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "522191d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211_F1-86\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(project.l_subjects)):\n",
    "    print(project.l_subjects[i].subject_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2688748",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.subjects_to_groups({\"211_F1-86\": \"control\"}, [\"control\", \"experimental\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6668e73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c235801db7ea42b8b74639646935e506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maze Corners for all videos set.\n"
     ]
    }
   ],
   "source": [
    "project.get_maze_corners()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6456bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.get_processed_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94e0b82f",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.70 GiB for an array with shape (8865, 25707) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 168>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m             df[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhole_session\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_y_norm_cm_all_freezing_bouts\u001b[39m\u001b[38;5;124m'\u001b[39m)] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mNaN       \n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dict_objects\n\u001b[1;32m--> 168\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36mtest.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtc_dict_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mtc\u001b[38;5;241m.\u001b[39mcleaned_df\u001b[38;5;241m.\u001b[39mdict_objects\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframerate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mtc\u001b[38;5;241m.\u001b[39mframerate\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_speed_and_rolling_speed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtc_dict_objects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_immobility(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtc_dict_objects)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_tc_direction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtc_dict_objects)\n",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36mtest.get_speed_and_rolling_speed\u001b[1;34m(self, dict_objects)\u001b[0m\n\u001b[0;32m     71\u001b[0m         bodypart\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[ :, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrolling_speed_px_per_s\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mNaN\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;66;03m# Limitation: since we have to exclude some frames, these calculations are not made frame by frame\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m         bodypart\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[bodypart\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexclude\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeed_px_per_s\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbodypart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbodypart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexclude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbodypart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbodypart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexclude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdict_objects\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     75\u001b[0m         bodypart\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[bodypart\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexclude\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrolling_speed_px_per_s\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m bodypart\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[bodypart\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexclude\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeed_px_per_s\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrolling(\u001b[38;5;241m5\u001b[39m, min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, center\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dict_objects\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     68\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:128\u001b[0m, in \u001b[0;36mOpsMixin.__rtruediv__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__rtruediv__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rtruediv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrtruediv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6944\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6941\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n\u001b[0;32m   6942\u001b[0m other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis],))\n\u001b[1;32m-> 6944\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign_method_FRAME\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   6946\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_frame_op(other, op, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   6947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py:307\u001b[0m, in \u001b[0;36malign_method_FRAME\u001b[1;34m(left, right, axis, flex, level)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m left\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mequals(right\u001b[38;5;241m.\u001b[39mindex):\n\u001b[0;32m    298\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    299\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutomatic reindexing on DataFrame vs Series comparisons \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    300\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis deprecated and will raise ValueError in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    305\u001b[0m             )\n\u001b[1;32m--> 307\u001b[0m     left, right \u001b[38;5;241m=\u001b[39m \u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mouter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    310\u001b[0m     right \u001b[38;5;241m=\u001b[39m _maybe_align_series_as_frame(left, right, axis)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m left, right\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4709\u001b[0m, in \u001b[0;36mDataFrame.align\u001b[1;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[0;32m   4695\u001b[0m \u001b[38;5;129m@doc\u001b[39m(NDFrame\u001b[38;5;241m.\u001b[39malign, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_shared_doc_kwargs)\n\u001b[0;32m   4696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21malign\u001b[39m(\n\u001b[0;32m   4697\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4707\u001b[0m     broadcast_axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4708\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 4709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4712\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbroadcast_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbroadcast_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4720\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:8872\u001b[0m, in \u001b[0;36mNDFrame.align\u001b[1;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[0;32m   8860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_frame(\n\u001b[0;32m   8861\u001b[0m         other,\n\u001b[0;32m   8862\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8869\u001b[0m         fill_axis\u001b[38;5;241m=\u001b[39mfill_axis,\n\u001b[0;32m   8870\u001b[0m     )\n\u001b[0;32m   8871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, ABCSeries):\n\u001b[1;32m-> 8872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_align_series\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   8873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8875\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8882\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m   8884\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(other)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:8995\u001b[0m, in \u001b[0;36mNDFrame._align_series\u001b[1;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis)\u001b[0m\n\u001b[0;32m   8993\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lidx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   8994\u001b[0m         bm_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis)\n\u001b[1;32m-> 8995\u001b[0m         fdata \u001b[38;5;241m=\u001b[39m \u001b[43mfdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8997\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   8998\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify axis=0 or 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:685\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 685\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice_take_blocks_ax0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_proxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    692\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    693\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    694\u001b[0m             indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    701\u001b[0m     ]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:803\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blkno, mgr_locs \u001b[38;5;129;01min\u001b[39;00m libinternals\u001b[38;5;241m.\u001b[39mget_blkno_placements(blknos, group\u001b[38;5;241m=\u001b[39mgroup):\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m blkno \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;66;03m# If we've got here, fill_value was not lib.no_default\u001b[39;00m\n\u001b[0;32m    802\u001b[0m         blocks\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 803\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_na_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m                \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmgr_locs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m                \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_proxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    808\u001b[0m         )\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    810\u001b[0m         blk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks[blkno]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:871\u001b[0m, in \u001b[0;36mBaseBlockManager._make_na_block\u001b[1;34m(self, placement, fill_value, use_na_proxy)\u001b[0m\n\u001b[0;32m    866\u001b[0m dtype, fill_value \u001b[38;5;241m=\u001b[39m infer_dtype_from_scalar(fill_value)\n\u001b[0;32m    867\u001b[0m \u001b[38;5;66;03m# error: Argument \"dtype\" to \"empty\" has incompatible type \"Union[dtype,\u001b[39;00m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;66;03m# ExtensionDtype]\"; expected \"Union[dtype, None, type, _SupportsDtype, str,\u001b[39;00m\n\u001b[0;32m    869\u001b[0m \u001b[38;5;66;03m# Tuple[Any, int], Tuple[Any, Union[int, Sequence[int]]], List[Any], _DtypeDict,\u001b[39;00m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;66;03m# Tuple[Any, Any]]\"\u001b[39;00m\n\u001b[1;32m--> 871\u001b[0m block_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    872\u001b[0m block_values\u001b[38;5;241m.\u001b[39mfill(fill_value)\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_block_2d(block_values, placement\u001b[38;5;241m=\u001b[39mplacement)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.70 GiB for an array with shape (8865, 25707) and data type float64"
     ]
    }
   ],
   "source": [
    "class test:\n",
    "    immobility_threshold = 16\n",
    "\n",
    "    min_freezing_duration = 1\n",
    "\n",
    "    TIME_OF_GAIT_BEFORE_DISRUPT = 0.5\n",
    "    TARGET_TIME_GAIT_DISRUPTION = 0.2\n",
    "    \n",
    "    def __init__(self):        \n",
    "        self.session = project.l_sessions[0]\n",
    "        self.session_ID = self.session.session_ID\n",
    "        self.subject = project.l_subjects[0]\n",
    "        self.subject_ID = self.subject.subject_ID\n",
    "        self.dict_selected_functions = {\"Anxiety\": True, \"Parkinson\": True}\n",
    "        self.save_dict = project.save_dict\n",
    "        self.l_dfs = []\n",
    "        \"\"\"\n",
    "        if self.save_dict[\"dict_cams_used\"][\"bottom_cam\"]:\n",
    "            \n",
    "            self.bc_dict_objects = session.bc.cleaned_df.dict_objects\n",
    "            self.framerate = session.bc.framerate\n",
    "            \n",
    "            df = self.get_speed_and_rolling_speed(self.session.bc.cleaned_df.dict_objects)\n",
    "            df = self.get_immobility(df)\n",
    "            if dict_selected_functions[\"Anxiety\"]:\n",
    "                df = self.get_freezing_bouts(df)\n",
    "                df = self.get_freezing_avg(df)\n",
    "            if dict_selected_functions[\"Parkinson\"]:\n",
    "                df = self.get_gait_disruption_bouts(df)\n",
    "                df = self.get_gait_disruption_avg(df)\n",
    "            self.l_dfs.append(df)\n",
    "            \"\"\"\n",
    "            \n",
    "        if self.save_dict[\"dict_cams_used\"][\"top_cam\"]:\n",
    "            self.tc_dict_objects = self.session.tc.cleaned_df.dict_objects\n",
    "            self.framerate = self.session.tc.framerate\n",
    "            \n",
    "            self.get_speed_and_rolling_speed(self.tc_dict_objects)\n",
    "            self.get_immobility(self.tc_dict_objects)\n",
    "            self.get_tc_direction(self.tc_dict_objects)\n",
    "            \n",
    "            if self.dict_selected_functions[\"Anxiety\"]:\n",
    "                self.get_freezing_bouts(self.tc_dict_objects)\n",
    "            \"\"\"    \n",
    "                self.get_freezing_avg(self.tc_dict_objects)\n",
    "            if self.dict_selected_functions[\"Parkinson\"]:\n",
    "                self.tc_dict_objects = self.get_direction_tc(self.tc_dict_objects)\n",
    "                self.tc_dict_objects = self.get_gait_disruption_bouts(self.tc_dict_objects)\n",
    "                self.tc_dict_objects = self.get_gait_disruption_avg(self.tc_dict_objects)\n",
    "            self.l_dfs.append(df)\n",
    "            \"\"\"\n",
    "            \n",
    "        if self.save_dict[\"dict_cams_used\"][\"side_cam\"]:\n",
    "            self.sc_dict_objects = session.sc.cleaned_df.dict_objects\n",
    "            self.l_bodyparts = save_dict[\"dict_bodyparts\"][\"side_cam\"]\n",
    "            self.framerate = session.sc.framerate\n",
    "            \n",
    "            self.l_dfs.append(df)\n",
    "        \"\"\"\n",
    "        self.combined_df = self.combine_cam_dfs()\n",
    "        self.combined_df = self.add_metadata(self.combined_df)\n",
    "        self.master_df = self.get_master_df()\n",
    "        \"\"\"\n",
    "        \n",
    "       \n",
    "    def get_speed_and_rolling_speed(self, dict_objects):\n",
    "        #calculates speed for the bodyparts        \n",
    "        for bodypart in dict_objects.values():\n",
    "            if isinstance(bodypart, Bodypart):\n",
    "                bodypart.df.loc[ :, 'speed_px_per_s'] = np.NaN\n",
    "                bodypart.df.loc[ :, 'rolling_speed_px_per_s'] = np.NaN\n",
    "\n",
    "                # Limitation: since we have to exclude some frames, these calculations are not made frame by frame\n",
    "                bodypart.df.loc[bodypart.df[\"exclude\"] == False, 'speed_px_per_s'] = (((bodypart.df.loc[bodypart.df['exclude'] == False, 'x'].diff()**2 + bodypart.df.loc[bodypart.df['exclude'] == False, 'y'].diff()**2)**(1/2)) / dict_objects[\"parameters\"].time.diff())\n",
    "                bodypart.df.loc[bodypart.df[\"exclude\"] == False, 'rolling_speed_px_per_s'] = bodypart.df.loc[bodypart.df['exclude'] == False, 'speed_px_per_s'].rolling(5, min_periods=3, center=True).mean()\n",
    "\n",
    "        return dict_objects\n",
    "     \n",
    "    def get_immobility(self, dict_objects):\n",
    "        #checks for immobility\n",
    "        for bodypart in dict_objects.values():\n",
    "            if isinstance(bodypart, Bodypart):\n",
    "                bodypart.df.loc[:, 'immobility'] = False\n",
    "                bodypart.df.loc[bodypart.df['rolling_speed_px_per_s'] < self.immobility_threshold, 'immobility'] = True\n",
    "        return dict_objects\n",
    "    \n",
    "    def get_tc_direction(self, dict_objects):\n",
    "        #calculates the direction of the animal and appends the dataframe by a direction column\n",
    "        dict_objects[\"parameters\"].moving_towards_maze_end = (dict_objects[\"EarRight\"].df.loc[:, 'y_norm'] < dict_objects[\"CenterOfGravity\"].df.loc[:, 'y_norm']) & (dict_objects['EarLeft'].df.loc[:, 'y_norm'] < dict_objects['CenterOfGravity'].df.loc[:, 'y_norm'])\n",
    "\n",
    "        return dict_objects\n",
    "    \n",
    "    def get_direction_sc(self, df):\n",
    "        pass\n",
    "    \n",
    "            \n",
    "    def find_nearest(self, array, value):\n",
    "        array = np.asarray(array)\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "        return array[idx]\n",
    "\n",
    "    def get_freezing_bouts(self, dict_objects):\n",
    "        #checks for freezing bouts\n",
    "        \"\"\"\n",
    "        dict_objects[\"parameters\"].freezing_bout = \n",
    "        df[('Freezing_bout', '')] = False\n",
    "        df[('Freezing_bout', 'count')] = np.NaN\n",
    "        df[('Freezing_bout', 'duration')] = np.NaN\n",
    "        df[('Freezing_bout', 'mean_x_norm_cm')] = np.NaN\n",
    "        df[('Freezing_bout', 'mean_y_norm_cm')] = np.NaN\n",
    "\"\"\"\n",
    "        dict_objects[\"parameters\"].all_freezing_bodyparts_immobile = df[[('EarRight', 'immobility'), ('EarLeft', 'immobility'), ('CenterOfGravity', 'immobility')]].all(axis=1)\n",
    "\n",
    "        times_where_freezing_threshold_was_reached = df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].iloc[np.where(df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].diff(self.framerate).values == 1)[0]].values\n",
    "\n",
    "        # could still throw an error if only a single frame, because of slicing to find first and last index of each interval?\n",
    "        if times_where_freezing_threshold_was_reached.shape[0] > 0:\n",
    "            indices = np.asarray(df.loc[df['time'].isin(times_where_freezing_threshold_was_reached)].index)\n",
    "            lower_end = (indices+1)[:-1]\n",
    "            upper_end = indices[1:]\n",
    "            mask = lower_end < upper_end\n",
    "            mask_last = np.concatenate([mask, np.array([True])])\n",
    "            mask_first = np.concatenate([np.array([True]), mask])\n",
    "\n",
    "            last_value_of_intervals = indices[mask_last]\n",
    "            first_value_of_intervals = indices[mask_first]\n",
    "\n",
    "            first_value_of_intervals = first_value_of_intervals-self.framerate\n",
    "\n",
    "            interval_ranges = np.column_stack([first_value_of_intervals,last_value_of_intervals])\n",
    "\n",
    "            bout_count = 0\n",
    "\n",
    "            if interval_ranges.shape[0] > 0:\n",
    "                for first_idx, last_idx in interval_ranges:\n",
    "                        bout_count = bout_count + 1\n",
    "                        bout_duration = (df.loc[last_idx, 'time'] - df.loc[first_idx, 'time'])[0]\n",
    "                        mean_pos_x_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'x_norm_cm')].mean()\n",
    "                        mean_pos_y_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'y_norm_cm')].mean()\n",
    "\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', '')] = True\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'count')] = bout_count\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'duration')] = bout_duration\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'mean_x_norm_cm')] = mean_pos_x_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'mean_y_norm_cm')] = mean_pos_y_norm_cm\n",
    "\n",
    "        return dict_objects\n",
    "    \n",
    "    def get_freezing_avg(self, dict_objects):\n",
    "        #calculates the session average for freezing\n",
    "        freezing_bout_count = df[('Freezing_bout', 'count')].unique().shape[0] - 1\n",
    "\n",
    "        if freezing_bout_count > 0:\n",
    "            df[('whole_session', 'percentage_time_spent_freezing')] = (df.loc[df[('Freezing_bout', '')] == True].shape[0] / df.shape[0]) * 100\n",
    "            df[('whole_session', 'median_freezing_bout_duration')] = np.nanmedian(df[('Freezing_bout', 'duration')].unique())\n",
    "            df[('whole_session', 'median_x_norm_cm_all_freezing_bouts')] = np.nanmedian(df[('Freezing_bout', 'mean_x_norm_cm')].unique())\n",
    "            df[('whole_session', 'median_y_norm_cm_all_freezing_bouts')] = np.nanmedian(df[('Freezing_bout', 'mean_y_norm_cm')].unique())\n",
    "        else:\n",
    "            df[('whole_session', 'percentage_time_spent_freezing')] = 0\n",
    "            df[('whole_session', 'median_freezing_bout_duration')] = np.NaN\n",
    "            df[('whole_session', 'median_x_norm_cm_all_freezing_bouts')] = np.NaN\n",
    "            df[('whole_session', 'median_y_norm_cm_all_freezing_bouts')] = np.NaN       \n",
    "            \n",
    "        return dict_objects\n",
    "            \n",
    "    \n",
    "\n",
    "a = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f801a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.tc_dict_objects[\"EarRight\"].df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d14122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #self.save_dict[\"sessions\"][session_ID].dict_bodyparts[cam][bodypart]\n",
    "    \n",
    "        \n",
    "    def get_gait_disruption_bouts(self, df):\n",
    "        #checks for gait disruption bouts\n",
    "        df[('GaitDisruption_bout', '')] = False\n",
    "        df[('GaitDisruption_bout', 'count')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'duration')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'mean_x_norm_cm')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'mean_y_norm_cm')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'direction_bool')] = ''\n",
    "        df[('GaitDisruption_bout', 'direction_mean')] = np.NaN\n",
    "\n",
    "        if self.dict_selected_functions[\"Anxiety\"] == False:\n",
    "            df['all_freezing_bodyparts_immobile'] = df[[('EarRight', 'immobility'), ('EarLeft', 'immobility'), ('CenterOfGravity', 'immobility')]].all(axis=1)\n",
    "        \n",
    "        l_timesteps = []\n",
    "        if self.framerate%1 != 0:\n",
    "            print(\"gait disruption bout calculations are invalid due to framerate with decimal places\")\n",
    "        for i in range(int(self.framerate)):\n",
    "            l_timesteps.append(i/self.framerate)\n",
    "\n",
    "        time_gait_disruption = self.find_nearest(np.asarray(l_timesteps), self.TARGET_TIME_GAIT_DISRUPTION)\n",
    "        frames_difference = l_timesteps.index(time_gait_disruption)\n",
    "\n",
    "        gait_disruption_threshold_reached = df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].iloc[np.where(np.round(df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].diff(frames_difference).values, 7) == round(time_gait_disruption, 7))[0]].values\n",
    "\n",
    "        # could still throw an error if only a single frame, because of slicing to find first and last index of each interval?    \n",
    "        if gait_disruption_threshold_reached.shape[0] > 0:\n",
    "            indices = np.asarray(df.loc[df['time'].isin(gait_disruption_threshold_reached)].index)\n",
    "            lower_end = (indices+1)[:-1]\n",
    "            upper_end = indices[1:]\n",
    "            mask = lower_end < upper_end\n",
    "            mask_last = np.concatenate([mask, np.array([True])])\n",
    "            mask_first = np.concatenate([np.array([True]), mask])\n",
    "\n",
    "            last_value_of_intervals = indices[mask_last]\n",
    "            first_value_of_intervals = indices[mask_first]\n",
    "            \n",
    "            first_value_of_intervals = first_value_of_intervals-l_timesteps.index(self.find_nearest(np.asarray(l_timesteps), self.TARGET_TIME_GAIT_DISRUPTION))\n",
    "\n",
    "            interval_ranges = np.column_stack([first_value_of_intervals,last_value_of_intervals])\n",
    "\n",
    "            frames_prior_to_interval_start = l_timesteps.index(self.find_nearest(np.asarray(l_timesteps), self.TIME_OF_GAIT_BEFORE_DISRUPT))\n",
    "            bout_count = 0\n",
    "\n",
    "            if interval_ranges.shape[0] > 0:\n",
    "                for first_idx, last_idx in interval_ranges:\n",
    "                    start_idx_gait_check = first_idx - frames_prior_to_interval_start\n",
    "                    if df.loc[start_idx_gait_check:first_idx-1, 'all_freezing_bodyparts_immobile'].any() == False:\n",
    "                        bout_count = bout_count + 1\n",
    "                        bout_duration = (df.loc[last_idx, 'time'] - df.loc[first_idx, 'time'])[0]\n",
    "                        mean_pos_x_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'x_norm_cm')].mean()\n",
    "                        mean_pos_y_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'y_norm_cm')].mean()\n",
    "                        direction_bool = df.loc[first_idx:last_idx, ('moving_towards_maze_end', '')].all()\n",
    "                        direction_mean = df.loc[first_idx:last_idx, ('moving_towards_maze_end', '')].mean()\n",
    "\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', '')] = True\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'count')] = bout_count\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'duration')] = bout_duration\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'mean_x_norm_cm')] = mean_pos_x_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'mean_y_norm_cm')] = mean_pos_y_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'direction_bool')] = direction_bool\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'direction_mean')] = direction_mean\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_gait_disruption_avg(self, df):\n",
    "        #calculates the session average for gait disruption\n",
    "        gait_disruption_bout_count = df[('GaitDisruption_bout', 'count')].unique().shape[0] - 1\n",
    "\n",
    "        if gait_disruption_bout_count > 0:\n",
    "            df[('whole_session', 'percentage_time_spent_gait_disrupted')] = (df.loc[df[('GaitDisruption_bout', '')] == True].shape[0] / df.shape[0]) * 100\n",
    "            df[('whole_session', 'median_gait_disruption_bout_duration')] = np.nanmedian(df[('GaitDisruption_bout', 'duration')].unique())\n",
    "            df[('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')] = np.nanmedian(df[('GaitDisruption_bout', 'mean_x_norm_cm')].unique())\n",
    "            df[('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts')] = np.nanmedian(df[('GaitDisruption_bout', 'mean_y_norm_cm')].unique())\n",
    "        else:\n",
    "            df[('whole_session', 'percentage_time_spent_gait_disrupted')] = 0\n",
    "            df[('whole_session', 'median_gait_disruption_bout_duration')] = np.NaN\n",
    "            df[('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')] = np.NaN\n",
    "            df[('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts')] = np.NaN\n",
    "\n",
    "        return df\n",
    "\n",
    "    def combine_cam_dfs(self):\n",
    "        #combines the data from different recording modalities. not yet implemented. requires class bodyparts\n",
    "        if len(self.l_dfs) == 1:\n",
    "            combined_df = self.l_dfs[0]\n",
    "            return combined_df\n",
    "        else:\n",
    "            #crazy function to combine input of all cams using self.l_dfs\n",
    "            #or the bodypart class\n",
    "            #return combined_df \n",
    "            pass\n",
    "        \n",
    "    def add_metadata(self, df):\n",
    "        #adds metadata to the dataframe\n",
    "        df['subject_ID'] = self.subject.subject_ID\n",
    "        df['group_ID'] = self.subject.group_ID\n",
    "        df['trialnumber'] = 1 #muss noch implementiert werden!\n",
    "        df['DateOfRecording'] = self.session.date\n",
    "        df['paradigm'] = self.session.paradigm\n",
    "        return df\n",
    "    \n",
    "    def get_master_df(self):\n",
    "        #combines all the information into a master_df as specified by col_in_precessed_df\n",
    "        d_for_master_df = {}\n",
    "\n",
    "        for key, col_in_processed_df in self.save_dict[\"col_in_master_df\"]:\n",
    "            d_for_master_df[key] = self.combined_df[col_in_processed_df].values\n",
    "\n",
    "        master_df = pd.DataFrame(data=d_for_master_df)\n",
    "        return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fcf8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.execute_functions(dict_selected_functions = {\"Anxiety\": True, \"Parkinson\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3d2d1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project.calculate_stats(output_path = \"C:/Users/kobel/Desktop/\", selected_data_col = \"all\", stats_dict = {\"hue\": \"subject_ID\", \"independent_variable\": \"group_ID\"}, dict_selected_functions = {\"Anxiety\": True, \"Parkinson\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc9743",
   "metadata": {},
   "source": [
    "Test Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8538fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save(filename = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d58fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bbf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = load(file = \"C:/Users/kobel/Documents/Medizin/Doktorarbeit/Coding/Dummy Data/maintest.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba47e9",
   "metadata": {},
   "source": [
    "Use GUI for the Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e25349",
   "metadata": {},
   "outputs": [],
   "source": [
    "gui.main_gui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e20031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
