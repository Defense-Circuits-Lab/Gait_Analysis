{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36ae279",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox, HBox, interactive\n",
    "import math\n",
    "import matplotlib.image as img\n",
    "import cv2\n",
    "from IPython.display import clear_output, display\n",
    "from tkinter import Tk, filedialog\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6effd3ea",
   "metadata": {},
   "source": [
    "This notebook consists of the following classes:\n",
    "  \n",
    "    \n",
    "    class main\n",
    "    class subjects\n",
    "    class session\n",
    "    class side_cam\n",
    "    class bottom_cam\n",
    "    class top_cam\n",
    "    class maze corner\n",
    "    class clean_df\n",
    "    class df_functions\n",
    "    class stats\n",
    "    \n",
    "    class gui\n",
    "        class main_gui\n",
    "        class subject_gui\n",
    "        class bc_gui\n",
    "        class tc_gui\n",
    "        class sc_gui\n",
    "        class clean_df_gui\n",
    "        class select_functions\n",
    "        \n",
    "    class maze_corner_gui       \n",
    "    class stats_gui\n",
    "\n",
    "\n",
    "Name all of your .csv/.mp4/.avi files strictly like this: \n",
    "\n",
    "                        210_F1-83_220518_OTT_bottom\n",
    "                        211_F3-04_211123_OTR_top\n",
    "\n",
    "                        Line_ID_Date_Paradigm_Camera   \n",
    "                    \n",
    "Your framerate should not have decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c74159",
   "metadata": {},
   "outputs": [],
   "source": [
    "class main: \n",
    "    \"\"\"Main object contains overview over all files, subjects and common variable over a folder of files as specified by the path.\"\"\"\n",
    "    l_maze_corners_bc = []\n",
    "    l_maze_corners_tc = []\n",
    "    save_dict = {}\n",
    "\n",
    "    def __init__(self, path = \"PATH\", dict_cams_used = {\"bottom_cam\": False, \"top_cam\": False, \"side_cam\": False}, gui = False):\n",
    "        #creates common variables\n",
    "        main.path = path\n",
    "        main.dict_cams_used = dict_cams_used\n",
    "        main.gui = gui\n",
    "        if main.path != \"PATH\":\n",
    "            self.all_information_given()\n",
    "        self.save_dict[\"path\"]=main.path\n",
    "        self.save_dict[\"dict_cams_used\"]=main.dict_cams_used\n",
    "        self.save_dict[\"main_object\"]=self\n",
    "        \n",
    "    def all_information_given(self):\n",
    "        #creates objects for all of the files in the chosen folder\n",
    "        main.l_session_IDs = np.unique(np.array([file for file in set ([elem[0:-11] for elem in os.listdir(self.path) if elem.endswith('bottom.csv')]+[elem[0:-8] for elem in os.listdir(self.path) if elem.endswith('top.csv')]+[elem[0:-9] for elem in os.listdir(self.path) if elem.endswith('side.csv')])])).tolist()\n",
    "        main.l_sessions = [session(session_ID) for session_ID in self.l_session_IDs]\n",
    "        main.l_subject_IDs = ([session.subject_ID for session in self.l_sessions])\n",
    "        main.l_subjects = np.unique(np.array([subject(subject_ID) for subject_ID in self.l_subject_IDs])).tolist()\n",
    "        self.save_dict[\"l_subjects\"]=main.l_subjects\n",
    "        self.save_dict[\"l_sessions\"]=main.l_sessions\n",
    "            \n",
    "    def subjects_to_groups(self, subject_group_dict, l_groups):\n",
    "        #provides each subject a subject_ID as in subject_group_dict\n",
    "        if main.all_files_there:\n",
    "            for subject in main.l_subjects:\n",
    "                subject.group_ID = subject_group_dict[subject.subject_ID]\n",
    "            main.l_groups = l_groups\n",
    "            if main.gui==False:\n",
    "                #branch that will be used if gui-less usage is chosen\n",
    "                if self.dict_cams_used[\"bottom_cam\"] or self.dict_cams_used[\"top_cam\"]:\n",
    "                    self.get_maze_corners()\n",
    "\n",
    "    def get_maze_corners(self):\n",
    "        #if top or bottom cam are used, this function creates the maze_corner annotation\n",
    "        if self.dict_cams_used[\"bottom_cam\"] & self.all_files_there:\n",
    "            main.l_maze_corners_bc = [session.bc.mc for session in self.l_sessions]\n",
    "        if self.dict_cams_used[\"top_cam\"] & self.all_files_there:\n",
    "            main.l_maze_corners_tc = [session.tc.mc for session in self.l_sessions]\n",
    "        \n",
    "        if self.dict_cams_used[\"bottom_cam\"] or self.dict_cams_used[\"top_cam\"]:\n",
    "            main.l_maze_corners = self.l_maze_corners_bc + self.l_maze_corners_tc\n",
    "            if gui.displayed == False:\n",
    "                display(gui.main_tab)\n",
    "                gui.displayed = True\n",
    "            maze_corner_gui()\n",
    "        else:\n",
    "            self.get_processed_dfs()\n",
    "                   \n",
    "    def get_processed_dfs(self, DLC_likelihood_threshold = 0.9):\n",
    "        #processes the dataframes\n",
    "        main.dict_bodyparts = {}#wird zuk체nftig ersetzt durch class bodypart \n",
    "        if self.dict_cams_used[\"bottom_cam\"]:\n",
    "            for session in self.l_sessions:\n",
    "                session.bc.processed_df = clean_df(session.bc, DLC_likelihood_threshold).df \n",
    "        if self.dict_cams_used[\"top_cam\"]:\n",
    "            for session in self.l_sessions:\n",
    "                session.tc.processed_df = clean_df(session.tc, DLC_likelihood_threshold).df\n",
    "        if self.dict_cams_used[\"side_cam\"]:\n",
    "            #clean_df\n",
    "            pass        \n",
    "        \n",
    "    def execute_functions(self, dict_selected_functions = {\"Anxiety\": False, \"Parkinson\": False}):\n",
    "        #calculates the target variables as chosen in dict_selected_functions\n",
    "        self.get_col_in_master_df_and_main_dataframe(dict_selected_functions)\n",
    "        for subject in self.l_subjects:\n",
    "            for session in subject.l_sessions:\n",
    "                session.master_df = df_functions(subject, session, dict_selected_functions).master_df\n",
    "                self.append_session_to_d_data(subject, session, dict_selected_functions)\n",
    "        if gui.displayed == False:\n",
    "            display(gui.main_tab)\n",
    "            gui.displayed = True\n",
    "        self.save_dict[\"dataframe\"]=main.dataframe\n",
    "        stats_gui(dict_selected_functions)\n",
    "        \n",
    "    def get_col_in_master_df_and_main_dataframe(self, dict_selected_functions):\n",
    "        #creates the master and main dataframe\n",
    "        main.d_data = {'subject_ID': [], 'group_ID': [], 'paradigm': [], 'trialnumber': [], }\n",
    "        main.col_in_master_df = [('subject_ID', ('subject_ID', '')),\n",
    "                    ('group_ID', ('group_ID', '')),\n",
    "                    ('paradigm', ('paradigm', '')),\n",
    "                    ('trialnumber', ('trialnumber', '')),\n",
    "                    ('time', ('time', '')),\n",
    "                    ('exclude', ('all', 'exclude')), \n",
    "                    ('CenterOfGravity_x_norm_cm', ('CenterOfGravity', 'x_norm_cm')),\n",
    "                    ('CenterOfGravity_y_norm_cm', ('CenterOfGravity', 'y_norm_cm')),                    \n",
    "                    ('CenterOfGravity_rolling_speed_px_per_s', ('CenterOfGravity', 'rolling_speed_px_per_s'))]\n",
    "        if dict_selected_functions[\"Anxiety\"]:              \n",
    "            d_data_anx = { 'count_freezing_bouts': [],\n",
    "                       'mean_freezing_bout_duration': [],\n",
    "                       'percentage_of_time_spent_freezing': [],\n",
    "                       'mean_freezing_bouts_y_position': [],\n",
    "                       'median_freezing_bouts_y_position': [],\n",
    "                       'wall_endzone_mean_freezing_bouts_y_position': [], \n",
    "                       'wall_endzone_median_freezing_bouts_y_position': [], \n",
    "                       'wall_endzone_stddev_freezing_bouts_y_position': [], \n",
    "                       'wall_endzone_count_freezing_bouts': [],}\n",
    "            main.d_data = self.d_data | d_data_anx\n",
    "            main.col_in_master_df.extend([('freezing', ('Freezing_bout', '')),\n",
    "                    ('freezing_bout_count', ('Freezing_bout', 'count')),\n",
    "                    ('freezing_bout_duration', ('Freezing_bout', 'duration')),\n",
    "                    ('freezing_bout_mean_x_norm_cm', ('Freezing_bout', 'mean_x_norm_cm')),\n",
    "                    ('freezing_bout_mean_y_norm_cm', ('Freezing_bout', 'mean_y_norm_cm')),\n",
    "                    ('Percentage_time_spent_freezing_session', ('whole_session', 'percentage_time_spent_freezing')),\n",
    "                    ('Median_freezing_bout_duration_session', ('whole_session', 'median_freezing_bout_duration')),\n",
    "                    ('Median_x_norm_cm_all_freezing_bouts_session', ('whole_session', 'median_x_norm_cm_all_freezing_bouts')),\n",
    "                    ('Median_y_norm_cm_all_freezing_bouts_session', ('whole_session', 'median_y_norm_cm_all_freezing_bouts'))])\n",
    "                      \n",
    "        if dict_selected_functions[\"Parkinson\"]:\n",
    "            d_data_pd =  {'count_gait_disruption_bouts_all': [],\n",
    "                       #'count_gait_disruption_bouts_in': [],\n",
    "                       #'count_gait_disruption_bouts_out': [],\n",
    "                       'mean_gait_disruption_bout_duration_all': [], \n",
    "                       #'mean_gait_disruption_bout_duration_in': [], \n",
    "                       #'mean_gait_disruption_bout_duration_out': [],\n",
    "                       'percentage_of_time_spent_gait_disrupted_all': [],\n",
    "                       'mean_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'mean_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'mean_gait_disruption_bouts_y_position_out': [], \n",
    "                       'median_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'median_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'median_gait_disruption_bouts_y_position_out': [], \n",
    "                       'wall_endzone_mean_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'wall_endzone_mean_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'wall_endzone_mean_gait_disruption_bouts_y_position_out': [],\n",
    "                       'wall_endzone_median_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'wall_endzone_median_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'wall_endzone_median_gait_disruption_bouts_y_position_out': [],\n",
    "                       'wall_endzone_stddev_gait_disruption_bouts_y_position_all': [],\n",
    "                       #'wall_endzone_stddev_gait_disruption_bouts_y_position_in': [], \n",
    "                       #'wall_endzone_stddev_gait_disruption_bouts_y_position_out': [],\n",
    "                       'wall_endzone_count_gait_disruption_bouts_all': [],\n",
    "                       #'wall_endzone_count_gait_disruption_bouts_in': [],\n",
    "                       #'wall_endzone_count_gait_disruption_bouts_out': [], \n",
    "                         }\n",
    "            main.d_data = self.d_data | d_data_pd\n",
    "            main.col_in_master_df.extend([('gaitdisruption', ('GaitDisruption_bout', '')),\n",
    "                    ('gaitdisruption_bout_count', ('GaitDisruption_bout', 'count')),\n",
    "                    ('gaitdisruption_bout_duration', ('GaitDisruption_bout', 'duration')),\n",
    "                    ('gaitdisruption_bout_mean_x_norm_cm', ('GaitDisruption_bout', 'mean_x_norm_cm')),\n",
    "                    ('gaitdisruption_bout_mean_y_norm_cm', ('GaitDisruption_bout', 'mean_y_norm_cm')),\n",
    "                    ('gaitdisruption_bout_direction_bool', ('GaitDisruption_bout', 'direction_bool')),\n",
    "                    ('gaitdisruption_bout_direction_mean', ('GaitDisruption_bout', 'direction_mean')),\n",
    "                    ('Percentage_time_spent_gaitdisrupted_session', ('whole_session', 'percentage_time_spent_gait_disrupted')),\n",
    "                    ('Median_gaitdisruption_bout_duration_session', ('whole_session', 'median_gait_disruption_bout_duration')),\n",
    "                    ('Median_x_norm_cm_all_gaitdisruption_bouts_session', ('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')),\n",
    "                    ('Median_y_norm_cm_all_gaitdisruption_bouts_session', ('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts'))])\n",
    "            \n",
    "    def append_session_to_d_data(self, subject, session, dict_selected_functions):\n",
    "        #appends data of each session to a dict containing all sessions\n",
    "            wall_end_position = 35 #in cm\n",
    "            \n",
    "            self.d_data['subject_ID'].append(session.subject_ID)\n",
    "            self.d_data['group_ID'].append(subject.group_ID)\n",
    "            self.d_data['paradigm'].append(session.paradigm)\n",
    "            self.d_data['trialnumber'].append(subject.trialnumber)\n",
    "            \n",
    "            if dict_selected_functions[\"Anxiety\"]: \n",
    "                self.d_data['count_freezing_bouts'].append(self.get_total_bount_count(session.master_df['freezing_bout_count'].unique()))\n",
    "                self.d_data['mean_freezing_bout_duration'].append(session.master_df['freezing_bout_duration'].mean())\n",
    "                self.d_data['percentage_of_time_spent_freezing'].append(session.master_df['Percentage_time_spent_freezing_session'].unique()[0])\n",
    "                self.d_data['mean_freezing_bouts_y_position'].append(session.master_df['freezing_bout_mean_y_norm_cm'].mean())\n",
    "                self.d_data['median_freezing_bouts_y_position'].append(session.master_df['freezing_bout_mean_y_norm_cm'].median())\n",
    "                \n",
    "                mean_pos_freezing, median_pos_freezing, std_dev_freezing, bout_count_freezing = self.get_fuzziness(session.master_df, wall_end_position, 10)\n",
    "                \n",
    "                self.d_data['wall_endzone_mean_freezing_bouts_y_position'].append(mean_pos_freezing)\n",
    "                self.d_data['wall_endzone_median_freezing_bouts_y_position'].append(median_pos_freezing)\n",
    "                self.d_data['wall_endzone_stddev_freezing_bouts_y_position'].append(std_dev_freezing)\n",
    "                self.d_data['wall_endzone_count_freezing_bouts'].append(bout_count_freezing)\n",
    "            \n",
    "            if dict_selected_functions[\"Parkinson\"]: \n",
    "                self.d_data['count_gait_disruption_bouts_all'].append(self.get_total_bount_count(session.master_df['gaitdisruption_bout_count'].unique()))\n",
    "                #self.d_data['count_gait_disruption_bouts_in'].append(self.get_total_bount_count(df_temp_in['gaitdisruption_bout_count'].unique()))\n",
    "                #self.d_data['count_gait_disruption_bouts_out'].append(self.get_total_bount_count(df_temp_out['gaitdisruption_bout_count'].unique()))\n",
    "\n",
    "\n",
    "                self.d_data['mean_gait_disruption_bout_duration_all'].append(session.master_df['gaitdisruption_bout_duration'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bout_duration_in'].append(df_temp_in['gaitdisruption_bout_duration'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bout_duration_out'].append(df_temp_out['gaitdisruption_bout_duration'].mean())\n",
    "\n",
    "\n",
    "                self.d_data['percentage_of_time_spent_gait_disrupted_all'].append(session.master_df['Percentage_time_spent_gaitdisrupted_session'].unique()[0])\n",
    "\n",
    "\n",
    "                self.d_data['mean_gait_disruption_bouts_y_position_all'].append(session.master_df['gaitdisruption_bout_mean_y_norm_cm'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bouts_y_position_in'].append(df_temp_in['gaitdisruption_bout_mean_y_norm_cm'].mean())\n",
    "                #self.d_data['mean_gait_disruption_bouts_y_position_out'].append(df_temp_out['gaitdisruption_bout_mean_y_norm_cm'].mean())\n",
    "\n",
    "\n",
    "                self.d_data['median_gait_disruption_bouts_y_position_all'].append(session.master_df['gaitdisruption_bout_mean_y_norm_cm'].median())\n",
    "                #self.d_data['median_gait_disruption_bouts_y_position_in'].append(df_temp_in['gaitdisruption_bout_mean_y_norm_cm'].median())\n",
    "                #self.d_data['median_gait_disruption_bouts_y_position_out'].append(df_temp_out['gaitdisruption_bout_mean_y_norm_cm'].median())\n",
    "\n",
    "\n",
    "                mean_pos_gait_all, median_pos_gait_all, std_dev_gait_all, bout_count_gait_all = self.get_fuzziness(session.master_df, wall_end_position, 10)\n",
    "                #mean_pos_gait_in, median_pos_gait_in, std_dev_gait_in, bout_count_gait_in = self.get_fuzziness(df_temp_in, wall_end_position, 10)\n",
    "                #mean_pos_gait_out, median_pos_gait_out, std_dev_gait_out, bout_count_gait_out = self.get_fuzziness(df_temp_out, wall_end_position, 10)\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_mean_gait_disruption_bouts_y_position_all'].append(mean_pos_gait_all)\n",
    "                #self.d_data['wall_endzone_mean_gait_disruption_bouts_y_position_in'].append(mean_pos_gait_in)\n",
    "                #self.d_data['wall_endzone_mean_gait_disruption_bouts_y_position_out'].append(mean_pos_gait_out)\n",
    "\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_median_gait_disruption_bouts_y_position_all'].append(median_pos_gait_all)\n",
    "                #self.d_data['wall_endzone_median_gait_disruption_bouts_y_position_in'].append(median_pos_gait_in)\n",
    "                #self.d_data['wall_endzone_median_gait_disruption_bouts_y_position_out'].append(median_pos_gait_out)\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_stddev_gait_disruption_bouts_y_position_all'].append(std_dev_gait_all)\n",
    "                #self.d_data['wall_endzone_stddev_gait_disruption_bouts_y_position_in'].append(std_dev_gait_in)\n",
    "                #self.d_data['wall_endzone_stddev_gait_disruption_bouts_y_position_out'].append(std_dev_gait_out)\n",
    "\n",
    "\n",
    "                self.d_data['wall_endzone_count_gait_disruption_bouts_all'].append(bout_count_gait_all)\n",
    "                #self.d_data['wall_endzone_count_gait_disruption_bouts_in'].append(bout_count_gait_in)\n",
    "                #self.d_data['wall_endzone_count_gait_disruption_bouts_out'].append(bout_count_gait_out)\n",
    "            \n",
    "            main.dataframe = pd.DataFrame(data = self.d_data)   \n",
    "            \n",
    "    def get_total_bount_count(self, uniques):\n",
    "        uniques = uniques[~np.isnan(uniques)]\n",
    "        return uniques.shape[0]\n",
    "\n",
    "    #was ist half_window_size, ist es fix auf 10?\n",
    "    def get_fuzziness(self, df_tmp, wall_end_position, half_window_size):\n",
    "        mean_pos = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                              (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].mean()\n",
    "\n",
    "        median_pos = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                                (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].median()\n",
    "\n",
    "        std_dev = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                             (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].std()\n",
    "\n",
    "        bout_count = df_tmp.loc[(df_tmp['CenterOfGravity_y_norm_cm'] >= wall_end_position - 10) &\n",
    "                                (df_tmp['CenterOfGravity_y_norm_cm'] <= wall_end_position + 10), 'CenterOfGravity_y_norm_cm'].shape[0]\n",
    "\n",
    "        if bout_count < 3:\n",
    "            mean_pos = np.NaN\n",
    "            std_dev = np.NaN    \n",
    "    \n",
    "        return mean_pos, median_pos, std_dev, bout_count\n",
    "        \n",
    "    def calculate_stats(self, output_path, l_selected_data_col_dict):\n",
    "        #calls the stats class with inputs as chosen in the stats_gui\n",
    "        for dict_stats in l_selected_data_col_dict:\n",
    "            stats.total_count_stats(self, dict_stats[\"data_col\"], dict_stats[\"independent_variable\"], dict_stats[\"hue\"], output_path)\n",
    "            if \"y_position\" in dict_stats[\"data_col\"]:\n",
    "                stats.position_stats(self, dict_stats[\"data_col\"], dict_stats[\"independent_variable\"], dict_stats[\"hue\"], output_path)\n",
    "                \n",
    "    def save(self):\n",
    "        with open('data.pickle', 'wb') as f:\n",
    "            pickle.dump(self.save_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5350d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class subject(main):\n",
    "    \"\"\"creates an object representing an individual subject\"\"\"\n",
    "    def __init__(self, subject_ID):\n",
    "        self.subject_ID = subject_ID\n",
    "        self.l_sessions = [session for session in main.l_sessions if session.subject_ID == self.subject_ID]\n",
    "        #if len(self.l_sessions) > 1:\n",
    "            #self.l_paradigms = [session.paradigm for session in self.l_sessions]\n",
    "        self.dict_date_paradigm = {session.date:session.paradigm for session in self.l_sessions}\n",
    "        self.trialnumber = 1 #muss noch implementiert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c17da831",
   "metadata": {},
   "outputs": [],
   "source": [
    "class session(subject):\n",
    "    \"\"\"creates an object representing an individual session and checks, whether all the files are there\"\"\"\n",
    "    def __init__(self, session_ID):\n",
    "        self.session_ID = session_ID\n",
    "        if 'OTE' in self.session_ID:\n",
    "            self.paradigm = 'exponential'\n",
    "        elif 'OTT'  in self.session_ID:\n",
    "            self.paradigm  = 'triangle'\n",
    "        elif 'OTR'  in self.session_ID:\n",
    "            self.paradigm = 'rectangle'\n",
    "        self.subject_ID_date = self.session_ID[0:-4] \n",
    "        #falls andere Paradigmen eingebaut werden, die nicht drei spaces in der Benennung haben, muss das ge채ndert werden\n",
    "        #generisch: self.session_ID[self.session_ID.index('')+1:self.session_ID.index('')]\n",
    "        self.date = datetime.strptime(self.subject_ID_date[-6:], '%y%m%d')\n",
    "        self.subject_ID = self.subject_ID_date[0:-7]\n",
    "        bc_csv = self.session_ID in set([elem[0:-11] for elem in os.listdir(main.path) if elem.endswith('_bottom.csv')])\n",
    "        bc_mp4 = self.session_ID in set([elem[0:-11] for elem in os.listdir(main.path) if elem.endswith('_bottom.mp4')]) \n",
    "        tc_csv = self.session_ID in set([elem[0:-8] for elem in os.listdir(main.path) if elem.endswith('_top.csv')])\n",
    "        tc_mp4 = self.session_ID in set([elem[0:-8] for elem in os.listdir(main.path) if elem.endswith('_top.mp4') or elem.endswith('_top.avi')])\n",
    "        sc_csv = self.session_ID in set([elem[0:-9] for elem in os.listdir(main.path) if elem.endswith('_side.csv')])\n",
    "        sc_mp4 = self.session_ID in set([elem[0:-9] for elem in os.listdir(main.path) if elem.endswith('_side.mp4')])\n",
    "        \n",
    "        main.all_files_there = True\n",
    "        missing_files_statement = \"\\nPlease name your files as the following: 210_F1-83_220518_OTT_bottom.mp4 \\nLine_ID_Date_Paradigm_Camera_ending\"\n",
    "        if main.dict_cams_used[\"bottom_cam\"]:\n",
    "            if bc_csv == False:\n",
    "                print(\"Missing _bottom.csv file for session {} in {}!\".format(self.session_ID, main.path), missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            elif bc_mp4 == False:\n",
    "                print(\"Missing _bottom.mp4 file for session {} in {}!\".format(self.session_ID, main.path), missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            else:\n",
    "                bc_video_filename = session_ID + \"_bottom.mp4\"\n",
    "                bc_csv_filename = session_ID + \"_bottom.csv\"\n",
    "                bc_df = pd.read_csv(main.path + bc_csv_filename, skiprows=1, index_col=0, header=[0, 1])\n",
    "                self.bc = bottom_cam(self.session_ID, bc_df)\n",
    "\n",
    "        if main.dict_cams_used[\"top_cam\"]:\n",
    "            if tc_csv ==False:\n",
    "                print(\"Missing _top.csv file for session {} in {}!\".format(self.session_ID, main.path), missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            elif tc_mp4 == False:\n",
    "                print(\"Missing top.mp4 file for session {} in {}!\".format(self.session_ID, main.path), missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            else:  \n",
    "                tc_video_filename = session_ID + \"_top.mp4\"\n",
    "                tc_csv_filename = session_ID + \"_top.csv\"\n",
    "                tc_df = pd.read_csv(main.path + tc_csv_filename, skiprows=1, index_col=0, header=[0, 1])\n",
    "                self.tc = top_cam(self.session_ID, tc_df)\n",
    "            \n",
    "        if main.dict_cams_used[\"side_cam\"]:\n",
    "            if sc_csv == False:\n",
    "                print(\"Missing _side.csv file for session {} in {}!\".format(self.session_ID, main.path), missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            elif sc_mp4 == False:\n",
    "                print(\"Missing side.mp4 file for session {} in {}!\".format(self.session_ID, main.path),missing_files_statement)\n",
    "                main.all_files_there = False\n",
    "            else:\n",
    "                sc_video_filename = session_ID + \"_side.mp4\"\n",
    "                sc_csv_filename = session_ID + \"_side.csv\"\n",
    "                sc_df = pd.read_csv(main.path + sc_csv_filename, skiprows=1, index_col=0, header=[0, 1])\n",
    "                #create side_cam object\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "620c7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottom_cam(session):\n",
    "    \"\"\"creates an object containing the data for bottom cam recording modality\"\"\"\n",
    "    def __init__(self, session_ID, df):\n",
    "        self.session_ID = session_ID\n",
    "        self.df = df\n",
    "        path_avi = main.path + session_ID + \"_bottom.AVI\"\n",
    "        path_mp4 = main.path + session_ID + \"_bottom.mp4\"\n",
    "        if os.path.exists(path_avi):\n",
    "            self.video_path = path_avi\n",
    "        elif os.path.exists(path_mp4):\n",
    "            self.video_path = path_mp4\n",
    "        self.mc = maze_corners(self.video_path)\n",
    "        video = imageio.get_reader(self.video_path,  'ffmpeg')\n",
    "        self.framerate = video.get_meta_data()[\"fps\"]\n",
    "        self.cam = \"bottom_cam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13d7d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class top_cam:\n",
    "    \"\"\"creates an object containing the data for top cam recording modality\"\"\"\n",
    "    def __init__(self, session_ID, df):\n",
    "        self.session_ID = session_ID\n",
    "        self.df = df\n",
    "        path_avi = main.path + session_ID + \"_top.AVI\"\n",
    "        path_mp4 = main.path + session_ID + \"_top.mp4\"\n",
    "        if os.path.exists(path_avi):\n",
    "            self.video_path = path_avi\n",
    "        elif os.path.exists(path_mp4):\n",
    "            self.video_path = path_mp4\n",
    "        self.mc = maze_corners(self.video_path)\n",
    "        video = imageio.get_reader(self.video_path,  'ffmpeg')\n",
    "        self.framerate = video.get_meta_data()[\"fps\"]\n",
    "        self.cam = \"top_cam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168e62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class side_cam:\n",
    "    \"\"\"creates an object containing the data for side cam recording modality\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        #stitch()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5456523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class clean_df(session):\n",
    "    \"\"\"creates an object that returns the cleaned dataframe after processing several functions\"\"\"\n",
    "    maze_length_in_cm = 50\n",
    "    \n",
    "    def __init__(self, session_cam_object, threshold):        \n",
    "        self.threshold = threshold\n",
    "        self.framerate = session_cam_object.framerate\n",
    "        self.results = session_cam_object.mc.results #side cams geben keine results weil sie keine mc objects haben\n",
    "        df = session_cam_object.df\n",
    "        self.l_bodyparts = [elem[0] for elem in df.columns[::3]]\n",
    "        main.dict_bodyparts[session_cam_object.cam] = self.l_bodyparts #wird zuk체nfitg ersetzt durch class bodypart \n",
    "        df = self.get_time(df)\n",
    "        df = self.identify_duplicates(df)\n",
    "        df[('all', 'exclude')] = False\n",
    "        df = self.exclude_frames(df)\n",
    "        if \"CenterOfGravity\" not in self.l_bodyparts:\n",
    "            df = self.get_center_of_gravity(df)\n",
    "        df = self.normalize_coordinates(df)\n",
    "        self.df = df\n",
    "        \n",
    "    def get_time(self, df):\n",
    "        #appends the dataframe with an column time, calculated by index and framerate\n",
    "        df['time'] = np.NaN\n",
    "        df['time'] = df['EarRight'].index/self.framerate\n",
    "\n",
    "        return df\n",
    "        # in future version: check for NaN\n",
    "        \n",
    "    def identify_duplicates(self, df):\n",
    "        #checks for possible duplicates made by the DLC network and excludes them\n",
    "        l_indices = list(df.index)\n",
    "        l_unique_indices = list(set(l_indices))\n",
    "\n",
    "        if len(l_indices) != len(l_unique_indices):\n",
    "            l_duplicates = []\n",
    "            for index in l_unique_indices:\n",
    "                if l_indices.count(index) > 1:\n",
    "                    l_duplicates.append(index)\n",
    "            df.loc[l_duplicates, ('all', 'exclude')] = True\n",
    "\n",
    "        return df\n",
    "\n",
    "    def exclude_frames(self, df):\n",
    "        #excludes frames, where the likelihood is below a certain threshold\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            df.loc[:, (bodypart, 'exclude')] = False\n",
    "            df.loc[df[bodypart]['likelihood'] < self.threshold, (bodypart, 'exclude')] = True\n",
    "            df.loc[df[('all', 'exclude')] == True, (bodypart, 'exclude')] = True\n",
    "        return df\n",
    "    \n",
    "    def rotate(self, xy, theta):\n",
    "        cos_theta, sin_theta = math.cos(theta), math.sin(theta)\n",
    "\n",
    "        return (\n",
    "            xy[0] * cos_theta - xy[1] * sin_theta,\n",
    "            xy[0] * sin_theta + xy[1] * cos_theta\n",
    "        )\n",
    "\n",
    "    def translate(self, xy, offset):\n",
    "        return xy[0] + offset[0], xy[1] + offset[1]\n",
    "\n",
    "\n",
    "    def normalize_coordinates(self, df):\n",
    "        #uses the functions rotate and translate to normalize the coordinates\n",
    "        length = self.results['length']\n",
    "        width = self.results['width']\n",
    "        offset_to_standard = (-self.results['offset_x'], -self.results['offset_y'])\n",
    "        offset_from_standard = (self.results['offset_x'], self.results['offset_y'])\n",
    "        theta_to_standard = -self.results['theta']\n",
    "\n",
    "\n",
    "        length_in_px = length\n",
    "        cm_per_px = self.maze_length_in_cm/length_in_px\n",
    "\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            df[(bodypart, 'x_norm')] = self.translate(self.rotate((df[(bodypart,'x')], df[(bodypart,'y')]), theta_to_standard), offset_to_standard)[0]\n",
    "            df[(bodypart, 'y_norm')] = self.translate(self.rotate((df[(bodypart,'x')], df[(bodypart,'y')]), theta_to_standard), offset_to_standard)[1]\n",
    "            df[(bodypart, 'x_norm_cm')] = 3 - (df[(bodypart, 'x_norm')] * cm_per_px)\n",
    "            df[(bodypart, 'y_norm_cm')] = 50 - (df[(bodypart, 'y_norm')] * cm_per_px)\n",
    "\n",
    "        return df    \n",
    "\n",
    "    \n",
    "    def get_center_of_gravity(self, df):\n",
    "        #calculates the center of gravity, if it is not labeled in DLC\n",
    "        df.loc[(df[('all', 'exclude')] == False) & (df[('EarRight', 'exclude')] == False) & (df[('EarLeft', 'exclude')] == False) & (df[('TailBase', 'exclude')] == False), \n",
    "           ('CenterOfGravity', 'x')] = (df.loc[df[('all', 'exclude')] == False, ('EarRight', 'x')] + \n",
    "                                          df.loc[df[('all', 'exclude')] == False, ('EarLeft', 'x')] + \n",
    "                                          df.loc[df[('all', 'exclude')] == False, ('TailBase', 'x')]) / 3\n",
    "\n",
    "        df.loc[(df[('all', 'exclude')] == False) & (df[('EarRight', 'exclude')] == False) & (df[('EarLeft', 'exclude')] == False) & (df[('TailBase', 'exclude')] == False), \n",
    "           ('CenterOfGravity', 'y')] = (df.loc[df[('all', 'exclude')] == False, ('EarRight', 'y')] + \n",
    "                                          df.loc[df[('all', 'exclude')] == False, ('EarLeft', 'y')] + \n",
    "                                          df.loc[df[('all', 'exclude')] == False, ('TailBase', 'y')]) / 3\n",
    "\n",
    "        df[('CenterOfGravity', 'exclude')] = False\n",
    "        df.loc[(df[('CenterOfGravity', 'x')].isnull()) | (df[('CenterOfGravity', 'y')].isnull()), ('CenterOfGravity', 'exclude')] = True\n",
    "\n",
    "        self.l_bodyparts.append('CenterOfGravity')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4374cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class df_functions(bottom_cam, top_cam, side_cam):\n",
    "    \"\"\"class that returns the dataframe appended with the chosen target variables after calling several functions and combines different recording modalities\"\"\"\n",
    "    immobility_threshold = 16\n",
    "\n",
    "    min_freezing_duration = 1\n",
    "\n",
    "    TIME_OF_GAIT_BEFORE_DISRUPT = 0.5\n",
    "    TARGET_TIME_GAIT_DISRUPTION = 0.2\n",
    "    \n",
    "    def __init__(self, subject, session, dict_selected_functions):\n",
    "        #loops through the functions for each dataframe\n",
    "        self.session = session\n",
    "        self.subject = subject\n",
    "        self.dict_selected_functions = dict_selected_functions\n",
    "        self.l_dfs = []\n",
    "        if main.dict_cams_used[\"bottom_cam\"]:\n",
    "            df = session.bc.processed_df\n",
    "            self.l_bodyparts = main.dict_bodyparts[\"bottom_cam\"]\n",
    "            self.framerate = session.bc.framerate\n",
    "            \n",
    "            df = self.get_speed_and_rolling_speed(df)\n",
    "            df = self.get_immobility(df)\n",
    "            if dict_selected_functions[\"Anxiety\"]:\n",
    "                df = self.get_freezing_bouts(df)\n",
    "                df = self.get_freezing_avg(df)\n",
    "            if dict_selected_functions[\"Parkinson\"]:\n",
    "                df = self.get_direction_bc(df)\n",
    "                df = self.get_gait_disruption_bouts(df)\n",
    "                df = self.get_gait_disruption_avg(df)\n",
    "            self.l_dfs.append(df)\n",
    "            \n",
    "        if main.dict_cams_used[\"top_cam\"]:\n",
    "            self.l_bodyparts = main.dict_bodyparts[\"top_cam\"]\n",
    "            df = session.tc.processed_df\n",
    "            self.framerate = session.tc.framerate\n",
    "            df = self.get_speed_and_rolling_speed(df)\n",
    "            df = self.get_immobility(df)\n",
    "            if dict_selected_functions[\"Anxiety\"]:\n",
    "                df = self.get_freezing_bouts(df)\n",
    "                df = self.get_freezing_avg(df)\n",
    "            if dict_selected_functions[\"Parkinson\"]:\n",
    "                df = self.get_direction_tc(df)\n",
    "                df = self.get_gait_disruption_bouts(df)\n",
    "                df = self.get_gait_disruption_avg(df)\n",
    "            self.l_dfs.append(df)\n",
    "            \n",
    "            \n",
    "        if main.dict_cams_used[\"side_cam\"]:\n",
    "            self.l_bodyparts = main.dict_bodyparts[\"side_cam\"]\n",
    "            self.framerate = session.sc.framerate\n",
    "            \n",
    "            self.l_dfs.append(df)\n",
    "        \n",
    "        self.combined_df = self.combine_cam_dfs()\n",
    "        self.combined_df = self.add_metadata(self.combined_df)\n",
    "        self.master_df = self.get_master_df()\n",
    "                \n",
    "    \n",
    "    def get_speed_and_rolling_speed(self, df):\n",
    "        #calcualtes speed for the bodyparts\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            df[(bodypart, 'speed_px_per_s')] = np.NaN\n",
    "            df[(bodypart, 'rolling_speed_px_per_s')] = np.NaN\n",
    "\n",
    "            # Limitation: since we have to exclude some frames, these calculations are not made frame by frame (yet for most)\n",
    "            df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'speed_px_per_s')] = (((df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'x')].diff()**2                                                                                                        + df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'y')].diff()**2)**(1/2)) \n",
    "                                                                                                                             / df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), 'time'].diff())\n",
    "            df.loc[(df[('all', 'exclude')] == False) & (df[(bodypart, 'exclude')] == False), (bodypart, 'rolling_speed_px_per_s')] = df.loc[df[('all', 'exclude')] == False, (bodypart, 'speed_px_per_s')].rolling(5, min_periods=3, center=True).mean()\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def get_direction_bc(self, df): \n",
    "        #calculates the direction of the animal and appends the dataframe by a direction column\n",
    "        #used Snout instead of EarLeft & EarRight (less secure parameter?, but better suitable for BottomCam?)\n",
    "            #could also synchronize with top Cam data and use direction from there\n",
    "        df[('moving_towards_maze_end', '')] = False\n",
    "        df.loc[(df[('Snout', 'y_norm')] < df[('TailBase', 'y_norm')]), ('moving_towards_maze_end', '')] = True\n",
    "        #df.loc[(df[('Snout', 'y_norm')] < df[('CenterOfGravity', 'y_norm')]), ('moving_towards_maze_end', '')] = True\n",
    "        return df\n",
    "    \n",
    "    def get_direction_tc(self, df):\n",
    "        #calculates the direction of the animal and appends the dataframe by a direction column\n",
    "        df[('moving_towards_maze_end', '')] = False\n",
    "        df.loc[(df[('EarRight', 'y_norm')] < df[('CenterOfGravity', 'y_norm')]) & (df[('EarLeft', 'y_norm')] < df[('CenterOfGravity', 'y_norm')]), ('moving_towards_maze_end', '')] = True\n",
    "        return df\n",
    "    \n",
    "    def get_direction_sc(self, df):\n",
    "        pass\n",
    "    \n",
    "    def get_immobility(self, df):\n",
    "        #checks for immobility\n",
    "        for bodypart in self.l_bodyparts:\n",
    "            # create 'immobility' column and set base value to false\n",
    "            df.loc[ :, (bodypart, 'immobility')] = False\n",
    "            df.loc[df[(bodypart,'rolling_speed_px_per_s')] < self.immobility_threshold, (bodypart, 'immobility')] = True\n",
    "        return df\n",
    "        \n",
    "    def get_gait_disruption_bouts(self, df):\n",
    "        #checks for gait disruption bouts\n",
    "        df[('GaitDisruption_bout', '')] = False\n",
    "        df[('GaitDisruption_bout', 'count')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'duration')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'mean_x_norm_cm')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'mean_y_norm_cm')] = np.NaN\n",
    "        df[('GaitDisruption_bout', 'direction_bool')] = ''\n",
    "        df[('GaitDisruption_bout', 'direction_mean')] = np.NaN\n",
    "\n",
    "        if self.dict_selected_functions[\"Anxiety\"] == False:\n",
    "            df['all_freezing_bodyparts_immobile'] = df[[('EarRight', 'immobility'), ('EarLeft', 'immobility'), ('CenterOfGravity', 'immobility')]].all(axis=1)\n",
    "        \n",
    "        l_timesteps = []\n",
    "        if self.framerate%1 != 0:\n",
    "            print(\"gait disruption bout calculations are invalid due to framerate with decimal places\")\n",
    "        for i in range(int(self.framerate)):\n",
    "            l_timesteps.append(i/self.framerate)\n",
    "\n",
    "        time_gait_disruption = self.find_nearest(np.asarray(l_timesteps), self.TARGET_TIME_GAIT_DISRUPTION)\n",
    "        frames_difference = l_timesteps.index(time_gait_disruption)\n",
    "\n",
    "        gait_disruption_threshold_reached = df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].iloc[np.where(np.round(df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].diff(frames_difference).values, 7) == round(time_gait_disruption, 7))[0]].values\n",
    "\n",
    "        # could still throw an error if only a single frame, because of slicing to find first and last index of each interval?    \n",
    "        if gait_disruption_threshold_reached.shape[0] > 0:\n",
    "            indices = np.asarray(df.loc[df['time'].isin(gait_disruption_threshold_reached)].index)\n",
    "            lower_end = (indices+1)[:-1]\n",
    "            upper_end = indices[1:]\n",
    "            mask = lower_end < upper_end\n",
    "            mask_last = np.concatenate([mask, np.array([True])])\n",
    "            mask_first = np.concatenate([np.array([True]), mask])\n",
    "\n",
    "            last_value_of_intervals = indices[mask_last]\n",
    "            first_value_of_intervals = indices[mask_first]\n",
    "            \n",
    "            first_value_of_intervals = first_value_of_intervals-l_timesteps.index(self.find_nearest(np.asarray(l_timesteps), self.TARGET_TIME_GAIT_DISRUPTION))\n",
    "\n",
    "            interval_ranges = np.column_stack([first_value_of_intervals,last_value_of_intervals])\n",
    "\n",
    "            frames_prior_to_interval_start = l_timesteps.index(self.find_nearest(np.asarray(l_timesteps), self.TIME_OF_GAIT_BEFORE_DISRUPT))\n",
    "            bout_count = 0\n",
    "\n",
    "            if interval_ranges.shape[0] > 0:\n",
    "                for first_idx, last_idx in interval_ranges:\n",
    "                    start_idx_gait_check = first_idx - frames_prior_to_interval_start\n",
    "                    if df.loc[start_idx_gait_check:first_idx-1, 'all_freezing_bodyparts_immobile'].any() == False:\n",
    "                        bout_count = bout_count + 1\n",
    "                        bout_duration = (df.loc[last_idx, 'time'] - df.loc[first_idx, 'time'])[0]\n",
    "                        mean_pos_x_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'x_norm_cm')].mean()\n",
    "                        mean_pos_y_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'y_norm_cm')].mean()\n",
    "                        direction_bool = df.loc[first_idx:last_idx, ('moving_towards_maze_end', '')].all()\n",
    "                        direction_mean = df.loc[first_idx:last_idx, ('moving_towards_maze_end', '')].mean()\n",
    "\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', '')] = True\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'count')] = bout_count\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'duration')] = bout_duration\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'mean_x_norm_cm')] = mean_pos_x_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'mean_y_norm_cm')] = mean_pos_y_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'direction_bool')] = direction_bool\n",
    "                        df.loc[first_idx:last_idx, ('GaitDisruption_bout', 'direction_mean')] = direction_mean\n",
    "\n",
    "        return df\n",
    "        \n",
    "    def find_nearest(self, array, value):\n",
    "        array = np.asarray(array)\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "        return array[idx]\n",
    "\n",
    "    # f체r verschiedene Cams anpassen?\n",
    "    def get_freezing_bouts(self, df):\n",
    "        #checks for freezing bouts\n",
    "        df[('Freezing_bout', '')] = False\n",
    "        df[('Freezing_bout', 'count')] = np.NaN\n",
    "        df[('Freezing_bout', 'duration')] = np.NaN\n",
    "        df[('Freezing_bout', 'mean_x_norm_cm')] = np.NaN\n",
    "        df[('Freezing_bout', 'mean_y_norm_cm')] = np.NaN\n",
    "\n",
    "        df['all_freezing_bodyparts_immobile'] = df[[('EarRight', 'immobility'), ('EarLeft', 'immobility'), ('CenterOfGravity', 'immobility')]].all(axis=1)\n",
    "\n",
    "        times_where_freezing_threshold_was_reached = df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].iloc[np.where(df.loc[df['all_freezing_bodyparts_immobile'] == True, 'time'].diff(self.framerate).values == 1)[0]].values\n",
    "\n",
    "        # could still throw an error if only a single frame, because of slicing to find first and last index of each interval?\n",
    "        if times_where_freezing_threshold_was_reached.shape[0] > 0:\n",
    "            indices = np.asarray(df.loc[df['time'].isin(times_where_freezing_threshold_was_reached)].index)\n",
    "            lower_end = (indices+1)[:-1]\n",
    "            upper_end = indices[1:]\n",
    "            mask = lower_end < upper_end\n",
    "            mask_last = np.concatenate([mask, np.array([True])])\n",
    "            mask_first = np.concatenate([np.array([True]), mask])\n",
    "\n",
    "            last_value_of_intervals = indices[mask_last]\n",
    "            first_value_of_intervals = indices[mask_first]\n",
    "\n",
    "            first_value_of_intervals = first_value_of_intervals-self.framerate\n",
    "\n",
    "            interval_ranges = np.column_stack([first_value_of_intervals,last_value_of_intervals])\n",
    "\n",
    "            bout_count = 0\n",
    "\n",
    "            if interval_ranges.shape[0] > 0:\n",
    "                for first_idx, last_idx in interval_ranges:\n",
    "                        bout_count = bout_count + 1\n",
    "                        bout_duration = (df.loc[last_idx, 'time'] - df.loc[first_idx, 'time'])[0]\n",
    "                        mean_pos_x_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'x_norm_cm')].mean()\n",
    "                        mean_pos_y_norm_cm = df.loc[first_idx:last_idx, ('CenterOfGravity', 'y_norm_cm')].mean()\n",
    "\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', '')] = True\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'count')] = bout_count\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'duration')] = bout_duration\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'mean_x_norm_cm')] = mean_pos_x_norm_cm\n",
    "                        df.loc[first_idx:last_idx, ('Freezing_bout', 'mean_y_norm_cm')] = mean_pos_y_norm_cm\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def get_freezing_avg(self, df):\n",
    "        #calculates the session average for freezing\n",
    "        freezing_bout_count = df[('Freezing_bout', 'count')].unique().shape[0] - 1\n",
    "\n",
    "        if freezing_bout_count > 0:\n",
    "            df[('whole_session', 'percentage_time_spent_freezing')] = (df.loc[df[('Freezing_bout', '')] == True].shape[0] / df.shape[0]) * 100\n",
    "            df[('whole_session', 'median_freezing_bout_duration')] = np.nanmedian(df[('Freezing_bout', 'duration')].unique())\n",
    "            df[('whole_session', 'median_x_norm_cm_all_freezing_bouts')] = np.nanmedian(df[('Freezing_bout', 'mean_x_norm_cm')].unique())\n",
    "            df[('whole_session', 'median_y_norm_cm_all_freezing_bouts')] = np.nanmedian(df[('Freezing_bout', 'mean_y_norm_cm')].unique())\n",
    "        else:\n",
    "            df[('whole_session', 'percentage_time_spent_freezing')] = 0\n",
    "            df[('whole_session', 'median_freezing_bout_duration')] = np.NaN\n",
    "            df[('whole_session', 'median_x_norm_cm_all_freezing_bouts')] = np.NaN\n",
    "            df[('whole_session', 'median_y_norm_cm_all_freezing_bouts')] = np.NaN       \n",
    "            \n",
    "        return df\n",
    "            \n",
    "    def get_gait_disruption_avg(self, df):\n",
    "        #calculates the session average for gait disruption\n",
    "        gait_disruption_bout_count = df[('GaitDisruption_bout', 'count')].unique().shape[0] - 1\n",
    "\n",
    "        if gait_disruption_bout_count > 0:\n",
    "            df[('whole_session', 'percentage_time_spent_gait_disrupted')] = (df.loc[df[('GaitDisruption_bout', '')] == True].shape[0] / df.shape[0]) * 100\n",
    "            df[('whole_session', 'median_gait_disruption_bout_duration')] = np.nanmedian(df[('GaitDisruption_bout', 'duration')].unique())\n",
    "            df[('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')] = np.nanmedian(df[('GaitDisruption_bout', 'mean_x_norm_cm')].unique())\n",
    "            df[('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts')] = np.nanmedian(df[('GaitDisruption_bout', 'mean_y_norm_cm')].unique())\n",
    "        else:\n",
    "            df[('whole_session', 'percentage_time_spent_gait_disrupted')] = 0\n",
    "            df[('whole_session', 'median_gait_disruption_bout_duration')] = np.NaN\n",
    "            df[('whole_session', 'median_x_norm_cm_all_gait_disruption_bouts')] = np.NaN\n",
    "            df[('whole_session', 'median_y_norm_cm_all_gait_disruption_bouts')] = np.NaN\n",
    "\n",
    "        return df\n",
    "\n",
    "    def combine_cam_dfs(self):\n",
    "        #combines the data from different recording modalities. not yet implemented. requires class bodyparts\n",
    "        if len(self.l_dfs) == 1:\n",
    "            combined_df = self.l_dfs[0]\n",
    "            return combined_df\n",
    "        else:\n",
    "            #crazy function to combine input of all cams using self.l_dfs\n",
    "            #or the bodypart class\n",
    "            #return combined_df \n",
    "            pass\n",
    "        \n",
    "    def add_metadata(self, df):\n",
    "        #adds metadata to the dataframe\n",
    "        df['subject_ID'] = self.subject.subject_ID\n",
    "        df['group_ID'] = self.subject.group_ID\n",
    "        df['trialnumber'] = 1 #muss noch implementiert werden!\n",
    "        df['DateOfRecording'] = self.session.date\n",
    "        df['paradigm'] = self.session.paradigm\n",
    "        return df\n",
    "    \n",
    "    def get_master_df(self):\n",
    "        #combines all the information into a master_df as specified by col_in_precessed_df\n",
    "        d_for_master_df = {}\n",
    "\n",
    "        for key, col_in_processed_df in main.col_in_master_df:\n",
    "            d_for_master_df[key] = self.combined_df[col_in_processed_df].values\n",
    "\n",
    "        master_df = pd.DataFrame(data=d_for_master_df)\n",
    "        return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e4ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maze_corners(bottom_cam, top_cam):   \n",
    "    \"\"\"creates an object representing the maze_corners\"\"\"\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        cap = cv2.VideoCapture(self.filepath)\n",
    "        self.ret, self.frame = cap.read()\n",
    "        self.results = {}\n",
    "        cap.release()\n",
    "        \n",
    "        \n",
    "    def rotate(self, xy, theta):\n",
    "        cos_theta, sin_theta = math.cos(theta), math.sin(theta)\n",
    "\n",
    "        return (\n",
    "            xy[0] * cos_theta - xy[1] * sin_theta,\n",
    "            xy[0] * sin_theta + xy[1] * cos_theta\n",
    "        )\n",
    "\n",
    "    def translate(self, xy, offset):\n",
    "        return xy[0] + offset[0], xy[1] + offset[1]\n",
    "\n",
    "    def f(self, x, y, length, width, degrees):\n",
    "        offset = (x, y)\n",
    "        corners = [(0, 0), (width, 0), (width, length), (0, length)]\n",
    "        rotated_and_shifted_corners = [self.translate(self.rotate(xy, math.radians(degrees)), offset) for xy in corners]\n",
    "\n",
    "        end_right_corner = list(rotated_and_shifted_corners[0]) + ['red']\n",
    "        end_left_corner = list(rotated_and_shifted_corners[1]) + ['orange']\n",
    "        start_left_corner = list(rotated_and_shifted_corners[2]) + ['cyan']\n",
    "        start_right_corner = list(rotated_and_shifted_corners[3]) + ['green']\n",
    "\n",
    "        fig = plt.figure(figsize=(18, 10))\n",
    "        gs = fig.add_gridspec(2, 4)\n",
    "\n",
    "        fig.add_subplot(gs[0:2, 0:2])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.ylim(0,self.frame.shape[0])\n",
    "        plt.xlim(0,self.frame.shape[1])\n",
    "\n",
    "        if len(self.results.keys()) > 0:\n",
    "            saved_current = 'saved'\n",
    "        else:\n",
    "            saved_current = 'missing'\n",
    "\n",
    "        plt.title('current file: {} (analysis {})'.format(self.filepath, saved_current))\n",
    "\n",
    "        l_corners = [start_right_corner, start_left_corner, end_right_corner, end_left_corner]\n",
    "\n",
    "        for corner in l_corners:\n",
    "            plt.scatter(corner[0], corner[1], c=corner[2], s=100)\n",
    "\n",
    "        fig.add_subplot(gs[0, 2])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[0][0], l_corners[0][1], c=l_corners[0][2], s=100)\n",
    "        plt.xlim(l_corners[0][0]-25, l_corners[0][0]+25)\n",
    "        plt.ylim(l_corners[0][1]-25, l_corners[0][1]+25)\n",
    "        plt.title('start right corner')\n",
    "\n",
    "        fig.add_subplot(gs[0, 3])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[1][0], l_corners[1][1], c=l_corners[1][2], s=100)\n",
    "        plt.xlim(l_corners[1][0]-25, l_corners[1][0]+25)\n",
    "        plt.ylim(l_corners[1][1]-25, l_corners[1][1]+25)\n",
    "        plt.title('start left corner')\n",
    "\n",
    "        fig.add_subplot(gs[1, 2])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[2][0], l_corners[2][1], c=l_corners[2][2], s=100)\n",
    "        plt.xlim(l_corners[2][0]-25, l_corners[2][0]+25)\n",
    "        plt.ylim(l_corners[2][1]-25, l_corners[2][1]+25)\n",
    "        plt.title('end right corner')\n",
    "\n",
    "        fig.add_subplot(gs[1, 3])\n",
    "        plt.imshow(self.frame)\n",
    "        plt.scatter(l_corners[3][0], l_corners[3][1], c=l_corners[3][2], s=100)\n",
    "        plt.xlim(l_corners[3][0]-25, l_corners[3][0]+25)\n",
    "        plt.ylim(l_corners[3][1]-25, l_corners[3][1]+25)\n",
    "        plt.title('end left corner')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b694fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gui():\n",
    "    \"\"\"represents the GUI\"\"\"\n",
    "    main_tab = widgets.Tab()   \n",
    "    tab_index = -1\n",
    "    displayed = False\n",
    "    \n",
    "    class main_gui(main):\n",
    "        \"\"\"creates a main object as specified by the path input and recording modalities\"\"\"\n",
    "        def __init__(self):\n",
    "            self.path = \"\"\n",
    "            folder_select = widgets.Button(description=\"Select folder\", layout=widgets.Layout(width=\"auto\"))\n",
    "            folder_select.on_click(self.select_folder)\n",
    "            \n",
    "            select_recording_modalities = widgets.Label(value=\"Select recording modalities\", layout=widgets.Layout(width=\"auto\"))\n",
    "            self.bottom_cam_check = widgets.Checkbox(value=False, description='Bottom Cam', layout=widgets.Layout(width=\"auto\"))\n",
    "            self.top_cam_check = widgets.Checkbox(value=False, description='Top Cam', layout=widgets.Layout(width=\"auto\"))\n",
    "            self.side_cam_check = widgets.Checkbox(value=False, description='Side Cam', disabled = True, layout=widgets.Layout(width=\"auto\"))\n",
    "            \n",
    "            confirm_button = widgets.Button(description = \"Confirm Settings\", layout=widgets.Layout(width=\"auto\"))\n",
    "            confirm_button.on_click(self.confirm_settings)\n",
    "            \n",
    "            col0 = VBox([folder_select])\n",
    "            col1 = VBox([select_recording_modalities, self.bottom_cam_check, self.top_cam_check, self.side_cam_check])\n",
    "            col2 = VBox([confirm_button])\n",
    "            box = HBox([col0, col1, col2])\n",
    "            gui.main_tab.children = [box]\n",
    "            gui.tab_index += 1\n",
    "            gui.main_tab.set_title(gui.tab_index, \"General Settings\")\n",
    "            display(gui.main_tab)\n",
    "            gui.displayed = True\n",
    "            gui.main_tab.selected_index = gui.tab_index\n",
    "\n",
    "        def select_folder(self, b):\n",
    "            root = Tk()\n",
    "            root.withdraw()\n",
    "            root.call('wm', 'attributes', '.', '-topmost', True)\n",
    "            self.path = filedialog.askdirectory() + \"/\"\n",
    "            display(self.path)        \n",
    "            \n",
    "        def confirm_settings(self, b):\n",
    "            if self.path == \"\":\n",
    "                display(\"Set the path before continuing!\")\n",
    "            else:\n",
    "                gui.a = main(path = self.path, dict_cams_used= {\"bottom_cam\": self.bottom_cam_check.value, \"top_cam\": self.top_cam_check.value, \"side_cam\": self.side_cam_check.value}, gui=True)\n",
    "                gui.a.all_information_given()\n",
    "                if gui.a.all_files_there == True:\n",
    "                    gui.subject_gui()\n",
    "        \n",
    "    class subject_gui(main):\n",
    "        \"\"\"allows to allocate subjects to groups\"\"\"\n",
    "        def __init__(self):\n",
    "            self.num_of_groups_dropdown = widgets.Dropdown(options=[1, 2, 3, 4, 5, 6], value=2, description='Choose, how many groups you have in your dataset', layout=widgets.Layout(width=\"auto\"), style={'description_width': 'auto'})\n",
    "            confirm_groups_button = widgets.Button(description='Confirm number of groups', layout=widgets.Layout(width=\"auto\"))\n",
    "            confirm_groups_button.on_click(self.name_groups)\n",
    "            row0 = HBox([self.num_of_groups_dropdown, confirm_groups_button])\n",
    "            box = VBox([row0])\n",
    "            gui.main_tab.children += (box, ) \n",
    "            gui.tab_index += 1\n",
    "            gui.main_tab.set_title(gui.tab_index, \"Subjects to groups\")\n",
    "            gui.main_tab.selected_index = gui.tab_index\n",
    "            \n",
    "        def name_groups(self, b):\n",
    "            self.num_of_groups = self.num_of_groups_dropdown.value\n",
    "            self.l_group_texts = [widgets.Text(value = 'group {}'.format(n), description='Name of group {}'.format(n), layout=widgets.Layout(width=\"auto\"), style = {'description_width': 'auto'}) for n in range (self.num_of_groups)]\n",
    "            name_subjects_button = widgets.Button(description = \"Confirm name of the groups\", layout=widgets.Layout(width=\"auto\"))\n",
    "            name_subjects_button.on_click(self.subjects_to_groups)\n",
    "            box = HBox([VBox(self.l_group_texts), name_subjects_button])\n",
    "            gui.main_tab.children[gui.tab_index].children += (box,)\n",
    "\n",
    "            \n",
    "        def subjects_to_groups(self, b):\n",
    "            l_subject_label = [widgets.Label(value=subject.subject_ID, layout=widgets.Layout(width=\"auto\")) for subject in gui.a.l_subjects]\n",
    "            self.l_group_toggle_buttons = [widgets.ToggleButtons(options = [text.value for text in self.l_group_texts], layout=widgets.Layout(width=\"auto\")) for subject in range(len(gui.a.l_subjects))]\n",
    "            continue_button = widgets.Button(description = \"All subjects in the right group\", layout=widgets.Layout(width=\"auto\"))\n",
    "            continue_button.on_click(self.next_step)\n",
    "            col0 = VBox(l_subject_label)\n",
    "            col1 = VBox(self.l_group_toggle_buttons)\n",
    "            box = HBox([col0, col1, continue_button])\n",
    "            gui.main_tab.children[gui.tab_index].children += (box,)\n",
    "            \n",
    "        def next_step(self, b):\n",
    "            l_groups = [self.l_group_texts[n].value for n in range(len(self.l_group_texts))]\n",
    "            gui.a.subjects_to_groups({subject.subject_ID:self.l_group_toggle_buttons[n].value for subject, n in zip (gui.a.l_subjects, range(len(gui.a.l_subjects)))}, l_groups)\n",
    "            gui.a.get_maze_corners()\n",
    "        \n",
    "    class bc_gui(main):\n",
    "        def __init__(self):\n",
    "            #defish\n",
    "            pass\n",
    "    class tc_gui(main):\n",
    "        def __init__(self):\n",
    "            #?\n",
    "            pass\n",
    "    class sc_gui(main):\n",
    "        def __init__(self):\n",
    "            # stitch\n",
    "            pass\n",
    "            \n",
    "    class select_functions(main):\n",
    "        \"\"\"allows to select the target variables, that will be analysed\"\"\"\n",
    "        def __init__(self):\n",
    "            select_functions = widgets.Label(value=\"Select functions in which you're interested in\", layout=widgets.Layout(width=\"auto\"), style = {'description_width': 'auto'})\n",
    "            self.anxiety_check = widgets.Checkbox(value=False, description='Anxiety', layout=widgets.Layout(width=\"auto\"))\n",
    "            self.parkinson_check = widgets.Checkbox(value=False, description='Parkinson', layout=widgets.Layout(width=\"auto\"))\n",
    "            \n",
    "            self.l_checkboxes = [self.anxiety_check, self.parkinson_check]\n",
    "\n",
    "            confirm_selection_button = widgets.Button(description = \"Confirm Selection\", layout=widgets.Layout(width=\"auto\"))\n",
    "            confirm_selection_button.on_click(self.confirm_selection)\n",
    "\n",
    "            col0 = VBox([select_functions, self.anxiety_check, self.parkinson_check])\n",
    "            col1 = VBox([confirm_selection_button])\n",
    "            box = HBox([col0, col1])\n",
    "            gui.main_tab.children += (box, ) \n",
    "            gui.tab_index += 1\n",
    "            gui.main_tab.set_title(gui.tab_index, \"Select Functions\")\n",
    "            gui.main_tab.selected_index = gui.tab_index\n",
    "\n",
    "        def confirm_selection(self, b):\n",
    "            l_selected_functions_values = [checkbox.value for checkbox in self.l_checkboxes]\n",
    "            l_selected_functions_keys = [checkbox.description for checkbox in self.l_checkboxes]\n",
    "            dict_selected_functions = {key:value for key,value in zip(l_selected_functions_keys,l_selected_functions_values)}\n",
    "            gui.a.execute_functions(dict_selected_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bc658d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maze_corner_gui(main):\n",
    "    \"\"\"creates the GUI for annotation maze corners, used in GUI as well as GUI-less usage\"\"\"\n",
    "    def __init__(self):\n",
    "        self.maze_corner_idx = 0\n",
    "        self.actualize()\n",
    "        self.clean_df = False\n",
    "        self.create_gui()\n",
    "\n",
    "    def on_load_next_button_click(self, b):\n",
    "        if self.results_saved:\n",
    "            if self.maze_corner_idx >= (len(main.l_maze_corners)-1):\n",
    "                #check, whether all Maze Corners are saved to bc.mc.results\n",
    "                if self.clean_df == False:\n",
    "                    print(\"Maze Corners for all videos set.\")\n",
    "                    main.get_processed_dfs(main)\n",
    "                    self.clean_df = True\n",
    "                    print(\"Dataframes cleaned.\")\n",
    "                    if main.gui == True:\n",
    "                        gui.select_functions()\n",
    "                else: \n",
    "                    self.maze_corner_idx += 1\n",
    "                    self.actualize()\n",
    "        else:\n",
    "            display(\"Please save the settings before continuing!\")\n",
    "\n",
    "    def on_load_previous_button_click(self, b):\n",
    "        if self.maze_corner_idx <= 0:\n",
    "            display(\"Index out of range! Index has been set to 0.\")\n",
    "            self.maze_corner_idx = 0\n",
    "        else:\n",
    "            if self.results_saved:\n",
    "                self.maze_corner_idx -= 1\n",
    "                self.actualize()\n",
    "            else:\n",
    "                display(\"Please save the settings before continuing!\")\n",
    "\n",
    "    def actualize(self):\n",
    "        self.results_saved = False\n",
    "\n",
    "    def on_save_button_click(self, b):\n",
    "        main.l_maze_corners[self.maze_corner_idx].results[\"offset_x\"] = self.interactive_plot.children[0].value\n",
    "        main.l_maze_corners[self.maze_corner_idx].results[\"offset_y\"] = self.interactive_plot.children[1].value\n",
    "        main.l_maze_corners[self.maze_corner_idx].results[\"length\"] = self.interactive_plot.children[2].value\n",
    "        main.l_maze_corners[self.maze_corner_idx].results[\"width\"] = self.interactive_plot.children[3].value\n",
    "        main.l_maze_corners[self.maze_corner_idx].results[\"theta\"] = math.radians(self.interactive_plot.children[4].value)\n",
    "        self.results_saved = True\n",
    "\n",
    "    def create_gui(self):\n",
    "        width, height = main.l_maze_corners[self.maze_corner_idx].frame.shape[0], main.l_maze_corners[self.maze_corner_idx].frame.shape[1]#replace slider with int, since slider are very slow\n",
    "        slider_x = widgets.IntSlider(value=300, min=0, max=width, step=1, description='x offset', continuous_update=False)\n",
    "        slider_y = widgets.IntSlider(value=5, min=0, max=height, step=1, description='y offset', continuous_update=False)\n",
    "        slider_length = widgets.IntSlider(value=height/2, min=0, max=height*1.5, step=1, continuous_update=False)\n",
    "        slider_width = widgets.IntSlider(value=width/20, min=0, max=width/7, step=1, continuous_update=False)\n",
    "        slider_degrees = widgets.FloatSlider(value=0, min=0, max=90, step=0.1, continuous_update=False)\n",
    "\n",
    "        self.interactive_plot = interactive(main.l_maze_corners[self.maze_corner_idx].f, x=slider_x, y=slider_y, length=slider_length, width=slider_width, degrees=slider_degrees)\n",
    "\n",
    "        self.interactive_plot.children[-1].layout.height = '600px'\n",
    "\n",
    "        load_next_button = widgets.Button(description=\"Load next file\", style = {'description_width': 'auto'})\n",
    "        save_button = widgets.Button(description=\"Save settings\", style = {'description_width': 'auto'})\n",
    "        load_previous_button = widgets.Button(description=\"Load previous file\", style = {'description_width': 'auto'})\n",
    "\n",
    "        load_next_button.on_click(self.on_load_next_button_click)\n",
    "        load_previous_button.on_click(self.on_load_previous_button_click)\n",
    "        save_button.on_click(self.on_save_button_click)\n",
    "\n",
    "        col0 = VBox([load_next_button, save_button])\n",
    "        col1 = VBox([self.interactive_plot.children[0], self.interactive_plot.children[1]])\n",
    "        col2 = VBox([self.interactive_plot.children[2], self.interactive_plot.children[3]])\n",
    "        col3 = VBox([self.interactive_plot.children[4], load_previous_button])\n",
    "        row0 = HBox([col0, col1, col2, col3])\n",
    "        box = VBox([row0, self.interactive_plot.children[-1]])\n",
    "\n",
    "        gui.main_tab.children += (box, ) \n",
    "        gui.tab_index += 1\n",
    "        gui.main_tab.set_title(gui.tab_index, \"Set Maze Corners\")\n",
    "        gui.main_tab.selected_index = gui.tab_index\n",
    "    \n",
    "class stats_gui(main):\n",
    "    \"\"\"allows to choose and individualize the stats\"\"\"\n",
    "    output_path = \"\"\n",
    "\n",
    "    def __init__(self, dict_selected_functions):\n",
    "        self.dict_selected_functions = dict_selected_functions\n",
    "        self.select_stats_dropdown = widgets.RadioButtons(options=[\"basic\", \"all\", \"select\"], value=\"basic\", description = \"Choose, which statistics you want to plot\", layout=widgets.Layout(width=\"auto\"), style = {'description_width': 'auto'})\n",
    "\n",
    "        confirm_button = widgets.Button(description = \"Confirm\", layout=widgets.Layout(width=\"auto\"))\n",
    "        confirm_button.on_click(self.confirm)\n",
    "\n",
    "        enter_path = widgets.Button(description=\"Select output folder\", layout=widgets.Layout(width=\"auto\"))\n",
    "        enter_path.on_click(self.select_output_path)\n",
    "\n",
    "        select_ind_var_label = widgets.Label(value=\"Select independent variable\", layout=widgets.Layout(width=\"auto\"))\n",
    "        self.select_ind_variable = widgets.Dropdown(options = [\"group_ID\", \"trialnumber\", \"paradigm\"], layout=widgets.Layout(width=\"auto\"))\n",
    "        select_hue_label = widgets.Label(value=\"Select hue\", layout=widgets.Layout(width=\"auto\"))\n",
    "        self.select_hue = widgets.Dropdown(options = [\"subject_ID\", \"paradigm\", \"group_ID\"], layout=widgets.Layout(width=\"auto\"))\n",
    "\n",
    "        col0 = VBox([self.select_stats_dropdown, confirm_button])\n",
    "        col1 = VBox([select_ind_var_label, self.select_ind_variable])\n",
    "        col2 = VBox([select_hue_label, self.select_hue])\n",
    "        col3 = VBox ([enter_path])\n",
    "        row0 = HBox([col0, col1, col2, col3])\n",
    "        box = VBox([row0])\n",
    "        gui.main_tab.children += (box, ) \n",
    "        gui.tab_index += 1\n",
    "        gui.main_tab.set_title(gui.tab_index, \"Select Statistics\")\n",
    "        gui.main_tab.selected_index = gui.tab_index\n",
    "\n",
    "    def select_output_path(self, b):\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.call('wm', 'attributes', '.', '-topmost', True)\n",
    "        self.output_path = filedialog.askdirectory() + \"/\"\n",
    "        display(self.output_path)        \n",
    "\n",
    "    def confirm(self, b):\n",
    "        if self.select_stats_dropdown.value == \"select\":\n",
    "            self.select_data_col()\n",
    "        else:\n",
    "            if self.select_stats_dropdown.value == \"basic\":\n",
    "                self.l_selected_data_col = []\n",
    "                if self.dict_selected_functions[\"Anxiety\"]:\n",
    "                    self.l_selected_data_col.extend(['count_freezing_bouts', 'percentage_of_time_spent_freezing', 'mean_freezing_bouts_y_position'])\n",
    "                if self.dict_selected_functions[\"Parkinson\"]:\n",
    "                    self.l_selected_data_col.extend(['mean_gait_disruption_bouts_y_position_all'])\n",
    "                elif self.select_stats_dropdown.value == \"all\":\n",
    "                    self.l_selected_data_col = [key for key in main.d_data.keys() if key not in set(['subject_ID', 'group_ID', 'paradigm', 'trialnumber'])]\n",
    "            l_selected_data_col_dict = []\n",
    "            for data_col in self.l_selected_data_col:\n",
    "                dict_stats = {}\n",
    "                dict_stats[\"data_col\"] = data_col\n",
    "                dict_stats[\"independent_variable\"] =  self.select_ind_variable.value\n",
    "                dict_stats[\"hue\"] =  self.select_hue.value\n",
    "                l_selected_data_col_dict.append(dict_stats)\n",
    "            main.calculate_stats(main, self.output_path, l_selected_data_col_dict)\n",
    "\n",
    "    def select_data_col(self):\n",
    "        confirm_button = widgets.Button(description = \"Confirm\", layout=widgets.Layout(width=\"auto\"))\n",
    "        confirm_button.on_click(self.confirm_selected_data_col)\n",
    "        select_data_key_label = widgets.Label(value=\"Select Data Column\", layout=widgets.Layout(width=\"auto\"))\n",
    "        select_ind_var_label = widgets.Label(value=\"Select independent variable\", layout=widgets.Layout(width=\"auto\"))\n",
    "        select_hue_label = widgets.Label(value=\"Select hue\", layout=widgets.Layout(width=\"auto\"))\n",
    "\n",
    "        l_grid_children = [select_data_key_label, select_ind_var_label, select_hue_label]\n",
    "        for key in main.d_data.keys(): \n",
    "            if key not in set(['subject_ID', 'group_ID', 'paradigm', 'trialnumber']):\n",
    "                l_grid_children.append(widgets.Checkbox(value=False, description=key, layout=widgets.Layout(width=\"auto\")))\n",
    "                l_grid_children.append(widgets.Dropdown(options = [\"group_ID\", \"trialnumber\", \"paradigm\"], value='group_ID', layout=widgets.Layout(width=\"auto\")))\n",
    "                l_grid_children.append(widgets.Dropdown(options = [\"subject_ID\", \"paradigm\", \"group_ID\"], value='subject_ID', layout=widgets.Layout(width=\"auto\")))\n",
    "\n",
    "        enter_path = widgets.Button(description=\"Select output folder\", layout=widgets.Layout(width=\"auto\"))\n",
    "        enter_path.on_click(self.select_output_path)\n",
    "\n",
    "        col3 = VBox([enter_path, confirm_button]) \n",
    "\n",
    "        self.grid = widgets.GridBox(l_grid_children, layout=widgets.Layout(grid_template_columns=\"repeat(3, auto)\"))\n",
    "\n",
    "        box = HBox([self.grid, col3])\n",
    "        gui.main_tab.children[gui.tab_index].children += (box,)\n",
    "        gui.main_tab.children[gui.tab_index].children[0].children = (gui.main_tab.children[gui.tab_index].children[0].children[0], )\n",
    "\n",
    "\n",
    "    def confirm_selected_data_col(self, b):\n",
    "        l_selected_data_col_dict = []\n",
    "        for n in range(len(self.grid.children)):\n",
    "            if n>2 & n%3 == 0:\n",
    "                if self.grid.children[n].value == True:\n",
    "                    dict_stats = {}\n",
    "                    dict_stats[\"data_col\"] = self.grid.children[n].description\n",
    "                    dict_stats[\"independent_variable\"] =  self.grid.children[n+1].value\n",
    "                    dict_stats[\"hue\"] =  self.grid.children[n+2].value\n",
    "                    l_selected_data_col_dict.append(dict_stats)\n",
    "        main.calculate_stats(main, self.output_path, l_selected_data_col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3ddf38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stats(main):\n",
    "    \"\"\"creates stats and output plots/.csv files as specified in the stats gui\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def position_stats(self, data_col, independent_variable, hue, output_path):\n",
    "        l_columns = ['group_ID', 'subject_ID', 'paradigm']\n",
    "\n",
    "        dataframe = main.dataframe.loc[:, [data_col] + l_columns]\n",
    "        dataframe.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        plt.figure(figsize=(7,9), facecolor='white')\n",
    "        \n",
    "        sns.violinplot(data=dataframe, y=\"paradigm\", x=data_col, fliersize=0, orient='h', hue=independent_variable)\n",
    "        sns.stripplot(data=dataframe, y=\"paradigm\", x=data_col, orient='h', color='k', hue=independent_variable, dodge=True, alpha=0.3)\n",
    "        plt.vlines(x=35, ymin=0.5, ymax=3.5, color='magenta', linestyle='dashed')\n",
    "\n",
    "        if output_path != \"\":\n",
    "            figname = 'differences between {} for {}.png'.format(data_col, independent_variable)\n",
    "            plt.savefig(output_path + figname, dpi=300)\n",
    "            csv_name = figname.replace('png', 'csv')\n",
    "            dataframe.to_csv(output_path + csv_name)\n",
    "    \n",
    "        plt.xlim(0, 75)\n",
    "        plt.legend(loc='center right')\n",
    "        plt.title(data_col + \" per \" + independent_variable)\n",
    "        plt.show()\n",
    "        #plt.close()\n",
    "        \n",
    "    def total_count_stats(self, data_col, independent_variable, hue, output_path):\n",
    "        l_columns = ['group_ID', 'subject_ID', 'paradigm']\n",
    "        \n",
    "        dataframe = main.dataframe.loc[:, [data_col] + l_columns].copy()\n",
    "        dataframe.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        plt.figure(figsize=(7,4), facecolor='white')\n",
    "        \n",
    "        sns.boxplot(data=dataframe, y=\"paradigm\", x=data_col, hue=independent_variable, fliersize=0)\n",
    "        sns.stripplot(data=dataframe, y=\"paradigm\", x=data_col, hue=independent_variable, dodge=True, color='k')\n",
    "        \n",
    "        if output_path != \"\":\n",
    "            figname = 'differences between {} for {}.png'.format(data_col, independent_variable)\n",
    "            plt.savefig(output_path + figname, dpi=300)\n",
    "            csv_name = figname.replace('png', 'csv')\n",
    "            dataframe.to_csv(output_path + csv_name)\n",
    "\n",
    "        plt.ylim(0)\n",
    "        plt.xlim(-0.5,5.5)\n",
    "        #plt.legend('')\n",
    "        plt.title(data_col + \" per \" + independent_variable)\n",
    "        plt.show()\n",
    "        #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0da755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    with open('data.pickle', 'rb') as f:\n",
    "        save_dict = pickle.load(f)\n",
    "    f.close()\n",
    "    main_obj = save_dict[\"main_object\"]\n",
    "    for key in save_dict:\n",
    "        setattr(main_obj, key, save_dict[key])\n",
    "    return main_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba47e9",
   "metadata": {},
   "source": [
    "Use GUI for the Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e25349",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gui.main_gui()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079d119a",
   "metadata": {},
   "source": [
    "GUI-less usage (as much as possible) of the Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b62177",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = main(path = \"C:/Users/kobel/Documents/Medizin/Doktorarbeit/Coding/Dummy Data/\", dict_cams_used = {\"bottom_cam\": False, \"top_cam\": True, \"side_cam\": False}, gui=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522191d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(project.l_subjects)):\n",
    "    print(project.l_subjects[i].subject_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2688748",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.subjects_to_groups({\"211_F1-86\": \"control\"}, [\"control\", \"experimental\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be760287",
   "metadata": {},
   "outputs": [],
   "source": [
    "del project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8538fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "657bbf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4fcf8dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'main' has no attribute 'dict_cams_used'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_functions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_selected_functions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnxiety\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mParkinson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mmain.execute_functions\u001b[1;34m(self, dict_selected_functions)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subject \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_subjects:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m session \u001b[38;5;129;01min\u001b[39;00m subject\u001b[38;5;241m.\u001b[39ml_sessions:\n\u001b[1;32m---> 72\u001b[0m         session\u001b[38;5;241m.\u001b[39mmaster_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf_functions\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_selected_functions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmaster_df\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend_session_to_d_data(subject, session, dict_selected_functions)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gui\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36mdf_functions.__init__\u001b[1;34m(self, subject, session, dict_selected_functions)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdict_selected_functions \u001b[38;5;241m=\u001b[39m dict_selected_functions\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdict_cams_used\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbottom_cam\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     17\u001b[0m     df \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mbc\u001b[38;5;241m.\u001b[39mprocessed_df\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_bodyparts \u001b[38;5;241m=\u001b[39m main\u001b[38;5;241m.\u001b[39mdict_bodyparts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbottom_cam\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'main' has no attribute 'dict_cams_used'"
     ]
    }
   ],
   "source": [
    "project.execute_functions(dict_selected_functions = {\"Anxiety\": True, \"Parkinson\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c1c9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
